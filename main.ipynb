{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from itertools import product\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "num_samples = 100       # per group (total = num_samples * num_groups)\n",
    "num_features = 700\n",
    "num_groups = 3\n",
    "\n",
    "np.random.seed(42)\n",
    "noise_level = 0.1\n",
    "true_beta = np.random.randn( num_features, 1 ) # does not include the identifier weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_structured_covariance(d):\n",
    "    return np.diag( np.random.uniform(0.3, 4, size = d) ** 2 )\n",
    "\n",
    "def identity_covariance(d):\n",
    "    return np.identity( d )\n",
    "\n",
    "class Group:\n",
    "\n",
    "    ID = 0\n",
    "\n",
    "    def __init__(self, covariance_generator = lambda: identity_covariance(num_features) ):\n",
    "        self.id = Group.ID + 1\n",
    "        Group.ID += 1\n",
    "\n",
    "        self.cov = covariance_generator()\n",
    "        self.x_dist = stats.multivariate_normal( cov = self.cov )\n",
    "\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    # Generates X (input vars) \n",
    "    def _generate_x(self, n_samples, ID = False , **kwargs):\n",
    "        x = self.x_dist.rvs(size= n_samples, **kwargs)\n",
    "        if ID:\n",
    "            identifier = np.repeat( self.ID , repeats=n_samples)\n",
    "            x = np.column_stack( (identifier, x))\n",
    "        return x\n",
    "    \n",
    "    # Generates (X, y) pairs according to linear model\n",
    "    def generate(self, n_samples, beta = true_beta):\n",
    "        x = self._generate_x(num_samples)\n",
    "        y = np.dot(x, beta) + noise_level * np.random.randn(num_samples, 1)\n",
    "        self.data = [x, y]\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.x, self.y\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, value):\n",
    "        x, y = value # unpack\n",
    "        self.x = torch.tensor(x, dtype = torch.float32, requires_grad=False)\n",
    "        self.y = torch.tensor(y, dtype = torch.float32, requires_grad=False)\n",
    "\n",
    "# Create the data\n",
    "cov_generator = lambda: fully_structured_covariance(num_features)\n",
    "groups = [ Group(cov_generator) for _ in range(num_groups) ]\n",
    "\n",
    "# TODO: by this data generating process, we have equal number of groups in the\n",
    "# training data, all disjoint. should we change this up (vary # of samples/gp)?\n",
    "Data = {}\n",
    "for group in groups:\n",
    "    group.generate(num_samples, beta= true_beta)\n",
    "\n",
    "X = torch.cat( [ group.x for group in groups ], dim = 0 )\n",
    "Y = torch.cat( [ group.y for group in groups ], dim = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, **kwargs) -> None:\n",
    "        super(LinearModel, self).__init__()\n",
    "        # Initialize at zero. \n",
    "        self.linear = torch.nn.Linear( input_dimension, 1, bias = False, **kwargs )\n",
    "        self._initialize(0.0)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _initialize(self, value):\n",
    "        self.linear.weight.fill_(value)\n",
    "        if self.linear.weight.grad is not None:\n",
    "            self.linear.weight.grad.detach_()\n",
    "            self.linear.weight.grad.zero_()\n",
    "    \n",
    "    # forward passes should NOT come from calling this directly!\n",
    "    # i.e. model(x) instead of model.forward(x)\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "    # by default, MSELoss divides by n, the size of sample\n",
    "    def risk(self, x, y):\n",
    "        loss = torch.nn.MSELoss()\n",
    "        mse = loss( self(x) , y )\n",
    "        return mse\n",
    "    \n",
    "# training loop (gradient descent on the balanaced risk: lmbd * std + dro)\n",
    "def optimize_GD(model, trade_regularization = 0.1, beta_regularization = 0, max_iter = 5000, lr = 1e-3, weight_decay = 0.0):\n",
    "    lmbd = torch.tensor([trade_regularization], requires_grad=False)\n",
    "    eta = torch.tensor([beta_regularization], requires_grad=False)  # explicit regularizer for beta\n",
    "    optimizer = torch.optim.SGD( params = model.parameters(), lr = lr, weight_decay = weight_decay )\n",
    "\n",
    "    flag = True         # for convergence criterion (objective low enough)\n",
    "    iteration = 0\n",
    "    while flag and iteration < max_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        standard_risk = model.risk( X, Y )\n",
    "        adversarial_risk = torch.max( torch.stack( [ model.risk(group.x, group.y) for group in groups ] ) )\n",
    "        objective = lmbd * standard_risk + adversarial_risk + eta * torch.norm(model.linear.weight)\n",
    "\n",
    "        objective.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            print(f\" Objective loss is {objective.item():.4f}  = {lmbd.item():.2f} * { standard_risk.item():.4f} + {adversarial_risk.item():.4f}\")\n",
    "        iteration += 1\n",
    "\n",
    "        # Check convergence\n",
    "        if objective.item() < 1e-4:\n",
    "            flag = False\n",
    "    \n",
    "    if iteration == max_iter:\n",
    "        print(\"Maximum iteration reached.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Objective loss is 6320.4780  = 0.50 * 3851.1809 + 4394.8877\n",
      " Objective loss is 64.1674  = 0.50 * 41.3549 + 43.4900\n",
      " Objective loss is 11.5422  = 0.50 * 7.5086 + 7.7879\n",
      " Objective loss is 3.1426  = 0.50 * 2.0018 + 2.1417\n",
      " Objective loss is 0.9565  = 0.50 * 0.6219 + 0.6456\n",
      " Objective loss is 0.3278  = 0.50 * 0.2087 + 0.2235\n",
      " Objective loss is 0.1149  = 0.50 * 0.0735 + 0.0781\n",
      " Objective loss is 0.0413  = 0.50 * 0.0268 + 0.0279\n",
      " Objective loss is 0.0155  = 0.50 * 0.0100 + 0.0105\n",
      " Objective loss is 0.0058  = 0.50 * 0.0038 + 0.0039\n",
      " Objective loss is 0.0022  = 0.50 * 0.0015 + 0.0015\n",
      " Objective loss is 0.0009  = 0.50 * 0.0006 + 0.0006\n",
      " Objective loss is 0.0003  = 0.50 * 0.0002 + 0.0002\n",
      " Objective loss is 0.0001  = 0.50 * 0.0001 + 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Solve the weighted regression problem using vanilla GD\n",
    "lmbd = torch.tensor([0.1], requires_grad=False)\n",
    "max_iter = 2000\n",
    "\n",
    "model = LinearModel(num_features)\n",
    "optimize_GD(model, trade_regularization = 0.5, max_iter= max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS\n",
    "ols_beta = torch.linalg.lstsq( X, Y ).solution\n",
    "\n",
    "# Subgroups- OLS\n",
    "subgroup_beta = [ torch.linalg.lstsq( group.x, group.y ).solution for group in groups ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "betas = np.hstack( [model.linear.weight.data.numpy().T, ols_beta.data.numpy()] + [beta.data.numpy() for beta in subgroup_beta ] )\n",
    "betas = pd.DataFrame( betas, columns=[\"model\", \"OLS\"] + [f\"Group {i} OLS\" for i in range(num_groups)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>OLS</th>\n",
       "      <th>Group 0 OLS</th>\n",
       "      <th>Group 1 OLS</th>\n",
       "      <th>Group 2 OLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546721</td>\n",
       "      <td>0.619180</td>\n",
       "      <td>0.528948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546681</td>\n",
       "      <td>0.619126</td>\n",
       "      <td>0.528920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group 0 OLS</th>\n",
       "      <td>0.546721</td>\n",
       "      <td>0.546681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150638</td>\n",
       "      <td>0.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group 1 OLS</th>\n",
       "      <td>0.619180</td>\n",
       "      <td>0.619126</td>\n",
       "      <td>0.150638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group 2 OLS</th>\n",
       "      <td>0.528948</td>\n",
       "      <td>0.528920</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.134142</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model       OLS  Group 0 OLS  Group 1 OLS  Group 2 OLS\n",
       "model        1.000000  1.000000     0.546721     0.619180     0.528948\n",
       "OLS          1.000000  1.000000     0.546681     0.619126     0.528920\n",
       "Group 0 OLS  0.546721  0.546681     1.000000     0.150638     0.111400\n",
       "Group 1 OLS  0.619180  0.619126     0.150638     1.000000     0.134142\n",
       "Group 2 OLS  0.528948  0.528920     0.111400     0.134142     1.000000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Varying $\\lambda$ Tradeoff Parameter\n",
    "Our notion of tradeoff risk between DRO and standard risk is controlled by the parameter $\\lambda$. Fully writing out the\n",
    "tradeoff objective, we have:\n",
    "$$\n",
    "\\mathcal{R}_{\\mathrm{trade}}(\\beta; \\lambda) := \\mathcal{R}_{\\mathrm{group}}(\\beta) + \\lambda \\mathcal{R}_{\\mathrm{std}}(\\beta)\n",
    "= \\max_{g \\in \\mathcal{G}} \\mathbb{E}_{(X, Y) \\sim \\mathbb{P}_g}[(X^\\top \\beta - Y)^2] + \\lambda \\mathbb{E}_{X \\sim \\mathbb{P}_X}\\left[ \\mathbb{E} \\left[ (X^\\top \\beta - Y)^2 \\mid X \\right] \\right],\n",
    "$$\n",
    "where $\\mathbb{P}_g$ is the group distribution for group $g \\in \\mathcal{G}$. The $\\lambda$ parameter controls how much we tradeoff for standard risk in our objective. $\\lambda = 0$ means we are solely optimizing for group DRO. We vary the value of $\\lambda$ and see if this has any effect on the resulting $\\hat{\\beta}$ that our model produces by minimizing $\\hat{\\mathcal{R}}_{\\mathrm{trade}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Objective loss is 4394.8877  = 0.00 * 3851.1809 + 4394.8877\n",
      " Objective loss is 99.4866  = 0.00 * 94.0577 + 99.4866\n",
      " Objective loss is 22.4200  = 0.00 * 21.2680 + 22.4200\n",
      " Objective loss is 7.7334  = 0.00 * 7.3495 + 7.7334\n",
      " Objective loss is 3.1883  = 0.00 * 2.9754 + 3.1883\n",
      " Objective loss is 1.3494  = 0.00 * 1.3091 + 1.3494\n",
      " Objective loss is 0.6196  = 0.00 * 0.6028 + 0.6196\n",
      " Objective loss is 0.2995  = 0.00 * 0.2889 + 0.2995\n",
      " Objective loss is 0.1443  = 0.00 * 0.1413 + 0.1443\n",
      " Objective loss is 0.0732  = 0.00 * 0.0706 + 0.0732\n",
      " Objective loss is 0.0389  = 0.00 * 0.0357 + 0.0389\n",
      " Objective loss is 0.0196  = 0.00 * 0.0183 + 0.0196\n",
      " Objective loss is 0.0095  = 0.00 * 0.0095 + 0.0095\n",
      " Objective loss is 0.0051  = 0.00 * 0.0049 + 0.0051\n",
      " Objective loss is 0.0027  = 0.00 * 0.0026 + 0.0027\n",
      " Objective loss is 0.0014  = 0.00 * 0.0014 + 0.0014\n",
      " Objective loss is 0.0008  = 0.00 * 0.0007 + 0.0008\n",
      " Objective loss is 0.0004  = 0.00 * 0.0004 + 0.0004\n",
      " Objective loss is 0.0002  = 0.00 * 0.0002 + 0.0002\n",
      " Objective loss is 0.0001  = 0.00 * 0.0001 + 0.0001\n",
      " Objective loss is 5180.8430  = 0.20 * 3851.1809 + 4394.8877\n",
      " Objective loss is 81.7816  = 0.20 * 65.6359 + 68.3866\n",
      " Objective loss is 17.0606  = 0.20 * 13.4785 + 14.3098\n",
      " Objective loss is 5.2823  = 0.20 * 4.2359 + 4.4178\n",
      " Objective loss is 1.9079  = 0.20 * 1.5362 + 1.5944\n",
      " Objective loss is 0.7677  = 0.20 * 0.6047 + 0.6443\n",
      " Objective loss is 0.3174  = 0.20 * 0.2494 + 0.2665\n",
      " Objective loss is 0.1353  = 0.20 * 0.1069 + 0.1135\n",
      " Objective loss is 0.0583  = 0.20 * 0.0468 + 0.0487\n",
      " Objective loss is 0.0260  = 0.20 * 0.0209 + 0.0217\n",
      " Objective loss is 0.0118  = 0.20 * 0.0095 + 0.0099\n",
      " Objective loss is 0.0054  = 0.20 * 0.0043 + 0.0045\n",
      " Objective loss is 0.0025  = 0.20 * 0.0020 + 0.0021\n",
      " Objective loss is 0.0011  = 0.20 * 0.0009 + 0.0009\n",
      " Objective loss is 0.0005  = 0.20 * 0.0004 + 0.0005\n",
      " Objective loss is 0.0003  = 0.20 * 0.0002 + 0.0002\n",
      " Objective loss is 0.0001  = 0.20 * 0.0001 + 0.0001\n",
      " Objective loss is 5966.7983  = 0.41 * 3851.1809 + 4394.8877\n",
      " Objective loss is 69.0112  = 0.41 * 47.3306 + 49.6926\n",
      " Objective loss is 13.0285  = 0.41 * 8.9153 + 9.3896\n",
      " Objective loss is 3.5670  = 0.41 * 2.5117 + 2.5419\n",
      " Objective loss is 1.2048  = 0.41 * 0.8179 + 0.8710\n",
      " Objective loss is 0.4244  = 0.41 * 0.2892 + 0.3063\n",
      " Objective loss is 0.1534  = 0.41 * 0.1071 + 0.1097\n",
      " Objective loss is 0.0587  = 0.41 * 0.0409 + 0.0420\n",
      " Objective loss is 0.0237  = 0.41 * 0.0160 + 0.0171\n",
      " Objective loss is 0.0094  = 0.41 * 0.0064 + 0.0068\n",
      " Objective loss is 0.0038  = 0.41 * 0.0026 + 0.0027\n",
      " Objective loss is 0.0015  = 0.41 * 0.0011 + 0.0011\n",
      " Objective loss is 0.0006  = 0.41 * 0.0004 + 0.0005\n",
      " Objective loss is 0.0003  = 0.41 * 0.0002 + 0.0002\n",
      " Objective loss is 0.0001  = 0.41 * 0.0001 + 0.0001\n",
      " Objective loss is 6752.7536  = 0.61 * 3851.1809 + 4394.8877\n",
      " Objective loss is 58.2406  = 0.61 * 35.5084 + 36.5007\n",
      " Objective loss is 9.9647  = 0.61 * 6.0642 + 6.2519\n",
      " Objective loss is 2.5192  = 0.61 * 1.5322 + 1.5812\n",
      " Objective loss is 0.7242  = 0.61 * 0.4476 + 0.4502\n",
      " Objective loss is 0.2339  = 0.61 * 0.1413 + 0.1474\n",
      " Objective loss is 0.0784  = 0.61 * 0.0468 + 0.0497\n",
      " Objective loss is 0.0267  = 0.61 * 0.0161 + 0.0168\n",
      " Objective loss is 0.0092  = 0.61 * 0.0056 + 0.0058\n",
      " Objective loss is 0.0033  = 0.61 * 0.0020 + 0.0021\n",
      " Objective loss is 0.0012  = 0.61 * 0.0007 + 0.0008\n",
      " Objective loss is 0.0004  = 0.61 * 0.0003 + 0.0003\n",
      " Objective loss is 0.0002  = 0.61 * 0.0001 + 0.0001\n",
      " Objective loss is 7538.7088  = 0.82 * 3851.1809 + 4394.8877\n",
      " Objective loss is 50.0919  = 0.82 * 27.0706 + 27.9934\n",
      " Objective loss is 7.6814  = 0.82 * 4.2122 + 4.2428\n",
      " Objective loss is 1.7705  = 0.82 * 0.9566 + 0.9896\n",
      " Objective loss is 0.4635  = 0.82 * 0.2502 + 0.2593\n",
      " Objective loss is 0.1313  = 0.82 * 0.0706 + 0.0736\n",
      " Objective loss is 0.0390  = 0.82 * 0.0209 + 0.0219\n",
      " Objective loss is 0.0121  = 0.82 * 0.0064 + 0.0069\n",
      " Objective loss is 0.0037  = 0.82 * 0.0020 + 0.0020\n",
      " Objective loss is 0.0012  = 0.82 * 0.0006 + 0.0007\n",
      " Objective loss is 0.0004  = 0.82 * 0.0002 + 0.0002\n",
      " Objective loss is 0.0001  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 8324.6641  = 1.02 * 3851.1809 + 4394.8877\n",
      " Objective loss is 43.3897  = 1.02 * 21.1972 + 21.7599\n",
      " Objective loss is 6.1236  = 1.02 * 2.9729 + 3.0900\n",
      " Objective loss is 1.2517  = 1.02 * 0.6039 + 0.6355\n",
      " Objective loss is 0.2885  = 1.02 * 0.1412 + 0.1444\n",
      " Objective loss is 0.0739  = 1.02 * 0.0358 + 0.0373\n",
      " Objective loss is 0.0195  = 1.02 * 0.0095 + 0.0099\n",
      " Objective loss is 0.0053  = 1.02 * 0.0026 + 0.0027\n",
      " Objective loss is 0.0015  = 1.02 * 0.0007 + 0.0007\n",
      " Objective loss is 0.0004  = 1.02 * 0.0002 + 0.0002\n",
      " Objective loss is 0.0001  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 9110.6194  = 1.22 * 3851.1809 + 4394.8877\n",
      " Objective loss is 37.5211  = 1.22 * 16.7363 + 17.0277\n",
      " Objective loss is 4.9093  = 1.22 * 2.1235 + 2.3090\n",
      " Objective loss is 0.8840  = 1.22 * 0.3858 + 0.4116\n",
      " Objective loss is 0.1838  = 1.22 * 0.0808 + 0.0849\n",
      " Objective loss is 0.0412  = 1.22 * 0.0183 + 0.0188\n",
      " Objective loss is 0.0098  = 1.22 * 0.0043 + 0.0045\n",
      " Objective loss is 0.0024  = 1.22 * 0.0010 + 0.0011\n",
      " Objective loss is 0.0006  = 1.22 * 0.0003 + 0.0003\n",
      " Objective loss is 0.0001  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 9896.5747  = 1.43 * 3851.1809 + 4394.8877\n",
      " Objective loss is 33.3574  = 1.43 * 13.4685 + 14.1167\n",
      " Objective loss is 3.8296  = 1.43 * 1.5317 + 1.6415\n",
      " Objective loss is 0.6050  = 1.43 * 0.2488 + 0.2495\n",
      " Objective loss is 0.1150  = 1.43 * 0.0467 + 0.0484\n",
      " Objective loss is 0.0231  = 1.43 * 0.0094 + 0.0096\n",
      " Objective loss is 0.0050  = 1.43 * 0.0020 + 0.0021\n",
      " Objective loss is 0.0011  = 1.43 * 0.0004 + 0.0004\n",
      " Objective loss is 0.0002  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 10682.5300  = 1.63 * 3851.1809 + 4394.8877\n",
      " Objective loss is 28.7058  = 1.63 * 10.8564 + 10.9811\n",
      " Objective loss is 2.9808  = 1.63 * 1.1142 + 1.1617\n",
      " Objective loss is 0.4301  = 1.63 * 0.1620 + 0.1657\n",
      " Objective loss is 0.0731  = 1.63 * 0.0271 + 0.0288\n",
      " Objective loss is 0.0129  = 1.63 * 0.0049 + 0.0049\n",
      " Objective loss is 0.0025  = 1.63 * 0.0009 + 0.0010\n",
      " Objective loss is 0.0005  = 1.63 * 0.0002 + 0.0002\n",
      " Objective loss is 11468.4853  = 1.84 * 3851.1809 + 4394.8877\n",
      " Objective loss is 25.7618  = 1.84 * 8.8421 + 9.5211\n",
      " Objective loss is 2.3520  = 1.84 * 0.8125 + 0.8597\n",
      " Objective loss is 0.3058  = 1.84 * 0.1061 + 0.1109\n",
      " Objective loss is 0.0463  = 1.84 * 0.0159 + 0.0171\n",
      " Objective loss is 0.0073  = 1.84 * 0.0026 + 0.0026\n",
      " Objective loss is 0.0012  = 1.84 * 0.0004 + 0.0004\n",
      " Objective loss is 0.0002  = 1.84 * 0.0001 + 0.0001\n",
      " Objective loss is 12254.4406  = 2.04 * 3851.1809 + 4394.8877\n",
      " Objective loss is 22.2743  = 2.04 * 7.2854 + 7.4061\n",
      " Objective loss is 1.8523  = 2.04 * 0.5998 + 0.6282\n",
      " Objective loss is 0.2153  = 2.04 * 0.0700 + 0.0724\n",
      " Objective loss is 0.0289  = 2.04 * 0.0094 + 0.0098\n",
      " Objective loss is 0.0042  = 2.04 * 0.0013 + 0.0014\n",
      " Objective loss is 0.0006  = 2.04 * 0.0002 + 0.0002\n",
      " Objective loss is 13040.3959  = 2.24 * 3851.1809 + 4394.8877\n",
      " Objective loss is 19.8778  = 2.24 * 6.0087 + 6.3888\n",
      " Objective loss is 1.4543  = 2.24 * 0.4441 + 0.4574\n",
      " Objective loss is 0.1515  = 2.24 * 0.0464 + 0.0474\n",
      " Objective loss is 0.0181  = 2.24 * 0.0055 + 0.0056\n",
      " Objective loss is 0.0023  = 2.24 * 0.0007 + 0.0007\n",
      " Objective loss is 0.0003  = 2.24 * 0.0001 + 0.0001\n",
      " Objective loss is 13826.3511  = 2.45 * 3851.1809 + 4394.8877\n",
      " Objective loss is 17.5295  = 2.45 * 5.0085 + 5.2639\n",
      " Objective loss is 1.1476  = 2.45 * 0.3305 + 0.3382\n",
      " Objective loss is 0.1092  = 2.45 * 0.0308 + 0.0337\n",
      " Objective loss is 0.0114  = 2.45 * 0.0033 + 0.0034\n",
      " Objective loss is 0.0013  = 2.45 * 0.0004 + 0.0004\n",
      " Objective loss is 0.0002  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 14612.3064  = 2.65 * 3851.1809 + 4394.8877\n",
      " Objective loss is 15.4216  = 2.65 * 4.1667 + 4.3671\n",
      " Objective loss is 0.9157  = 2.65 * 0.2464 + 0.2620\n",
      " Objective loss is 0.0763  = 2.65 * 0.0206 + 0.0216\n",
      " Objective loss is 0.0073  = 2.65 * 0.0020 + 0.0021\n",
      " Objective loss is 0.0007  = 2.65 * 0.0002 + 0.0002\n",
      " Objective loss is 15398.2617  = 2.86 * 3851.1809 + 4394.8877\n",
      " Objective loss is 13.7783  = 2.86 * 3.4955 + 3.7912\n",
      " Objective loss is 0.7251  = 2.86 * 0.1850 + 0.1967\n",
      " Objective loss is 0.0540  = 2.86 * 0.0138 + 0.0146\n",
      " Objective loss is 0.0045  = 2.86 * 0.0012 + 0.0012\n",
      " Objective loss is 0.0004  = 2.86 * 0.0001 + 0.0001\n",
      " Objective loss is 16184.2170  = 3.06 * 3851.1809 + 4394.8877\n",
      " Objective loss is 12.0865  = 3.06 * 2.9360 + 3.0989\n",
      " Objective loss is 0.5754  = 3.06 * 0.1393 + 0.1489\n",
      " Objective loss is 0.0385  = 3.06 * 0.0093 + 0.0101\n",
      " Objective loss is 0.0029  = 3.06 * 0.0007 + 0.0007\n",
      " Objective loss is 0.0002  = 3.06 * 0.0001 + 0.0001\n",
      " Objective loss is 16970.1723  = 3.27 * 3851.1809 + 4394.8877\n",
      " Objective loss is 10.7067  = 3.27 * 2.4766 + 2.6198\n",
      " Objective loss is 0.4515  = 3.27 * 0.1048 + 0.1092\n",
      " Objective loss is 0.0270  = 3.27 * 0.0062 + 0.0066\n",
      " Objective loss is 0.0018  = 3.27 * 0.0004 + 0.0004\n",
      " Objective loss is 0.0001  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 17756.1276  = 3.47 * 3851.1809 + 4394.8877\n",
      " Objective loss is 9.4257  = 3.47 * 2.0867 + 2.1861\n",
      " Objective loss is 0.3553  = 3.47 * 0.0793 + 0.0802\n",
      " Objective loss is 0.0191  = 3.47 * 0.0042 + 0.0045\n",
      " Objective loss is 0.0011  = 3.47 * 0.0003 + 0.0003\n",
      " Objective loss is 18542.0829  = 3.67 * 3851.1809 + 4394.8877\n",
      " Objective loss is 8.3728  = 3.67 * 1.7687 + 1.8756\n",
      " Objective loss is 0.2848  = 3.67 * 0.0601 + 0.0641\n",
      " Objective loss is 0.0135  = 3.67 * 0.0029 + 0.0030\n",
      " Objective loss is 0.0007  = 3.67 * 0.0002 + 0.0002\n",
      " Objective loss is 19328.0382  = 3.88 * 3851.1809 + 4394.8877\n",
      " Objective loss is 7.3418  = 3.88 * 1.5036 + 1.5117\n",
      " Objective loss is 0.2257  = 3.88 * 0.0457 + 0.0486\n",
      " Objective loss is 0.0095  = 3.88 * 0.0019 + 0.0021\n",
      " Objective loss is 0.0004  = 3.88 * 0.0001 + 0.0001\n",
      " Objective loss is 20113.9934  = 4.08 * 3851.1809 + 4394.8877\n",
      " Objective loss is 6.5610  = 4.08 * 1.2781 + 1.3441\n",
      " Objective loss is 0.1786  = 4.08 * 0.0348 + 0.0364\n",
      " Objective loss is 0.0066  = 4.08 * 0.0013 + 0.0013\n",
      " Objective loss is 0.0003  = 4.08 * 0.0001 + 0.0001\n",
      " Objective loss is 20899.9487  = 4.29 * 3851.1809 + 4394.8877\n",
      " Objective loss is 5.8585  = 4.29 * 1.0922 + 1.1775\n",
      " Objective loss is 0.1400  = 4.29 * 0.0265 + 0.0265\n",
      " Objective loss is 0.0047  = 4.29 * 0.0009 + 0.0009\n",
      " Objective loss is 0.0002  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 21685.9040  = 4.49 * 3851.1809 + 4394.8877\n",
      " Objective loss is 5.1746  = 4.49 * 0.9326 + 0.9872\n",
      " Objective loss is 0.1118  = 4.49 * 0.0202 + 0.0211\n",
      " Objective loss is 0.0034  = 4.49 * 0.0006 + 0.0007\n",
      " Objective loss is 0.0001  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 22471.8593  = 4.69 * 3851.1809 + 4394.8877\n",
      " Objective loss is 4.5960  = 4.69 * 0.7984 + 0.8486\n",
      " Objective loss is 0.0883  = 4.69 * 0.0154 + 0.0158\n",
      " Objective loss is 0.0024  = 4.69 * 0.0004 + 0.0004\n",
      " Objective loss is 23257.8146  = 4.90 * 3851.1809 + 4394.8877\n",
      " Objective loss is 4.0518  = 4.90 * 0.6822 + 0.7104\n",
      " Objective loss is 0.0704  = 4.90 * 0.0118 + 0.0126\n",
      " Objective loss is 0.0017  = 4.90 * 0.0003 + 0.0003\n",
      " Objective loss is 24043.7699  = 5.10 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.5931  = 5.10 * 0.5850 + 0.6082\n",
      " Objective loss is 0.0557  = 5.10 * 0.0091 + 0.0094\n",
      " Objective loss is 0.0012  = 5.10 * 0.0002 + 0.0002\n",
      " Objective loss is 24829.7252  = 5.31 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.1906  = 5.31 * 0.5023 + 0.5255\n",
      " Objective loss is 0.0438  = 5.31 * 0.0069 + 0.0070\n",
      " Objective loss is 0.0008  = 5.31 * 0.0001 + 0.0001\n",
      " Objective loss is 25615.6805  = 5.51 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.8347  = 5.51 * 0.4330 + 0.4487\n",
      " Objective loss is 0.0349  = 5.51 * 0.0053 + 0.0056\n",
      " Objective loss is 0.0006  = 5.51 * 0.0001 + 0.0001\n",
      " Objective loss is 26401.6357  = 5.71 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.5008  = 5.71 * 0.3721 + 0.3746\n",
      " Objective loss is 0.0278  = 5.71 * 0.0041 + 0.0044\n",
      " Objective loss is 0.0004  = 5.71 * 0.0001 + 0.0001\n",
      " Objective loss is 27187.5910  = 5.92 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.2342  = 5.92 * 0.3206 + 0.3370\n",
      " Objective loss is 0.0219  = 5.92 * 0.0031 + 0.0033\n",
      " Objective loss is 0.0003  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 27973.5463  = 6.12 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.9940  = 6.12 * 0.2771 + 0.2974\n",
      " Objective loss is 0.0173  = 6.12 * 0.0024 + 0.0025\n",
      " Objective loss is 0.0002  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 28759.5016  = 6.33 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.7616  = 6.33 * 0.2387 + 0.2512\n",
      " Objective loss is 0.0138  = 6.33 * 0.0019 + 0.0020\n",
      " Objective loss is 0.0001  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 29545.4569  = 6.53 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.5660  = 6.53 * 0.2070 + 0.2140\n",
      " Objective loss is 0.0108  = 6.53 * 0.0014 + 0.0015\n",
      " Objective loss is 0.0001  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 30331.4122  = 6.73 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.3906  = 6.73 * 0.1790 + 0.1850\n",
      " Objective loss is 0.0086  = 6.73 * 0.0011 + 0.0011\n",
      " Objective loss is 31117.3675  = 6.94 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.2317  = 6.94 * 0.1547 + 0.1587\n",
      " Objective loss is 0.0068  = 6.94 * 0.0008 + 0.0009\n",
      " Objective loss is 31903.3228  = 7.14 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.0940  = 7.14 * 0.1339 + 0.1375\n",
      " Objective loss is 0.0053  = 7.14 * 0.0007 + 0.0007\n",
      " Objective loss is 32689.2780  = 7.35 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.9734  = 7.35 * 0.1159 + 0.1220\n",
      " Objective loss is 0.0042  = 7.35 * 0.0005 + 0.0005\n",
      " Objective loss is 33475.2333  = 7.55 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.8685  = 7.55 * 0.1007 + 0.1082\n",
      " Objective loss is 0.0034  = 7.55 * 0.0004 + 0.0004\n",
      " Objective loss is 34261.1886  = 7.76 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.7664  = 7.76 * 0.0873 + 0.0893\n",
      " Objective loss is 0.0027  = 7.76 * 0.0003 + 0.0003\n",
      " Objective loss is 35047.1439  = 7.96 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.6840  = 7.96 * 0.0757 + 0.0818\n",
      " Objective loss is 0.0021  = 7.96 * 0.0002 + 0.0002\n",
      " Objective loss is 35833.0992  = 8.16 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.6060  = 8.16 * 0.0657 + 0.0693\n",
      " Objective loss is 0.0016  = 8.16 * 0.0002 + 0.0002\n",
      " Objective loss is 36619.0545  = 8.37 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.5372  = 8.37 * 0.0572 + 0.0584\n",
      " Objective loss is 0.0013  = 8.37 * 0.0001 + 0.0001\n",
      " Objective loss is 37405.0098  = 8.57 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.4759  = 8.57 * 0.0497 + 0.0499\n",
      " Objective loss is 0.0010  = 8.57 * 0.0001 + 0.0001\n",
      " Objective loss is 38190.9651  = 8.78 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.4254  = 8.78 * 0.0432 + 0.0461\n",
      " Objective loss is 0.0008  = 8.78 * 0.0001 + 0.0001\n",
      " Objective loss is 38976.9203  = 8.98 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.3784  = 8.98 * 0.0376 + 0.0408\n",
      " Objective loss is 0.0006  = 8.98 * 0.0001 + 0.0001\n",
      " Objective loss is 39762.8756  = 9.18 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.3362  = 9.18 * 0.0327 + 0.0355\n",
      " Objective loss is 0.0005  = 9.18 * 0.0000 + 0.0001\n",
      " Objective loss is 40548.8309  = 9.39 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.2986  = 9.39 * 0.0285 + 0.0309\n",
      " Objective loss is 0.0004  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 41334.7862  = 9.59 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.2653  = 9.59 * 0.0248 + 0.0269\n",
      " Objective loss is 0.0003  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 42120.7415  = 9.80 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.2358  = 9.80 * 0.0217 + 0.0234\n",
      " Objective loss is 0.0002  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 42906.6968  = 10.00 * 3851.1809 + 4394.8877\n",
      " Objective loss is 0.2096  = 10.00 * 0.0189 + 0.0207\n",
      " Objective loss is 0.0002  = 10.00 * 0.0000 + 0.0000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_iter = 2000\n",
    "lambdas = torch.tensor(np.linspace(0, 10.0), requires_grad=False)\n",
    "ols_beta = torch.linalg.lstsq( X, Y ).solution  # regular OLS solution\n",
    "subgroup_betas = [ torch.linalg.lstsq( group.x, group.y ).solution for group in groups ] # OLS for each group\n",
    "model_betas = list()\n",
    "\n",
    "for lmbd in lambdas:\n",
    "    # train tradeoff model\n",
    "    model = LinearModel(num_features)\n",
    "    optimize_GD(model, trade_regularization = lmbd, max_iter= max_iter)\n",
    "    model_betas.append(model.linear.weight.data.numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$\\\\| \\\\beta_{\\\\mathrm{trade}} - \\\\beta_{\\\\mathrm{OLS}} \\\\|_2$')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot difference between model's betas and OLS beta\n",
    "# Is this actually a significant difference?\n",
    "beta_l2 = [np.linalg.norm(model_beta - ols_beta.numpy().T) for model_beta in model_betas]\n",
    "plt.plot(lambdas, beta_l2)\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(r'$\\| \\beta_{\\mathrm{trade}} - \\beta_{\\mathrm{OLS}} \\|_2$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Adding Explicit Regularizer and Varying $\\lambda$ Tradeoff Parameter\n",
    "Now, we add an explicit $\\ell_2$ regularization to the objective, controlled by $\\eta > 0.$ This gives us the objective:\n",
    "$$\n",
    "\\mathcal{R}_{\\mathrm{trade}}(\\beta; \\lambda) + \\eta \\|\\beta\\|_2\n",
    "= \\max_{g \\in \\mathcal{G}} \\mathbb{E}_{(X, Y) \\sim \\mathbb{P}_g}[(X^\\top \\beta - Y)^2] + \\lambda \\mathbb{E}_{X \\sim \\mathbb{P}_X}\\left[ \\mathbb{E} \\left[ (X^\\top \\beta - Y)^2 \\mid X \\right] \\right] + \\eta\\|\\beta\\|_2.\n",
    "$$\n",
    "Again, we first look at the effect that varying $\\lambda$ has on this objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Objective loss is 4394.8877  = 0.00 * 3851.1809 + 4394.8877\n",
      " Objective loss is 101.1026  = 0.00 * 94.1922 + 99.6609\n",
      " Objective loss is 24.1462  = 0.00 * 21.3383 + 22.5286\n",
      " Objective loss is 9.4619  = 0.00 * 7.3925 + 7.7818\n",
      " Objective loss is 4.9382  = 0.00 * 3.0047 + 3.2281\n",
      " Objective loss is 3.1003  = 0.00 * 1.3300 + 1.3731\n",
      " Objective loss is 2.3647  = 0.00 * 0.6172 + 0.6273\n",
      " Objective loss is 2.0625  = 0.00 * 0.2982 + 0.3186\n",
      " Objective loss is 1.8994  = 0.00 * 0.1487 + 0.1514\n",
      " Objective loss is 1.8285  = 0.00 * 0.0758 + 0.0778\n",
      " Objective loss is 1.7935  = 0.00 * 0.0396 + 0.0409\n",
      " Objective loss is 1.7758  = 0.00 * 0.0211 + 0.0220\n",
      " Objective loss is 1.7670  = 0.00 * 0.0116 + 0.0124\n",
      " Objective loss is 1.7621  = 0.00 * 0.0065 + 0.0069\n",
      " Objective loss is 1.7598  = 0.00 * 0.0038 + 0.0042\n",
      " Objective loss is 1.7583  = 0.00 * 0.0024 + 0.0025\n",
      " Objective loss is 1.7577  = 0.00 * 0.0015 + 0.0016\n",
      " Objective loss is 1.7574  = 0.00 * 0.0011 + 0.0011\n",
      " Objective loss is 1.7572  = 0.00 * 0.0008 + 0.0008\n",
      " Objective loss is 1.7571  = 0.00 * 0.0006 + 0.0007\n",
      "Maximum iteration reached.\n",
      " Objective loss is 5180.8430  = 0.20 * 3851.1809 + 4394.8877\n",
      " Objective loss is 84.1184  = 0.20 * 65.7483 + 69.2035\n",
      " Objective loss is 18.8801  = 0.20 * 13.5268 + 14.4710\n",
      " Objective loss is 7.0296  = 0.20 * 4.2468 + 4.4623\n",
      " Objective loss is 3.6564  = 0.20 * 1.5548 + 1.6145\n",
      " Objective loss is 2.5297  = 0.20 * 0.6147 + 0.6667\n",
      " Objective loss is 2.0675  = 0.20 * 0.2573 + 0.2700\n",
      " Objective loss is 1.8927  = 0.20 * 0.1124 + 0.1204\n",
      " Objective loss is 1.8147  = 0.20 * 0.0505 + 0.0524\n",
      " Objective loss is 1.7826  = 0.20 * 0.0234 + 0.0241\n",
      " Objective loss is 1.7684  = 0.20 * 0.0112 + 0.0113\n",
      " Objective loss is 1.7624  = 0.20 * 0.0056 + 0.0058\n",
      " Objective loss is 1.7595  = 0.20 * 0.0029 + 0.0030\n",
      " Objective loss is 1.7582  = 0.20 * 0.0016 + 0.0017\n",
      " Objective loss is 1.7575  = 0.20 * 0.0010 + 0.0010\n",
      " Objective loss is 1.7573  = 0.20 * 0.0007 + 0.0007\n",
      " Objective loss is 1.7571  = 0.20 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7571  = 0.20 * 0.0004 + 0.0004\n",
      " Objective loss is 1.7571  = 0.20 * 0.0003 + 0.0004\n",
      " Objective loss is 1.7570  = 0.20 * 0.0003 + 0.0003\n",
      "Maximum iteration reached.\n",
      " Objective loss is 5966.7983  = 0.41 * 3851.1809 + 4394.8877\n",
      " Objective loss is 70.6691  = 0.41 * 47.4009 + 49.7826\n",
      " Objective loss is 14.7568  = 0.41 * 8.9486 + 9.4332\n",
      " Objective loss is 5.3131  = 0.41 * 2.5316 + 2.5652\n",
      " Objective loss is 2.9522  = 0.41 * 0.8296 + 0.8794\n",
      " Objective loss is 2.1749  = 0.41 * 0.2964 + 0.3099\n",
      " Objective loss is 1.9144  = 0.41 * 0.1114 + 0.1195\n",
      " Objective loss is 1.8158  = 0.41 * 0.0438 + 0.0454\n",
      " Objective loss is 1.7801  = 0.41 * 0.0179 + 0.0186\n",
      " Objective loss is 1.7663  = 0.41 * 0.0076 + 0.0080\n",
      " Objective loss is 1.7607  = 0.41 * 0.0034 + 0.0035\n",
      " Objective loss is 1.7585  = 0.41 * 0.0016 + 0.0017\n",
      " Objective loss is 1.7577  = 0.41 * 0.0009 + 0.0009\n",
      " Objective loss is 1.7573  = 0.41 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7572  = 0.41 * 0.0004 + 0.0004\n",
      " Objective loss is 1.7571  = 0.41 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7571  = 0.41 * 0.0002 + 0.0003\n",
      " Objective loss is 1.7571  = 0.41 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.41 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.41 * 0.0002 + 0.0002\n",
      "Maximum iteration reached.\n",
      " Objective loss is 6752.7536  = 0.61 * 3851.1809 + 4394.8877\n",
      " Objective loss is 59.9124  = 0.61 * 35.5626 + 36.5681\n",
      " Objective loss is 11.6978  = 0.61 * 6.0888 + 6.2821\n",
      " Objective loss is 4.2563  = 0.61 * 1.5457 + 1.5852\n",
      " Objective loss is 2.4785  = 0.61 * 0.4555 + 0.4590\n",
      " Objective loss is 1.9900  = 0.61 * 0.1458 + 0.1525\n",
      " Objective loss is 1.8341  = 0.61 * 0.0495 + 0.0517\n",
      " Objective loss is 1.7831  = 0.61 * 0.0176 + 0.0180\n",
      " Objective loss is 1.7663  = 0.61 * 0.0066 + 0.0069\n",
      " Objective loss is 1.7603  = 0.61 * 0.0026 + 0.0026\n",
      " Objective loss is 1.7583  = 0.61 * 0.0011 + 0.0012\n",
      " Objective loss is 1.7575  = 0.61 * 0.0006 + 0.0006\n",
      " Objective loss is 1.7572  = 0.61 * 0.0003 + 0.0004\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0003\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0001 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0001 + 0.0002\n",
      "Maximum iteration reached.\n",
      " Objective loss is 7538.7088  = 0.82 * 3851.1809 + 4394.8877\n",
      " Objective loss is 51.7766  = 0.82 * 27.1128 + 28.0464\n",
      " Objective loss is 9.4150  = 0.82 * 4.2308 + 4.2607\n",
      " Objective loss is 3.5276  = 0.82 * 0.9676 + 1.0056\n",
      " Objective loss is 2.2270  = 0.82 * 0.2546 + 0.2739\n",
      " Objective loss is 1.8854  = 0.82 * 0.0734 + 0.0744\n",
      " Objective loss is 1.7960  = 0.82 * 0.0225 + 0.0237\n",
      " Objective loss is 1.7691  = 0.82 * 0.0073 + 0.0078\n",
      " Objective loss is 1.7609  = 0.82 * 0.0025 + 0.0028\n",
      " Objective loss is 1.7583  = 0.82 * 0.0010 + 0.0010\n",
      " Objective loss is 1.7575  = 0.82 * 0.0004 + 0.0005\n",
      " Objective loss is 1.7572  = 0.82 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7572  = 0.82 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 8324.6641  = 1.02 * 3851.1809 + 4394.8877\n",
      " Objective loss is 45.0762  = 1.02 * 21.2314 + 21.7938\n",
      " Objective loss is 7.8631  = 1.02 * 2.9875 + 3.1040\n",
      " Objective loss is 2.9946  = 1.02 * 0.6108 + 0.6335\n",
      " Objective loss is 2.0425  = 1.02 * 0.1448 + 0.1464\n",
      " Objective loss is 1.8311  = 1.02 * 0.0375 + 0.0399\n",
      " Objective loss is 1.7767  = 1.02 * 0.0104 + 0.0110\n",
      " Objective loss is 1.7623  = 1.02 * 0.0031 + 0.0031\n",
      " Objective loss is 1.7586  = 1.02 * 0.0010 + 0.0010\n",
      " Objective loss is 1.7575  = 1.02 * 0.0004 + 0.0004\n",
      " Objective loss is 1.7572  = 1.02 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 1.02 * 0.0001 + 0.0002\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 9110.6194  = 1.22 * 3851.1809 + 4394.8877\n",
      " Objective loss is 39.2243  = 1.22 * 16.7641 + 17.0617\n",
      " Objective loss is 6.6632  = 1.22 * 2.1353 + 2.3301\n",
      " Objective loss is 2.6460  = 1.22 * 0.3915 + 0.4247\n",
      " Objective loss is 1.9390  = 1.22 * 0.0833 + 0.0863\n",
      " Objective loss is 1.7984  = 1.22 * 0.0195 + 0.0204\n",
      " Objective loss is 1.7671  = 1.22 * 0.0049 + 0.0053\n",
      " Objective loss is 1.7595  = 1.22 * 0.0014 + 0.0015\n",
      " Objective loss is 1.7577  = 1.22 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7573  = 1.22 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 9896.5747  = 1.43 * 3851.1809 + 4394.8877\n",
      " Objective loss is 35.0632  = 1.43 * 13.4916 + 14.1401\n",
      " Objective loss is 5.5787  = 1.43 * 1.5407 + 1.6528\n",
      " Objective loss is 2.3716  = 1.43 * 0.2528 + 0.2652\n",
      " Objective loss is 1.8723  = 1.43 * 0.0484 + 0.0508\n",
      " Objective loss is 1.7804  = 1.43 * 0.0102 + 0.0107\n",
      " Objective loss is 1.7621  = 1.43 * 0.0024 + 0.0025\n",
      " Objective loss is 1.7582  = 1.43 * 0.0006 + 0.0006\n",
      " Objective loss is 1.7574  = 1.43 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 10682.5300  = 1.63 * 3851.1809 + 4394.8877\n",
      " Objective loss is 30.4154  = 1.63 * 10.8757 + 10.9975\n",
      " Objective loss is 4.7298  = 1.63 * 1.1215 + 1.1687\n",
      " Objective loss is 2.1847  = 1.63 * 0.1648 + 0.1678\n",
      " Objective loss is 1.8297  = 1.63 * 0.0285 + 0.0297\n",
      " Objective loss is 1.7702  = 1.63 * 0.0054 + 0.0057\n",
      " Objective loss is 1.7596  = 1.63 * 0.0012 + 0.0012\n",
      " Objective loss is 1.7576  = 1.63 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 11468.4853  = 1.84 * 3851.1809 + 4394.8877\n",
      " Objective loss is 27.4635  = 1.84 * 8.8586 + 9.5206\n",
      " Objective loss is 4.1026  = 1.84 * 0.8182 + 0.8653\n",
      " Objective loss is 2.0628  = 1.84 * 0.1083 + 0.1141\n",
      " Objective loss is 1.8032  = 1.84 * 0.0168 + 0.0180\n",
      " Objective loss is 1.7645  = 1.84 * 0.0029 + 0.0031\n",
      " Objective loss is 1.7584  = 1.84 * 0.0006 + 0.0006\n",
      " Objective loss is 1.7574  = 1.84 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 1.84 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 12254.4406  = 2.04 * 3851.1809 + 4394.8877\n",
      " Objective loss is 23.9975  = 2.04 * 7.2995 + 7.4198\n",
      " Objective loss is 3.6045  = 2.04 * 0.6045 + 0.6328\n",
      " Objective loss is 1.9738  = 2.04 * 0.0717 + 0.0761\n",
      " Objective loss is 1.7858  = 2.04 * 0.0100 + 0.0103\n",
      " Objective loss is 1.7614  = 2.04 * 0.0016 + 0.0017\n",
      " Objective loss is 1.7578  = 2.04 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 2.04 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.04 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 13040.3959  = 2.24 * 3851.1809 + 4394.8877\n",
      " Objective loss is 21.6046  = 2.24 * 6.0208 + 6.3999\n",
      " Objective loss is 3.2202  = 2.24 * 0.4481 + 0.4733\n",
      " Objective loss is 1.9085  = 2.24 * 0.0477 + 0.0490\n",
      " Objective loss is 1.7751  = 2.24 * 0.0060 + 0.0060\n",
      " Objective loss is 1.7595  = 2.24 * 0.0009 + 0.0009\n",
      " Objective loss is 1.7575  = 2.24 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 2.24 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 13826.3511  = 2.45 * 3851.1809 + 4394.8877\n",
      " Objective loss is 19.2613  = 2.45 * 5.0190 + 5.2745\n",
      " Objective loss is 2.9066  = 2.45 * 0.3341 + 0.3450\n",
      " Objective loss is 1.8654  = 2.45 * 0.0318 + 0.0341\n",
      " Objective loss is 1.7686  = 2.45 * 0.0036 + 0.0038\n",
      " Objective loss is 1.7585  = 2.45 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7574  = 2.45 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 14612.3064  = 2.65 * 3851.1809 + 4394.8877\n",
      " Objective loss is 17.1557  = 2.65 * 4.1759 + 4.3754\n",
      " Objective loss is 2.6705  = 2.65 * 0.2490 + 0.2645\n",
      " Objective loss is 1.8333  = 2.65 * 0.0214 + 0.0224\n",
      " Objective loss is 1.7644  = 2.65 * 0.0022 + 0.0023\n",
      " Objective loss is 1.7579  = 2.65 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 2.65 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 15398.2617  = 2.86 * 3851.1809 + 4394.8877\n",
      " Objective loss is 15.5183  = 2.86 * 3.5036 + 3.8016\n",
      " Objective loss is 2.4809  = 2.86 * 0.1871 + 0.1992\n",
      " Objective loss is 1.8110  = 2.86 * 0.0144 + 0.0152\n",
      " Objective loss is 1.7617  = 2.86 * 0.0013 + 0.0014\n",
      " Objective loss is 1.7576  = 2.86 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 2.86 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 16184.2170  = 3.06 * 3851.1809 + 4394.8877\n",
      " Objective loss is 13.8262  = 3.06 * 2.9430 + 3.1055\n",
      " Objective loss is 2.3314  = 3.06 * 0.1411 + 0.1510\n",
      " Objective loss is 1.7956  = 3.06 * 0.0097 + 0.0106\n",
      " Objective loss is 1.7601  = 3.06 * 0.0008 + 0.0009\n",
      " Objective loss is 1.7574  = 3.06 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 16970.1723  = 3.27 * 3851.1809 + 4394.8877\n",
      " Objective loss is 12.4504  = 3.27 * 2.4829 + 2.6277\n",
      " Objective loss is 2.2078  = 3.27 * 0.1063 + 0.1109\n",
      " Objective loss is 1.7842  = 3.27 * 0.0066 + 0.0070\n",
      " Objective loss is 1.7590  = 3.27 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7574  = 3.27 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 17756.1276  = 3.47 * 3851.1809 + 4394.8877\n",
      " Objective loss is 11.1693  = 3.47 * 2.0923 + 2.1912\n",
      " Objective loss is 2.1115  = 3.47 * 0.0805 + 0.0813\n",
      " Objective loss is 1.7764  = 3.47 * 0.0045 + 0.0049\n",
      " Objective loss is 1.7584  = 3.47 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 3.47 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 18542.0829  = 3.67 * 3851.1809 + 4394.8877\n",
      " Objective loss is 10.1169  = 3.67 * 1.7737 + 1.8790\n",
      " Objective loss is 2.0413  = 3.67 * 0.0611 + 0.0651\n",
      " Objective loss is 1.7706  = 3.67 * 0.0031 + 0.0032\n",
      " Objective loss is 1.7579  = 3.67 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 19328.0382  = 3.88 * 3851.1809 + 4394.8877\n",
      " Objective loss is 9.0884  = 3.88 * 1.5080 + 1.5156\n",
      " Objective loss is 1.9825  = 3.88 * 0.0465 + 0.0496\n",
      " Objective loss is 1.7667  = 3.88 * 0.0021 + 0.0022\n",
      " Objective loss is 1.7577  = 3.88 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 20113.9934  = 4.08 * 3851.1809 + 4394.8877\n",
      " Objective loss is 8.3090  = 4.08 * 1.2821 + 1.3479\n",
      " Objective loss is 1.9355  = 4.08 * 0.0355 + 0.0372\n",
      " Objective loss is 1.7639  = 4.08 * 0.0014 + 0.0014\n",
      " Objective loss is 1.7575  = 4.08 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 20899.9487  = 4.29 * 3851.1809 + 4394.8877\n",
      " Objective loss is 7.6088  = 4.29 * 1.0958 + 1.1820\n",
      " Objective loss is 1.8975  = 4.29 * 0.0271 + 0.0277\n",
      " Objective loss is 1.7620  = 4.29 * 0.0010 + 0.0011\n",
      " Objective loss is 1.7574  = 4.29 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 21685.9040  = 4.49 * 3851.1809 + 4394.8877\n",
      " Objective loss is 6.9248  = 4.49 * 0.9358 + 0.9904\n",
      " Objective loss is 1.8688  = 4.49 * 0.0207 + 0.0217\n",
      " Objective loss is 1.7606  = 4.49 * 0.0007 + 0.0008\n",
      " Objective loss is 1.7574  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 22471.8593  = 4.69 * 3851.1809 + 4394.8877\n",
      " Objective loss is 6.3478  = 4.69 * 0.8012 + 0.8522\n",
      " Objective loss is 1.8456  = 4.69 * 0.0159 + 0.0165\n",
      " Objective loss is 1.7596  = 4.69 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 23257.8146  = 4.90 * 3851.1809 + 4394.8877\n",
      " Objective loss is 5.8041  = 4.90 * 0.6847 + 0.7135\n",
      " Objective loss is 1.8274  = 4.90 * 0.0122 + 0.0127\n",
      " Objective loss is 1.7589  = 4.90 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 24043.7699  = 5.10 * 3851.1809 + 4394.8877\n",
      " Objective loss is 5.3460  = 5.10 * 0.5873 + 0.6110\n",
      " Objective loss is 1.8128  = 5.10 * 0.0094 + 0.0097\n",
      " Objective loss is 1.7584  = 5.10 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 24829.7252  = 5.31 * 3851.1809 + 4394.8877\n",
      " Objective loss is 4.9435  = 5.31 * 0.5043 + 0.5276\n",
      " Objective loss is 1.8010  = 5.31 * 0.0072 + 0.0073\n",
      " Objective loss is 1.7581  = 5.31 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 25615.6805  = 5.51 * 3851.1809 + 4394.8877\n",
      " Objective loss is 4.5881  = 5.51 * 0.4349 + 0.4505\n",
      " Objective loss is 1.7921  = 5.51 * 0.0055 + 0.0058\n",
      " Objective loss is 1.7578  = 5.51 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 26401.6357  = 5.71 * 3851.1809 + 4394.8877\n",
      " Objective loss is 4.2546  = 5.71 * 0.3738 + 0.3762\n",
      " Objective loss is 1.7850  = 5.71 * 0.0043 + 0.0046\n",
      " Objective loss is 1.7577  = 5.71 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 27187.5910  = 5.92 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.9865  = 5.92 * 0.3221 + 0.3366\n",
      " Objective loss is 1.7793  = 5.92 * 0.0033 + 0.0036\n",
      " Objective loss is 1.7575  = 5.92 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 27973.5463  = 6.12 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.7521  = 6.12 * 0.2778 + 0.3066\n",
      " Objective loss is 1.7745  = 6.12 * 0.0025 + 0.0026\n",
      " Objective loss is 1.7575  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 28759.5016  = 6.33 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.5166  = 6.33 * 0.2400 + 0.2525\n",
      " Objective loss is 1.7710  = 6.33 * 0.0020 + 0.0021\n",
      " Objective loss is 1.7574  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 29545.4569  = 6.53 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.3214  = 6.53 * 0.2082 + 0.2153\n",
      " Objective loss is 1.7681  = 6.53 * 0.0015 + 0.0016\n",
      " Objective loss is 1.7574  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 30331.4122  = 6.73 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.1463  = 6.73 * 0.1801 + 0.1862\n",
      " Objective loss is 1.7658  = 6.73 * 0.0012 + 0.0012\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 31117.3675  = 6.94 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.9874  = 6.94 * 0.1556 + 0.1596\n",
      " Objective loss is 1.7640  = 6.94 * 0.0009 + 0.0009\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 31903.3228  = 7.14 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.8498  = 7.14 * 0.1348 + 0.1383\n",
      " Objective loss is 1.7626  = 7.14 * 0.0007 + 0.0007\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 32689.2780  = 7.35 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.7294  = 7.35 * 0.1167 + 0.1228\n",
      " Objective loss is 1.7615  = 7.35 * 0.0006 + 0.0006\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 33475.2333  = 7.55 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.6248  = 7.55 * 0.1014 + 0.1090\n",
      " Objective loss is 1.7606  = 7.55 * 0.0004 + 0.0004\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 34261.1886  = 7.76 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.5226  = 7.76 * 0.0880 + 0.0899\n",
      " Objective loss is 1.7599  = 7.76 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 35047.1439  = 7.96 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.4404  = 7.96 * 0.0762 + 0.0824\n",
      " Objective loss is 1.7594  = 7.96 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 35833.0992  = 8.16 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.3625  = 8.16 * 0.0663 + 0.0698\n",
      " Objective loss is 1.7589  = 8.16 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 36619.0545  = 8.37 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.2938  = 8.37 * 0.0577 + 0.0589\n",
      " Objective loss is 1.7586  = 8.37 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 37405.0098  = 8.57 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.2325  = 8.57 * 0.0501 + 0.0503\n",
      " Objective loss is 1.7583  = 8.57 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 38190.9651  = 8.78 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.1822  = 8.78 * 0.0436 + 0.0465\n",
      " Objective loss is 1.7581  = 8.78 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 38976.9203  = 8.98 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.1352  = 8.98 * 0.0380 + 0.0412\n",
      " Objective loss is 1.7579  = 8.98 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 39762.8756  = 9.18 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.0931  = 9.18 * 0.0331 + 0.0359\n",
      " Objective loss is 1.7578  = 9.18 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 40548.8309  = 9.39 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.0555  = 9.39 * 0.0288 + 0.0312\n",
      " Objective loss is 1.7577  = 9.39 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 41334.7862  = 9.59 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.0222  = 9.59 * 0.0251 + 0.0272\n",
      " Objective loss is 1.7576  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 42120.7415  = 9.80 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.9925  = 9.80 * 0.0219 + 0.0235\n",
      " Objective loss is 1.7575  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 42906.6968  = 10.00 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.9667  = 10.00 * 0.0191 + 0.0210\n",
      " Objective loss is 1.7575  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_iter = 2000\n",
    "lambdas = torch.tensor(np.linspace(0, 10.0), requires_grad=False)\n",
    "ols_beta = torch.linalg.lstsq( X, Y ).solution  # regular OLS solution (TODO: regularize this)\n",
    "subgroup_betas = [ torch.linalg.lstsq( group.x, group.y ).solution for group in groups ] # OLS for each group\n",
    "model_betas = list()\n",
    "\n",
    "# Fix beta regularizer to 0.1, vary lambdas\n",
    "for lmbd in lambdas:\n",
    "    # train tradeoff model\n",
    "    model = LinearModel(num_features)\n",
    "    optimize_GD(model, trade_regularization = lmbd, beta_regularization=0.1, max_iter= max_iter)\n",
    "    model_betas.append(model.linear.weight.data.numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do standard OLS with regularization to compare?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
