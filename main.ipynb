{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "num_samples = 300       # per group (total = num_samples * num_groups)\n",
    "num_features = 700\n",
    "num_groups = 3\n",
    "\n",
    "np.random.seed(42)\n",
    "noise_level = 0.1\n",
    "true_beta = np.random.randn( num_features, 1 ) # does not include the identifier weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_structured_covariance(d):\n",
    "    return np.diag( np.random.uniform(0.3, 4, size = d) ** 2 )\n",
    "\n",
    "def identity_covariance(d):\n",
    "    return np.identity( d )\n",
    "\n",
    "def partially_structured_covariace(d):\n",
    "    U = np.random.randn(d,d) / np.sqrt(d)\n",
    "    return np.matmul(U, U.T)\n",
    "\n",
    "def unstructured_covariace(d):\n",
    "    U = np.random.randn(d,d) / np.sqrt(d)\n",
    "    return np.matmul(U, np.matmul(fully_structured_covariance(d), U.T))\n",
    "\n",
    "class Group:\n",
    "\n",
    "    ID = 0\n",
    "\n",
    "    def __init__(self, covariance_generator = lambda: identity_covariance(num_features) ):\n",
    "\n",
    "        self.id = Group.ID \n",
    "        Group.ID += 1\n",
    "\n",
    "        self.cov = covariance_generator()\n",
    "        self.x_dist = stats.multivariate_normal( cov = self.cov )\n",
    "\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    # Generates X (input vars) \n",
    "    def _generate_x(self, n_samples, ID = False , **kwargs):\n",
    "        x = self.x_dist.rvs(size= n_samples, **kwargs)\n",
    "        if ID:\n",
    "            identifier = np.repeat( self.ID , repeats=n_samples)\n",
    "            x = np.column_stack( (identifier, x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.x, self.y\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, value):\n",
    "        x, y = value # unpack\n",
    "        self.x = torch.tensor(x, dtype = torch.float32, requires_grad=False)\n",
    "        self.y = torch.tensor(y, dtype = torch.float32, requires_grad=False)\n",
    "    \n",
    "\n",
    "class Groups:\n",
    "\n",
    "    WEIGHT_HANDLER = stats.beta(1,1).rvs\n",
    "\n",
    "    def __init__(self, num_groups, cov_generator = identity_covariance):\n",
    "\n",
    "        Group.ID = 0\n",
    "        self.groups = [ Group(cov_generator) for _ in range(num_groups) ]\n",
    "\n",
    "        weights = self.WEIGHT_HANDLER(size = num_groups)\n",
    "        weights /= weights.sum()\n",
    "        self.weights = weights\n",
    "\n",
    "        self.x , self.y = None, None\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.groups.__iter__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.groups[index]\n",
    "\n",
    "    def generate(self, n_samples, beta = true_beta):\n",
    "\n",
    "        for group in self.groups:\n",
    "            # Determine number of samples for this group\n",
    "            n_group = self._get_nsample(n_samples, group)\n",
    "\n",
    "            # Create the data for that specific group\n",
    "            x = group._generate_x(n_group)\n",
    "            y = np.dot(x, beta) + noise_level * np.random.randn(n_group, 1)\n",
    "            \n",
    "            group.data = [x, y]\n",
    "    \n",
    "    def _get_nsample(self, n, group):\n",
    "        weights = self.weights\n",
    "        weights = (weights * n).astype(int)\n",
    "        weights[-1] = n - weights[:-1].sum()\n",
    "        return int(weights[group.id])\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        if self.x is None:\n",
    "            self.x = torch.cat( [ group.x for group in self.groups ], dim = 0 )\n",
    "            self.y = torch.cat( [ group.y for group in self.groups ], dim = 0 )\n",
    "        return self.x, self.y\n",
    "\n",
    "    @data.setter\n",
    "    def data(self,value):\n",
    "        raise AttributeError(\"Can't assign data to this object.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, **kwargs) -> None:\n",
    "        super(LinearModel, self).__init__()\n",
    "        # Initialize at zero. \n",
    "        self.linear = torch.nn.Linear( input_dimension, 1, bias = False, **kwargs )\n",
    "        self._initialize(0.0)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _initialize(self, value):\n",
    "        self.linear.weight.fill_(value)\n",
    "        if self.linear.weight.grad is not None:\n",
    "            self.linear.weight.grad.detach_()\n",
    "            self.linear.weight.grad.zero_()\n",
    "    \n",
    "    # forward passes should NOT come from calling this directly!\n",
    "    # i.e. model(x) instead of model.forward(x)\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "    # by default, MSELoss divides by n, the size of sample\n",
    "    def risk(self, x, y):\n",
    "        loss = torch.nn.MSELoss()\n",
    "        mse = loss( self(x) , y )\n",
    "        return mse\n",
    "    \n",
    "# training loop (gradient descent on the balanaced risk: lmbd * std + dro)\n",
    "def optimize_GD(model, X, Y, groups, trade_regularization = 0.1, max_iter = 5000, lr = 1e-3, weight_decay = 0.0, verbose=False):\n",
    "    if trade_regularization > 1:\n",
    "        lmbd_adv = torch.tensor([1.0], requires_grad=False)\n",
    "        lmbd_std = torch.tensor([1 / trade_regularization], requires_grad=False)\n",
    "    else:\n",
    "        lmbd_adv = torch.tensor([trade_regularization], requires_grad=False)\n",
    "        lmbd_std = torch.tensor([1.0], requires_grad=False)\n",
    "\n",
    "    optimizer = torch.optim.SGD( params = model.parameters(), lr = lr, weight_decay = weight_decay )\n",
    "\n",
    "    flag = True         # for convergence criterion (objective low enough)\n",
    "    iteration = 0\n",
    "    while flag and iteration < max_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        standard_risk = model.risk( X, Y )\n",
    "        adversarial_risk = torch.max( torch.stack( [ model.risk(group.x, group.y) for group in groups ] ) )\n",
    "        objective =  standard_risk * lmbd_std + adversarial_risk * lmbd_adv\n",
    "\n",
    "        objective.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 100 == 0 and verbose:\n",
    "            print(f\" Objective loss is {objective.item():.4f} = {lmbd_std.item():.2f} * { standard_risk.item():.4f} + {lmbd_adv.item():.2f} * {adversarial_risk.item():.4f}\")\n",
    "        iteration += 1\n",
    "\n",
    "        # Check convergence\n",
    "        if objective.item() < 1e-4:\n",
    "            flag = False\n",
    "    \n",
    "    if iteration == max_iter:\n",
    "        print(\"Maximum iteration reached.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Objective loss is 4546.8491 = 0.01 * 3920.4954 + 1.00 * 4507.6440\n",
      " Objective loss is 86.1022 = 0.01 * 83.2433 + 1.00 * 85.2698\n",
      " Objective loss is 21.0247 = 0.01 * 19.9931 + 1.00 * 20.8247\n",
      " Objective loss is 7.2654 = 0.01 * 7.0683 + 1.00 * 7.1947\n",
      " Objective loss is 3.1588 = 0.01 * 2.9507 + 1.00 * 3.1293\n",
      " Objective loss is 1.4398 = 0.01 * 1.3710 + 1.00 * 1.4261\n",
      " Objective loss is 0.7005 = 0.01 * 0.6860 + 1.00 * 0.6936\n",
      " Objective loss is 0.3794 = 0.01 * 0.3550 + 1.00 * 0.3758\n",
      " Objective loss is 0.2013 = 0.01 * 0.1910 + 1.00 * 0.1994\n",
      " Objective loss is 0.1079 = 0.01 * 0.1043 + 1.00 * 0.1069\n",
      " Objective loss is 0.0624 = 0.01 * 0.0585 + 1.00 * 0.0618\n",
      " Objective loss is 0.0345 = 0.01 * 0.0328 + 1.00 * 0.0342\n",
      " Objective loss is 0.0201 = 0.01 * 0.0189 + 1.00 * 0.0199\n",
      " Objective loss is 0.0113 = 0.01 * 0.0108 + 1.00 * 0.0112\n",
      " Objective loss is 0.0066 = 0.01 * 0.0063 + 1.00 * 0.0065\n",
      " Objective loss is 0.0038 = 0.01 * 0.0037 + 1.00 * 0.0038\n",
      " Objective loss is 0.0022 = 0.01 * 0.0022 + 1.00 * 0.0022\n",
      " Objective loss is 0.0013 = 0.01 * 0.0013 + 1.00 * 0.0013\n",
      " Objective loss is 0.0008 = 0.01 * 0.0008 + 1.00 * 0.0008\n",
      " Objective loss is 0.0005 = 0.01 * 0.0004 + 1.00 * 0.0005\n",
      " Objective loss is 0.0003 = 0.01 * 0.0003 + 1.00 * 0.0003\n",
      " Objective loss is 0.0002 = 0.01 * 0.0002 + 1.00 * 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Create the data\n",
    "cov_generator = lambda: unstructured_covariace(num_features)\n",
    "groups = Groups(num_groups, cov_generator)\n",
    "\n",
    "# TODO: by this data generating process, we have equal number of groups in the\n",
    "# training data, all disjoint. should we change this up (vary # of samples/gp)?\n",
    "groups.generate(num_samples, beta= true_beta)\n",
    "\n",
    "X , Y = groups.data\n",
    "\n",
    "# Solve the weighted regression problem using vanilla GD\n",
    "max_iter = float('inf')\n",
    "\n",
    "model = LinearModel(num_features)\n",
    "optimize_GD(model, X, Y, groups, trade_regularization = 1e2, lr=1e-3, max_iter= max_iter, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS\n",
    "ols_beta = torch.linalg.lstsq( X, Y ).solution\n",
    "\n",
    "# Subgroups- OLS\n",
    "subgroup_beta = [ torch.linalg.lstsq( group.x, group.y ).solution for group in groups ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "betas = np.hstack( [true_beta, model.linear.weight.data.numpy().T, ols_beta.data.numpy()] + [beta.data.numpy() for beta in subgroup_beta ] )\n",
    "betas = pd.DataFrame( betas, columns=[\"true_beta\", \"model\", \"OLS\"] + [f\"Group {i} OLS\" for i in range(num_groups)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_beta</th>\n",
       "      <th>model</th>\n",
       "      <th>OLS</th>\n",
       "      <th>Group 0 OLS</th>\n",
       "      <th>Group 1 OLS</th>\n",
       "      <th>Group 2 OLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_beta</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.699505</td>\n",
       "      <td>0.699505</td>\n",
       "      <td>0.369453</td>\n",
       "      <td>0.355829</td>\n",
       "      <td>0.458924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.699505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528292</td>\n",
       "      <td>0.509027</td>\n",
       "      <td>0.656233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>0.699505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528272</td>\n",
       "      <td>0.508986</td>\n",
       "      <td>0.656194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group 0 OLS</th>\n",
       "      <td>0.369453</td>\n",
       "      <td>0.528292</td>\n",
       "      <td>0.528272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088858</td>\n",
       "      <td>0.118470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group 1 OLS</th>\n",
       "      <td>0.355829</td>\n",
       "      <td>0.509027</td>\n",
       "      <td>0.508986</td>\n",
       "      <td>0.088858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group 2 OLS</th>\n",
       "      <td>0.458924</td>\n",
       "      <td>0.656233</td>\n",
       "      <td>0.656194</td>\n",
       "      <td>0.118470</td>\n",
       "      <td>0.165822</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             true_beta     model       OLS  Group 0 OLS  Group 1 OLS  \\\n",
       "true_beta     1.000000  0.699505  0.699505     0.369453     0.355829   \n",
       "model         0.699505  1.000000  1.000000     0.528292     0.509027   \n",
       "OLS           0.699505  1.000000  1.000000     0.528272     0.508986   \n",
       "Group 0 OLS   0.369453  0.528292  0.528272     1.000000     0.088858   \n",
       "Group 1 OLS   0.355829  0.509027  0.508986     0.088858     1.000000   \n",
       "Group 2 OLS   0.458924  0.656233  0.656194     0.118470     0.165822   \n",
       "\n",
       "             Group 2 OLS  \n",
       "true_beta       0.458924  \n",
       "model           0.656233  \n",
       "OLS             0.656194  \n",
       "Group 0 OLS     0.118470  \n",
       "Group 1 OLS     0.165822  \n",
       "Group 2 OLS     1.000000  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Varying $\\lambda$ Tradeoff Parameter\n",
    "Our notion of tradeoff risk between DRO and standard risk is controlled by the parameter $\\lambda$. Fully writing out the\n",
    "tradeoff objective, we have:\n",
    "$$\n",
    "\\mathcal{R}_{\\mathrm{trade}}(\\beta; \\lambda) := \\lambda \\mathcal{R}_{\\mathrm{group}}(\\beta) +  \\mathcal{R}_{\\mathrm{std}}(\\beta)\n",
    "= \\lambda \\max_{g \\in \\mathcal{G}} \\mathbb{E}[(X^\\top \\beta - Y)^2 | X \\in g ] +  \\mathbb{E}_{X \\sim \\mathbb{P}_X}\\left[ \\mathbb{E} \\left[ (X^\\top \\beta - Y)^2 \\mid X \\right] \\right],\n",
    "$$\n",
    "where $\\mathbb{P}_g$ is the group distribution for group $g \\in \\mathcal{G}$. The $\\lambda$ parameter controls how much we tradeoff for standard risk in our objective. $\\lambda = 0$ means we are solely optimizing for group DRO. We vary the value of $\\lambda$ and see if this has any effect on the resulting $\\hat{\\beta}$ that our model produces by minimizing $\\hat{\\mathcal{R}}_{\\mathrm{trade}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Objective loss is 4193.0852 = 1.00 * 4193.0342 + 0.00 * 5103.8906\n",
      " Objective loss is 77.0369 = 1.00 * 77.0361 + 0.00 * 79.5078\n",
      " Objective loss is 15.7893 = 1.00 * 15.7891 + 0.00 * 17.8931\n",
      " Objective loss is 4.6580 = 1.00 * 4.6580 + 0.00 * 5.3538\n",
      " Objective loss is 1.6214 = 1.00 * 1.6213 + 0.00 * 1.8299\n",
      " Objective loss is 0.6249 = 1.00 * 0.6249 + 0.00 * 0.6853\n",
      " Objective loss is 0.2582 = 1.00 * 0.2582 + 0.00 * 0.2747\n",
      " Objective loss is 0.1122 = 1.00 * 0.1122 + 0.00 * 0.1212\n",
      " Objective loss is 0.0505 = 1.00 * 0.0505 + 0.00 * 0.0555\n",
      " Objective loss is 0.0233 = 1.00 * 0.0233 + 0.00 * 0.0261\n",
      " Objective loss is 0.0110 = 1.00 * 0.0110 + 0.00 * 0.0125\n",
      " Objective loss is 0.0053 = 1.00 * 0.0053 + 0.00 * 0.0061\n",
      " Objective loss is 0.0026 = 1.00 * 0.0026 + 0.00 * 0.0030\n",
      " Objective loss is 0.0012 = 1.00 * 0.0012 + 0.00 * 0.0015\n",
      " Objective loss is 0.0006 = 1.00 * 0.0006 + 0.00 * 0.0007\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.00 * 0.0004\n",
      " Objective loss is 0.0002 = 1.00 * 0.0002 + 0.00 * 0.0002\n",
      " Objective loss is 4193.1688 = 1.00 * 4193.0342 + 0.00 * 5103.8906\n",
      " Objective loss is 77.0353 = 1.00 * 77.0332 + 0.00 * 79.4986\n",
      " Objective loss is 15.7888 = 1.00 * 15.7884 + 0.00 * 17.8914\n",
      " Objective loss is 4.6578 = 1.00 * 4.6577 + 0.00 * 5.3532\n",
      " Objective loss is 1.6213 = 1.00 * 1.6212 + 0.00 * 1.8296\n",
      " Objective loss is 0.6249 = 1.00 * 0.6248 + 0.00 * 0.6852\n",
      " Objective loss is 0.2582 = 1.00 * 0.2582 + 0.00 * 0.2746\n",
      " Objective loss is 0.1121 = 1.00 * 0.1121 + 0.00 * 0.1212\n",
      " Objective loss is 0.0505 = 1.00 * 0.0505 + 0.00 * 0.0555\n",
      " Objective loss is 0.0233 = 1.00 * 0.0233 + 0.00 * 0.0261\n",
      " Objective loss is 0.0110 = 1.00 * 0.0110 + 0.00 * 0.0125\n",
      " Objective loss is 0.0053 = 1.00 * 0.0053 + 0.00 * 0.0061\n",
      " Objective loss is 0.0026 = 1.00 * 0.0026 + 0.00 * 0.0030\n",
      " Objective loss is 0.0012 = 1.00 * 0.0012 + 0.00 * 0.0015\n",
      " Objective loss is 0.0006 = 1.00 * 0.0006 + 0.00 * 0.0007\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.00 * 0.0004\n",
      " Objective loss is 0.0002 = 1.00 * 0.0002 + 0.00 * 0.0002\n",
      " Objective loss is 4193.3890 = 1.00 * 4193.0342 + 0.00 * 5103.8906\n",
      " Objective loss is 77.0312 = 1.00 * 77.0256 + 0.00 * 79.4745\n",
      " Objective loss is 15.7876 = 1.00 * 15.7863 + 0.00 * 17.8872\n",
      " Objective loss is 4.6573 = 1.00 * 4.6569 + 0.00 * 5.3513\n",
      " Objective loss is 1.6210 = 1.00 * 1.6209 + 0.00 * 1.8288\n",
      " Objective loss is 0.6247 = 1.00 * 0.6247 + 0.00 * 0.6849\n",
      " Objective loss is 0.2582 = 1.00 * 0.2581 + 0.00 * 0.2745\n",
      " Objective loss is 0.1121 = 1.00 * 0.1121 + 0.00 * 0.1212\n",
      " Objective loss is 0.0505 = 1.00 * 0.0505 + 0.00 * 0.0555\n",
      " Objective loss is 0.0233 = 1.00 * 0.0233 + 0.00 * 0.0261\n",
      " Objective loss is 0.0110 = 1.00 * 0.0110 + 0.00 * 0.0125\n",
      " Objective loss is 0.0053 = 1.00 * 0.0053 + 0.00 * 0.0061\n",
      " Objective loss is 0.0026 = 1.00 * 0.0026 + 0.00 * 0.0030\n",
      " Objective loss is 0.0012 = 1.00 * 0.0012 + 0.00 * 0.0015\n",
      " Objective loss is 0.0006 = 1.00 * 0.0006 + 0.00 * 0.0007\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.00 * 0.0004\n",
      " Objective loss is 0.0002 = 1.00 * 0.0002 + 0.00 * 0.0002\n",
      " Objective loss is 4193.9697 = 1.00 * 4193.0342 + 0.00 * 5103.8906\n",
      " Objective loss is 77.0202 = 1.00 * 77.0057 + 0.00 * 79.4110\n",
      " Objective loss is 15.7843 = 1.00 * 15.7810 + 0.00 * 17.8760\n",
      " Objective loss is 4.6559 = 1.00 * 4.6549 + 0.00 * 5.3466\n",
      " Objective loss is 1.6204 = 1.00 * 1.6200 + 0.00 * 1.8269\n",
      " Objective loss is 0.6245 = 1.00 * 0.6243 + 0.00 * 0.6840\n",
      " Objective loss is 0.2580 = 1.00 * 0.2580 + 0.00 * 0.2742\n",
      " Objective loss is 0.1121 = 1.00 * 0.1120 + 0.00 * 0.1211\n",
      " Objective loss is 0.0504 = 1.00 * 0.0504 + 0.00 * 0.0554\n",
      " Objective loss is 0.0233 = 1.00 * 0.0233 + 0.00 * 0.0260\n",
      " Objective loss is 0.0110 = 1.00 * 0.0110 + 0.00 * 0.0125\n",
      " Objective loss is 0.0053 = 1.00 * 0.0053 + 0.00 * 0.0061\n",
      " Objective loss is 0.0025 = 1.00 * 0.0025 + 0.00 * 0.0030\n",
      " Objective loss is 0.0012 = 1.00 * 0.0012 + 0.00 * 0.0015\n",
      " Objective loss is 0.0006 = 1.00 * 0.0006 + 0.00 * 0.0007\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.00 * 0.0004\n",
      " Objective loss is 0.0002 = 1.00 * 0.0002 + 0.00 * 0.0002\n",
      " Objective loss is 4195.5009 = 1.00 * 4193.0342 + 0.00 * 5103.8906\n",
      " Objective loss is 76.9914 = 1.00 * 76.9531 + 0.00 * 79.2437\n",
      " Objective loss is 15.7756 = 1.00 * 15.7669 + 0.00 * 17.8463\n",
      " Objective loss is 4.6521 = 1.00 * 4.6495 + 0.00 * 5.3339\n",
      " Objective loss is 1.6187 = 1.00 * 1.6178 + 0.00 * 1.8217\n",
      " Objective loss is 0.6237 = 1.00 * 0.6234 + 0.00 * 0.6819\n",
      " Objective loss is 0.2577 = 1.00 * 0.2575 + 0.00 * 0.2739\n",
      " Objective loss is 0.1119 = 1.00 * 0.1118 + 0.00 * 0.1208\n",
      " Objective loss is 0.0504 = 1.00 * 0.0503 + 0.00 * 0.0553\n",
      " Objective loss is 0.0233 = 1.00 * 0.0233 + 0.00 * 0.0260\n",
      " Objective loss is 0.0110 = 1.00 * 0.0110 + 0.00 * 0.0124\n",
      " Objective loss is 0.0053 = 1.00 * 0.0052 + 0.00 * 0.0060\n",
      " Objective loss is 0.0025 = 1.00 * 0.0025 + 0.00 * 0.0030\n",
      " Objective loss is 0.0012 = 1.00 * 0.0012 + 0.00 * 0.0015\n",
      " Objective loss is 0.0006 = 1.00 * 0.0006 + 0.00 * 0.0007\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.00 * 0.0004\n",
      " Objective loss is 0.0002 = 1.00 * 0.0002 + 0.00 * 0.0002\n",
      " Objective loss is 4199.5379 = 1.00 * 4193.0342 + 0.00 * 5103.8906\n",
      " Objective loss is 76.9156 = 1.00 * 76.8152 + 0.00 * 78.8047\n",
      " Objective loss is 15.7526 = 1.00 * 15.7299 + 0.00 * 17.7680\n",
      " Objective loss is 4.6422 = 1.00 * 4.6354 + 0.00 * 5.3008\n",
      " Objective loss is 1.6143 = 1.00 * 1.6120 + 0.00 * 1.8081\n",
      " Objective loss is 0.6217 = 1.00 * 0.6208 + 0.00 * 0.6761\n",
      " Objective loss is 0.2567 = 1.00 * 0.2564 + 0.00 * 0.2729\n",
      " Objective loss is 0.1114 = 1.00 * 0.1113 + 0.00 * 0.1200\n",
      " Objective loss is 0.0501 = 1.00 * 0.0501 + 0.00 * 0.0548\n",
      " Objective loss is 0.0232 = 1.00 * 0.0231 + 0.00 * 0.0257\n",
      " Objective loss is 0.0109 = 1.00 * 0.0109 + 0.00 * 0.0123\n",
      " Objective loss is 0.0052 = 1.00 * 0.0052 + 0.00 * 0.0060\n",
      " Objective loss is 0.0025 = 1.00 * 0.0025 + 0.00 * 0.0029\n",
      " Objective loss is 0.0012 = 1.00 * 0.0012 + 0.00 * 0.0015\n",
      " Objective loss is 0.0006 = 1.00 * 0.0006 + 0.00 * 0.0007\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.00 * 0.0004\n",
      " Objective loss is 0.0001 = 1.00 * 0.0001 + 0.00 * 0.0002\n",
      " Objective loss is 4210.1823 = 1.00 * 4193.0342 + 0.00 * 5103.8906\n",
      " Objective loss is 76.7177 = 1.00 * 76.4563 + 0.00 * 77.8034\n",
      " Objective loss is 15.6921 = 1.00 * 15.6331 + 0.00 * 17.5579\n",
      " Objective loss is 4.6161 = 1.00 * 4.5986 + 0.00 * 5.2136\n",
      " Objective loss is 1.6027 = 1.00 * 1.5968 + 0.00 * 1.7726\n",
      " Objective loss is 0.6164 = 1.00 * 0.6142 + 0.00 * 0.6613\n",
      " Objective loss is 0.2543 = 1.00 * 0.2534 + 0.00 * 0.2691\n",
      " Objective loss is 0.1103 = 1.00 * 0.1099 + 0.00 * 0.1179\n",
      " Objective loss is 0.0496 = 1.00 * 0.0494 + 0.00 * 0.0537\n",
      " Objective loss is 0.0229 = 1.00 * 0.0228 + 0.00 * 0.0252\n",
      " Objective loss is 0.0108 = 1.00 * 0.0107 + 0.00 * 0.0120\n",
      " Objective loss is 0.0051 = 1.00 * 0.0051 + 0.00 * 0.0058\n",
      " Objective loss is 0.0025 = 1.00 * 0.0025 + 0.00 * 0.0029\n",
      " Objective loss is 0.0012 = 1.00 * 0.0012 + 0.00 * 0.0014\n",
      " Objective loss is 0.0006 = 1.00 * 0.0006 + 0.00 * 0.0007\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.00 * 0.0003\n",
      " Objective loss is 0.0001 = 1.00 * 0.0001 + 0.00 * 0.0002\n",
      " Objective loss is 4238.2479 = 1.00 * 4193.0342 + 0.01 * 5103.8906\n",
      " Objective loss is 76.2398 = 1.00 * 75.5569 + 0.01 * 77.0818\n",
      " Objective loss is 15.5334 = 1.00 * 15.3829 + 0.01 * 16.9908\n",
      " Objective loss is 4.5482 = 1.00 * 4.5040 + 0.01 * 4.9870\n",
      " Objective loss is 1.5729 = 1.00 * 1.5580 + 0.01 * 1.6817\n",
      " Objective loss is 0.6030 = 1.00 * 0.5974 + 0.01 * 0.6334\n",
      " Objective loss is 0.2481 = 1.00 * 0.2458 + 0.01 * 0.2590\n",
      " Objective loss is 0.1073 = 1.00 * 0.1063 + 0.01 * 0.1122\n",
      " Objective loss is 0.0481 = 1.00 * 0.0476 + 0.01 * 0.0508\n",
      " Objective loss is 0.0221 = 1.00 * 0.0219 + 0.01 * 0.0237\n",
      " Objective loss is 0.0104 = 1.00 * 0.0103 + 0.01 * 0.0112\n",
      " Objective loss is 0.0049 = 1.00 * 0.0049 + 0.01 * 0.0054\n",
      " Objective loss is 0.0024 = 1.00 * 0.0024 + 0.01 * 0.0026\n",
      " Objective loss is 0.0012 = 1.00 * 0.0011 + 0.01 * 0.0013\n",
      " Objective loss is 0.0006 = 1.00 * 0.0006 + 0.01 * 0.0006\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.01 * 0.0003\n",
      " Objective loss is 0.0001 = 1.00 * 0.0001 + 0.01 * 0.0002\n",
      " Objective loss is 4312.2468 = 1.00 * 4193.0342 + 0.02 * 5103.8906\n",
      " Objective loss is 75.0801 = 1.00 * 73.3537 + 0.02 * 73.9118\n",
      " Objective loss is 15.1261 = 1.00 * 14.7635 + 0.02 * 15.5236\n",
      " Objective loss is 4.3781 = 1.00 * 4.2733 + 0.02 * 4.4864\n",
      " Objective loss is 1.5000 = 1.00 * 1.4641 + 0.02 * 1.5380\n",
      " Objective loss is 0.5704 = 1.00 * 0.5568 + 0.02 * 0.5810\n",
      " Objective loss is 0.2329 = 1.00 * 0.2274 + 0.02 * 0.2354\n",
      " Objective loss is 0.1000 = 1.00 * 0.0976 + 0.02 * 0.1006\n",
      " Objective loss is 0.0445 = 1.00 * 0.0434 + 0.02 * 0.0444\n",
      " Objective loss is 0.0203 = 1.00 * 0.0198 + 0.02 * 0.0203\n",
      " Objective loss is 0.0094 = 1.00 * 0.0092 + 0.02 * 0.0095\n",
      " Objective loss is 0.0045 = 1.00 * 0.0044 + 0.02 * 0.0045\n",
      " Objective loss is 0.0021 = 1.00 * 0.0021 + 0.02 * 0.0022\n",
      " Objective loss is 0.0010 = 1.00 * 0.0010 + 0.02 * 0.0011\n",
      " Objective loss is 0.0005 = 1.00 * 0.0005 + 0.02 * 0.0005\n",
      " Objective loss is 0.0002 = 1.00 * 0.0002 + 0.02 * 0.0003\n",
      " Objective loss is 0.0001 = 1.00 * 0.0001 + 0.02 * 0.0001\n",
      " Objective loss is 4507.3564 = 1.00 * 4193.0342 + 0.06 * 5103.8906\n",
      " Objective loss is 72.2079 = 1.00 * 68.0147 + 0.06 * 68.0882\n",
      " Objective loss is 14.1417 = 1.00 * 13.3147 + 0.06 * 13.4280\n",
      " Objective loss is 3.9842 = 1.00 * 3.7505 + 0.06 * 3.7947\n",
      " Objective loss is 1.3317 = 1.00 * 1.2543 + 0.06 * 1.2569\n",
      " Objective loss is 0.4954 = 1.00 * 0.4665 + 0.06 * 0.4698\n",
      " Objective loss is 0.1981 = 1.00 * 0.1865 + 0.06 * 0.1875\n",
      " Objective loss is 0.0833 = 1.00 * 0.0785 + 0.06 * 0.0788\n",
      " Objective loss is 0.0363 = 1.00 * 0.0342 + 0.06 * 0.0343\n",
      " Objective loss is 0.0162 = 1.00 * 0.0153 + 0.06 * 0.0153\n",
      " Objective loss is 0.0074 = 1.00 * 0.0070 + 0.06 * 0.0070\n",
      " Objective loss is 0.0034 = 1.00 * 0.0032 + 0.06 * 0.0032\n",
      " Objective loss is 0.0016 = 1.00 * 0.0015 + 0.06 * 0.0015\n",
      " Objective loss is 0.0007 = 1.00 * 0.0007 + 0.06 * 0.0007\n",
      " Objective loss is 0.0004 = 1.00 * 0.0003 + 0.06 * 0.0003\n",
      " Objective loss is 0.0002 = 1.00 * 0.0002 + 0.06 * 0.0002\n",
      " Objective loss is 5021.7921 = 1.00 * 4193.0342 + 0.16 * 5103.8906\n",
      " Objective loss is 65.4299 = 1.00 * 56.2459 + 0.16 * 56.5596\n",
      " Objective loss is 11.9000 = 1.00 * 10.2279 + 0.16 * 10.2976\n",
      " Objective loss is 3.1340 = 1.00 * 2.6923 + 0.16 * 2.7206\n",
      " Objective loss is 0.9860 = 1.00 * 0.8473 + 0.16 * 0.8538\n",
      " Objective loss is 0.3463 = 1.00 * 0.2976 + 0.16 * 0.3002\n",
      " Objective loss is 0.1309 = 1.00 * 0.1125 + 0.16 * 0.1132\n",
      " Objective loss is 0.0520 = 1.00 * 0.0447 + 0.16 * 0.0451\n",
      " Objective loss is 0.0214 = 1.00 * 0.0184 + 0.16 * 0.0185\n",
      " Objective loss is 0.0090 = 1.00 * 0.0077 + 0.16 * 0.0078\n",
      " Objective loss is 0.0039 = 1.00 * 0.0033 + 0.16 * 0.0033\n",
      " Objective loss is 0.0017 = 1.00 * 0.0014 + 0.16 * 0.0014\n",
      " Objective loss is 0.0007 = 1.00 * 0.0006 + 0.16 * 0.0006\n",
      " Objective loss is 0.0003 = 1.00 * 0.0003 + 0.16 * 0.0003\n",
      " Objective loss is 0.0001 = 1.00 * 0.0001 + 0.16 * 0.0001\n",
      " Objective loss is 6378.1794 = 1.00 * 4193.0342 + 0.43 * 5103.8906\n",
      " Objective loss is 50.9439 = 1.00 * 35.5613 + 0.43 * 35.9295\n",
      " Objective loss is 7.6409 = 1.00 * 5.3273 + 0.43 * 5.4039\n",
      " Objective loss is 1.6915 = 1.00 * 1.1814 + 0.43 * 1.1914\n",
      " Objective loss is 0.4567 = 1.00 * 0.3185 + 0.43 * 0.3228\n",
      " Objective loss is 0.1386 = 1.00 * 0.0963 + 0.43 * 0.0988\n",
      " Objective loss is 0.0450 = 1.00 * 0.0313 + 0.43 * 0.0320\n",
      " Objective loss is 0.0153 = 1.00 * 0.0106 + 0.43 * 0.0109\n",
      " Objective loss is 0.0054 = 1.00 * 0.0037 + 0.43 * 0.0038\n",
      " Objective loss is 0.0019 = 1.00 * 0.0013 + 0.43 * 0.0014\n",
      " Objective loss is 0.0007 = 1.00 * 0.0005 + 0.43 * 0.0005\n",
      " Objective loss is 0.0003 = 1.00 * 0.0002 + 0.43 * 0.0002\n",
      " Objective loss is 8818.3604 = 0.89 * 4193.0342 + 1.00 * 5103.8906\n",
      " Objective loss is 34.4376 = 0.89 * 17.4175 + 1.00 * 19.0081\n",
      " Objective loss is 3.5696 = 0.89 * 1.8824 + 1.00 * 1.9020\n",
      " Objective loss is 0.6110 = 0.89 * 0.3149 + 1.00 * 0.3321\n",
      " Objective loss is 0.1283 = 0.89 * 0.0649 + 1.00 * 0.0708\n",
      " Objective loss is 0.0296 = 0.89 * 0.0150 + 1.00 * 0.0164\n",
      " Objective loss is 0.0071 = 0.89 * 0.0037 + 1.00 * 0.0038\n",
      " Objective loss is 0.0018 = 0.89 * 0.0009 + 1.00 * 0.0010\n",
      " Objective loss is 0.0005 = 0.89 * 0.0002 + 1.00 * 0.0003\n",
      " Objective loss is 0.0001 = 0.89 * 0.0001 + 1.00 * 0.0001\n",
      " Objective loss is 6512.6739 = 0.34 * 4193.0342 + 1.00 * 5103.8906\n",
      " Objective loss is 54.7410 = 0.34 * 39.7865 + 1.00 * 41.3735\n",
      " Objective loss is 8.7284 = 0.34 * 6.2998 + 1.00 * 6.6118\n",
      " Objective loss is 2.0383 = 0.34 * 1.4556 + 1.00 * 1.5493\n",
      " Objective loss is 0.5679 = 0.34 * 0.4082 + 1.00 * 0.4307\n",
      " Objective loss is 0.1739 = 0.34 * 0.1283 + 1.00 * 0.1308\n",
      " Objective loss is 0.0596 = 0.34 * 0.0434 + 1.00 * 0.0450\n",
      " Objective loss is 0.0210 = 0.34 * 0.0154 + 1.00 * 0.0158\n",
      " Objective loss is 0.0078 = 0.34 * 0.0057 + 1.00 * 0.0059\n",
      " Objective loss is 0.0029 = 0.34 * 0.0021 + 1.00 * 0.0022\n",
      " Objective loss is 0.0011 = 0.34 * 0.0008 + 1.00 * 0.0008\n",
      " Objective loss is 0.0004 = 0.34 * 0.0003 + 1.00 * 0.0003\n",
      " Objective loss is 0.0002 = 0.34 * 0.0001 + 1.00 * 0.0001\n",
      " Objective loss is 5638.1985 = 0.13 * 4193.0342 + 1.00 * 5103.8906\n",
      " Objective loss is 66.9219 = 0.13 * 57.1584 + 1.00 * 59.6384\n",
      " Objective loss is 12.1764 = 0.13 * 10.4753 + 1.00 * 10.8416\n",
      " Objective loss is 3.1584 = 0.13 * 2.7715 + 1.00 * 2.8053\n",
      " Objective loss is 1.0147 = 0.13 * 0.8777 + 1.00 * 0.9029\n",
      " Objective loss is 0.3522 = 0.13 * 0.3095 + 1.00 * 0.3127\n",
      " Objective loss is 0.1410 = 0.13 * 0.1179 + 1.00 * 0.1260\n",
      " Objective loss is 0.0550 = 0.13 * 0.0472 + 1.00 * 0.0490\n",
      " Objective loss is 0.0236 = 0.13 * 0.0194 + 1.00 * 0.0211\n",
      " Objective loss is 0.0094 = 0.13 * 0.0082 + 1.00 * 0.0084\n",
      " Objective loss is 0.0042 = 0.13 * 0.0036 + 1.00 * 0.0037\n",
      " Objective loss is 0.0018 = 0.13 * 0.0016 + 1.00 * 0.0016\n",
      " Objective loss is 0.0008 = 0.13 * 0.0007 + 1.00 * 0.0007\n",
      " Objective loss is 0.0004 = 0.13 * 0.0003 + 1.00 * 0.0003\n",
      " Objective loss is 0.0002 = 0.13 * 0.0001 + 1.00 * 0.0001\n",
      " Objective loss is 5306.5370 = 0.05 * 4193.0342 + 1.00 * 5103.8906\n",
      " Objective loss is 73.8555 = 0.05 * 66.3101 + 1.00 * 70.6508\n",
      " Objective loss is 14.2104 = 0.05 * 12.7947 + 1.00 * 13.5921\n",
      " Objective loss is 4.0488 = 0.05 * 3.5962 + 1.00 * 3.8750\n",
      " Objective loss is 1.2978 = 0.05 * 1.1868 + 1.00 * 1.2404\n",
      " Objective loss is 0.4805 = 0.05 * 0.4393 + 1.00 * 0.4593\n",
      " Objective loss is 0.1928 = 0.05 * 0.1742 + 1.00 * 0.1844\n",
      " Objective loss is 0.0820 = 0.05 * 0.0729 + 1.00 * 0.0785\n",
      " Objective loss is 0.0339 = 0.05 * 0.0316 + 1.00 * 0.0324\n",
      " Objective loss is 0.0160 = 0.05 * 0.0140 + 1.00 * 0.0153\n",
      " Objective loss is 0.0067 = 0.05 * 0.0063 + 1.00 * 0.0064\n",
      " Objective loss is 0.0032 = 0.05 * 0.0029 + 1.00 * 0.0031\n",
      " Objective loss is 0.0015 = 0.05 * 0.0013 + 1.00 * 0.0014\n",
      " Objective loss is 0.0007 = 0.05 * 0.0006 + 1.00 * 0.0007\n",
      " Objective loss is 0.0003 = 0.05 * 0.0003 + 1.00 * 0.0003\n",
      " Objective loss is 0.0002 = 0.05 * 0.0001 + 1.00 * 0.0002\n",
      " Objective loss is 5180.7481 = 0.02 * 4193.0342 + 1.00 * 5103.8906\n",
      " Objective loss is 76.1347 = 0.02 * 69.7940 + 1.00 * 74.8554\n",
      " Objective loss is 14.6392 = 0.02 * 13.8528 + 1.00 * 14.3852\n",
      " Objective loss is 4.3127 = 0.02 * 3.9517 + 1.00 * 4.2403\n",
      " Objective loss is 1.3927 = 0.02 * 1.3361 + 1.00 * 1.3682\n",
      " Objective loss is 0.5477 = 0.02 * 0.5015 + 1.00 * 0.5385\n",
      " Objective loss is 0.2200 = 0.02 * 0.2027 + 1.00 * 0.2162\n",
      " Objective loss is 0.0942 = 0.02 * 0.0860 + 1.00 * 0.0926\n",
      " Objective loss is 0.0404 = 0.02 * 0.0379 + 1.00 * 0.0397\n",
      " Objective loss is 0.0183 = 0.02 * 0.0171 + 1.00 * 0.0180\n",
      " Objective loss is 0.0084 = 0.02 * 0.0079 + 1.00 * 0.0083\n",
      " Objective loss is 0.0040 = 0.02 * 0.0037 + 1.00 * 0.0040\n",
      " Objective loss is 0.0019 = 0.02 * 0.0017 + 1.00 * 0.0018\n",
      " Objective loss is 0.0008 = 0.02 * 0.0008 + 1.00 * 0.0008\n",
      " Objective loss is 0.0004 = 0.02 * 0.0004 + 1.00 * 0.0004\n",
      " Objective loss is 0.0002 = 0.02 * 0.0002 + 1.00 * 0.0002\n",
      " Objective loss is 5133.0403 = 0.01 * 4193.0342 + 1.00 * 5103.8906\n",
      " Objective loss is 76.5025 = 0.01 * 71.3453 + 1.00 * 76.0065\n",
      " Objective loss is 14.8989 = 0.01 * 14.2808 + 1.00 * 14.7996\n",
      " Objective loss is 4.4099 = 0.01 * 4.1051 + 1.00 * 4.3814\n",
      " Objective loss is 1.4305 = 0.01 * 1.3980 + 1.00 * 1.4208\n",
      " Objective loss is 0.5682 = 0.01 * 0.5280 + 1.00 * 0.5645\n",
      " Objective loss is 0.2312 = 0.01 * 0.2148 + 1.00 * 0.2297\n",
      " Objective loss is 0.0988 = 0.01 * 0.0917 + 1.00 * 0.0982\n",
      " Objective loss is 0.0430 = 0.01 * 0.0407 + 1.00 * 0.0428\n",
      " Objective loss is 0.0190 = 0.01 * 0.0185 + 1.00 * 0.0189\n",
      " Objective loss is 0.0090 = 0.01 * 0.0086 + 1.00 * 0.0090\n",
      " Objective loss is 0.0044 = 0.01 * 0.0040 + 1.00 * 0.0044\n",
      " Objective loss is 0.0020 = 0.01 * 0.0019 + 1.00 * 0.0019\n",
      " Objective loss is 0.0010 = 0.01 * 0.0009 + 1.00 * 0.0009\n",
      " Objective loss is 0.0005 = 0.01 * 0.0004 + 1.00 * 0.0005\n",
      " Objective loss is 0.0002 = 0.01 * 0.0002 + 1.00 * 0.0002\n",
      " Objective loss is 0.0001 = 0.01 * 0.0001 + 1.00 * 0.0001\n",
      " Objective loss is 5114.9462 = 0.00 * 4193.0342 + 1.00 * 5103.8906\n",
      " Objective loss is 76.7777 = 0.00 * 71.9460 + 1.00 * 76.5880\n",
      " Objective loss is 14.8298 = 0.00 * 14.4518 + 1.00 * 14.7917\n",
      " Objective loss is 4.4462 = 0.00 * 4.1650 + 1.00 * 4.4353\n",
      " Objective loss is 1.4482 = 0.00 * 1.4223 + 1.00 * 1.4445\n",
      " Objective loss is 0.5772 = 0.00 * 0.5385 + 1.00 * 0.5757\n",
      " Objective loss is 0.2360 = 0.00 * 0.2196 + 1.00 * 0.2354\n",
      " Objective loss is 0.1001 = 0.00 * 0.0940 + 1.00 * 0.0999\n",
      " Objective loss is 0.0441 = 0.00 * 0.0418 + 1.00 * 0.0440\n",
      " Objective loss is 0.0193 = 0.00 * 0.0191 + 1.00 * 0.0192\n",
      " Objective loss is 0.0093 = 0.00 * 0.0089 + 1.00 * 0.0093\n",
      " Objective loss is 0.0045 = 0.00 * 0.0042 + 1.00 * 0.0045\n",
      " Objective loss is 0.0020 = 0.00 * 0.0020 + 1.00 * 0.0020\n",
      " Objective loss is 0.0010 = 0.00 * 0.0010 + 1.00 * 0.0010\n",
      " Objective loss is 0.0005 = 0.00 * 0.0005 + 1.00 * 0.0005\n",
      " Objective loss is 0.0002 = 0.00 * 0.0002 + 1.00 * 0.0002\n",
      " Objective loss is 0.0001 = 0.00 * 0.0001 + 1.00 * 0.0001\n",
      " Objective loss is 5108.0837 = 0.00 * 4193.0342 + 1.00 * 5103.8906\n",
      " Objective loss is 76.8823 = 0.00 * 72.1756 + 1.00 * 76.8101\n",
      " Objective loss is 14.8675 = 0.00 * 14.5153 + 1.00 * 14.8530\n",
      " Objective loss is 4.4461 = 0.00 * 4.1883 + 1.00 * 4.4419\n",
      " Objective loss is 1.4623 = 0.00 * 1.4319 + 1.00 * 1.4609\n",
      " Objective loss is 0.5791 = 0.00 * 0.5425 + 1.00 * 0.5785\n",
      " Objective loss is 0.2373 = 0.00 * 0.2215 + 1.00 * 0.2371\n",
      " Objective loss is 0.1008 = 0.00 * 0.0949 + 1.00 * 0.1007\n",
      " Objective loss is 0.0445 = 0.00 * 0.0422 + 1.00 * 0.0445\n",
      " Objective loss is 0.0194 = 0.00 * 0.0193 + 1.00 * 0.0194\n",
      " Objective loss is 0.0094 = 0.00 * 0.0090 + 1.00 * 0.0094\n",
      " Objective loss is 0.0046 = 0.00 * 0.0042 + 1.00 * 0.0045\n",
      " Objective loss is 0.0020 = 0.00 * 0.0020 + 1.00 * 0.0020\n",
      " Objective loss is 0.0010 = 0.00 * 0.0010 + 1.00 * 0.0010\n",
      " Objective loss is 0.0005 = 0.00 * 0.0005 + 1.00 * 0.0005\n",
      " Objective loss is 0.0002 = 0.00 * 0.0002 + 1.00 * 0.0002\n",
      " Objective loss is 0.0001 = 0.00 * 0.0001 + 1.00 * 0.0001\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_iter = 5000\n",
    "lambdas = np.logspace(-5, 3, 20)\n",
    "model_betas = list()\n",
    "\n",
    "for lmbd in lambdas:\n",
    "    # train tradeoff model\n",
    "    model = LinearModel(num_features)\n",
    "    optimize_GD(model, X, Y, groups, trade_regularization = lmbd, lr = 1e-3,max_iter= max_iter, verbose=True)\n",
    "    model_betas.append(model.linear.weight.data.numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$\\\\| \\\\beta_{\\\\mathrm{trade}} - \\\\beta_{\\\\mathrm{OLS}} \\\\|_2$')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAG2CAYAAACu3oj0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABg6UlEQVR4nO3de1xUdf4/8NdcmBnuiMhVBCwU73gJwuuWtNS6Fq1bapbm8lN3VzfTWsvy8s3apcx2/VqWq7tbbavp2rfLrimbYmUmoaKUV5RERXRARIabwMycz+8PmGOTqCDDnJnh9Xw85oGc8zln3sOI8/JzPufzUQkhBIiIiIiow6mVLoCIiIios2DwIiIiInISBi8iIiIiJ2HwIiIiInISBi8iIiIiJ2HwIiIiInISBi8iIiIiJ2HwIiIiInISrdIF0FWSJOH8+fPw9/eHSqVSuhwiIiJqBSEEqqurERkZCbX6xn1aDF4u5Pz584iOjla6DCIiIroFxcXF6N69+w3bMHi5EH9/fwBNb1xAQIDC1RAREVFrVFVVITo6Wv4cvxEGLxdiu7wYEBDA4EVERORmWjNMiIPriYiIiJyEwYuIiIjISRi8iIiIiJyEwYuIiIjISRi8iIiIiJyEwYuIiIjISRi8iIiIiJyEwYuIiIjISRi8iIiIiJyEwYuIiIjISRi8iIiIiJyEwYuIiIjISbhIdidwpdGK4st1UKFpAU+VClABUMt/bv6qat5vtw+Aqvn75uPVzceg+RjbPo1a1fRQqaBW33yhUE9gtkqorDPjcl0jLtc24nJdIypqr35fUdcIU50Zei81Ar116OLjhS4+OgQ2f+3i44UgHy8E+egQ5O0FrYb/FyIi8mQMXp3A0QtVmPDWHqc+p0oFaNUqqFWqq4FMrZK3adVN4czuq0oFraYpuP3wmKbj1DB4qWHw0kCvbfpq8NLAoFVDb/uzlxoG7Q/+bNdWDf2P9nn9KOS0JkRV1plRIe9rRHW9xaE/N3+9FkG+zeHM+2o4C/S5GtpsQa1L81d/vRZmSUJ9o4QrZmvTo7Hpa/0P/tzS9w1m6Yb76xutMOg0GNOrG+7pG4Y7YoOv+bkREVHrMXh1Alq1CsG+OgghIABIUtNXCEBq3iYEICAgiabttj+LH+xvCyEAs7X5ZC5Ko1bB0BzMGq3SLYcolQoI9PZCsI8OXXx1clgK9m36PsjbCw2Wq6Gusq4Rl+vMqLxibvpzbSOqmp+7usGC6gYLiiuuOPKlttupi7V4++vTCDBocVdCKO7pG4YxvbrB3+CldGlERG5FJURbP1Kpo1RVVSEwMBAmkwkBAQFKl3MNIURzQGsObM0BTYimoGUVAlargFUIWCQJkgT7r0LAIglYr/do3i9JP/oqBBotEhosEurNVvlr06P5zz/a12DbZ7Fv12CRbvgabxaibL1Owb46BDV/DfT2gqadl1atkoDpii2Yma+Gs+bvL9c1/iCoNW+/YkZdo9XuPBq1Cj5eGhh0Gnh7NT2a/qxu+l6naeoV/MF+b11TT2DTn5vaGX6w73xlPbKPlSL7eBkqahvl5/LSqHBnz664p28YUvuEITLIu10/AyIid9WWz28GLxfi6sHLEwghfhDcbKHNCq1a7bAQ5Uz1ZitqGizQaZsCU0deBrRKAgfPXsb2Y6XYfrQUpy7W2u3vFxkgh7B+kQFQqdzn50hE1B4MXm6KwYvcyfcXa7DjaCl2HCvF/jOX7S5HRwYakNocwu7s2RU6LceFEZHnYvByUwxe5K4u1TRg5/EybD9aiq9OluOK+eolUD+9FmN6d8M9fcJwV+9QBPpwXBgReRYGLzfF4EWeoN5sxZ7vy7H9aCl2HCvDxeoGeZ9GrUJSbDBS+4bhp33DEB3so2ClRESOweDlphi8yNNIksC35yqx41gpdhwtQ0Fptd3+3mH+GDcwApPuiEZogEGhKomI2ofBy00xeJGnO3OpFjuOlWH7USP2nb4Mq9T0z49WrcK9/cMxNSUWd8R24cB8InIrDF5uisGLOpPKukZkHyvD+3vPYv+Zy/L2hHB/TE2JRfrgSPjoONUgEbk+Bi83xeBFndWR8ya8l3MGH+eXoN7cNNeav0GLh4ZG47GUGMSF+CpcIRHR9TF4uSkGL+rsTHVmbM4rxnvfnMGZS3Xy9lHxIZiaEou7E0Ldap41IuocGLzcFIMXURNJEth18iLeyzmDnQVl8hxhUUHeePTOGEy8IxrBvjpliyQityKEwO7CcvjoNBgaE+zQczN4uSkGL6Jrnb1Uh/W5Z7BpfzEq68wAAJ1WjfEDIzE1JQaDooOULZCIXFqDxYp/55/H33YX4bixGslxwdg0K8Whz8Hg5aYYvIiur95sxb+/PY/3cs7gUIlJ3j4oOghT74zBuIERMHhpFKyQiFzJ5dpG/PObM3g35wzKa5rmE/TRafDwsGgsGtcHWgcuscbg5aYYvIhuTgiB/OJK/CPnDD797gIarU2D8YN9dZh4RzSmJPdA9y6cmJWoszp1sQZ/212E/ztwTr5ZJzzAgMdHxGLyHT06ZPUMBi83xeBF1DblNQ3YtK8Y6785g/OmegCAWgXcnRCGqSkxGHl7CNQcjE/k8YQQ+OZUBf62+xR2HCuTt/eLDMCMUT0xbmAEvBzYw/VjDF5uisGL6NZYrBKyj5fhvZwz2F1YLm/vGeKLBff2xr39IxSsjog6itkq4dPvLuCvu0/hcEmVvD21TygyRvbEnT2DnTIhM4OXm2LwImq/wrIa/PObM/i/vHOobrAAAH41Ig4Lf5bQof/jJSLnMdWZ8f6+s3jn69MwVjX1dhu81JgwpDt+NTIOt3Xzc2o9DF5uisGLyHFqGyxYtfMk/vLlKQDA0JguWP3IEIQHck1IInd19lId/v51Ef61vxh1jVYAQIifHtNSYjDlzhjFpplh8HJTDF5Ejrf9aCnm/ysf1fUWdPXVYdXkwRhxe4jSZRFRG+SdqcC6XUX47KgRzUu8oneYPzJGxeGBxEjotcre0czg5aYYvIg6xplLtfj1Pw/g2IUqqFXAUz/tjd+MuY0D74lcmMUq4b9HSvHX3adw8GylvH10r26YMSoOI28Pccr4rdZg8HJTDF5EHafebMWSTw7jX/vPAQDGJoTiTw8ndsit5UR066rrzfjX/nN4++sinLt8BQCg06iRPjgSGSN7one4v8IVXovBy00xeBF1vE37zmLxJ0fQaJEQHeyNt6YMRf+oQKXLIurUzFYJ+4oq8N8jRnx4oES+MSbYV4dH74zBY3fGoJu/XuEqr4/By00xeBE5x+ESE367/gDOVtRBp1Vj2f39MPGOaJe5bEHUGZiumPFFQRmyj5Xh84IyVNdb5H09u/ni/43siV8MiXKLFSna8vntkvdWr169GrGxsTAYDEhOTsbevXtv2H7z5s1ISEiAwWDAgAEDsHXrVrv9QggsWbIEERER8Pb2RmpqKk6ePGnXpqKiAlOmTEFAQACCgoKQkZGBmpqaFp+vsLAQ/v7+CAoKum5NGzduhEqlQnp6eqteMxE5T/+oQPxnzkik9glFo0XCsx8ewu8/+A5Xmu+SIqKOUVxRh7/vLsIj677B0Be3Y+7GfPz72/PyzS8PDe2Ot6ffgR3zxuCR5B5uEbrayuV6vDZt2oSpU6dizZo1SE5OxsqVK7F582YUFBQgNDT0mvZ79uzB6NGjkZmZiZ///OfYsGEDXnnlFRw4cAD9+/cHALzyyivIzMzEu+++i7i4OCxevBiHDh3C0aNHYTA03Vp+33334cKFC/jLX/4Cs9mM6dOn44477sCGDRvsns9sNmP48OHo1q0b9uzZg8rKymtqOn36NEaOHImePXsiODgYH3/8cateO3u8iJxLkgTW7PoeK/5bAEkACeH+WPPoUMSG+CpdGpFHkCSBb89VYsexUuw4WoaC0mq7/beH+iG1Txju6RuKxOgu0LjpDS9ufakxOTkZd9xxB9544w0AgCRJiI6Oxu9+9zs8++yz17SfOHEiamtrsWXLFnnbnXfeicTERKxZswZCCERGRuKpp57C008/DQAwmUwICwvDO++8g0mTJuHYsWPo27cv9u3bh2HDhgEAsrKy8LOf/Qznzp1DZGSkfO5nnnkG58+fx9ixY/Hkk09eE7ysVitGjx6NX/3qV/jqq69QWVnJ4EXk4vZ8X44n3j+I8ppG+Ou1WPHwIKT1C1e6LCK3dKXRit2F5cg+Voodx8rkBaoBQKNW4Y7YLkjtE4bUPmEe85+ctnx+a51UU6s0NjYiLy8PCxculLep1WqkpqYiJyenxWNycnIwf/58u21paWly2CkqKoLRaERqaqq8PzAwEMnJycjJycGkSZOQk5ODoKAgOXQBQGpqKtRqNXJzc/Hggw8CAHbu3InNmzcjPz8fH374YYv1LFu2DKGhocjIyMBXX311w9fb0NCAhoarfyGrqqpu0JqIOsrw20Lw6ROjMHv9Aew/cxmz3svDrNE98fu03tBytnuimyqrrsfOY2XYcawUX50sR4NFkvf567UY3bsb7ukThp/07oYgH2UmOXUVLhW8ysvLYbVaERYWZrc9LCwMx48fb/EYo9HYYnuj0Sjvt227UZsfX8bUarUIDg6W21y6dAmPP/44/vnPf143ze7evRt/+9vfkJ+f34pXC2RmZuKFF15oVVsi6lhhAQa8P/NOvLLtOP66uwh/2XUKB4sr8cbkwQgN4Gz3RD8khMCJ0hrsOFaK7UdLkV9cabc/Ksgb9/Rt6tVKiguGTsv/wNi4VPByZTNmzMAjjzyC0aNHt7i/uroajz32GNatW4eQkNbNir1w4UK73rqqqipER0c7pF4iajsvjRqLft4XQ2K6YMEH32FvUQXGvb4bb0wejOSeXZUuj0hRjRYJ+05XNI3XOlaK4oordvsHdQ9suoTYNwwJ4f68S/g6XCp4hYSEQKPRoLS01G57aWkpwsNbHm8RHh5+w/a2r6WlpYiIiLBrk5iYKLcpKyuzO4fFYkFFRYV8/M6dO/Hvf/8bK1asANCU9iVJglarxdq1azFkyBCcPn0a48ePl88hSU1drVqtFgUFBbjtttvsnkOv10Ovd915SYg6q58NiEBCuD9+888DKCitxiN/zcWCtN6YObonP0yoU6mobcTnx8uw83gZdp24KM+vBQB6rRojbw9Bat8w3J0QijD2DLeKSwUvnU6HoUOHIjs7W56GQZIkZGdnY86cOS0ek5KSguzsbDz55JPytu3btyMlJQUAEBcXh/DwcGRnZ8tBq6qqCrm5ufjNb34jn6OyshJ5eXkYOnQogKagJUkSkpOTATSNJbNar95q/sknn+CVV17Bnj17EBUVBW9vbxw6dMiutkWLFqG6uhr/+7//y54sIjfTs5sfPpo9HM9/dBgfHSxB5rbjyDtzGSseHoQAA2e7J89ku4SYfbwU2cfKcODsZfzwFrwQPz3uTuiG1D5hGBkfAh+dS8UIt+ByP7H58+dj2rRpGDZsGJKSkrBy5UrU1tZi+vTpAICpU6ciKioKmZmZAIC5c+dizJgxeO211zBu3Dhs3LgR+/fvx9q1awEAKpUKTz75JF566SXEx8fL00lERkbK4a5Pnz649957MWPGDKxZswZmsxlz5szBpEmT5Dsa+/TpY1fn/v37oVar5SkrANj9GYA8z9ePtxORe/DRafGnhwdhaEwXLPvPUXx2tBT3v74bb04Zir6RvPOYPEODxYpvTlVg57FSZB8vk5fpsekbEYDUPqG4u08YBkYFco3TdnK54DVx4kRcvHgRS5YsgdFoRGJiIrKysuTB8WfPnoVafXWQ3vDhw7FhwwYsWrQIzz33HOLj4/Hxxx/bhZ0FCxagtrYWM2fORGVlJUaOHImsrCx5Di8AWL9+PebMmYOxY8dCrVZjwoQJWLVqlfNeOBG5JJVKhUfvjMGAqED8dv0BnL5Uhwff/BovpffHQ8PYk03u6WJ1Az4vKEN2812IdT+YPFivVWPE7SG4OyEUY/uEIiLQW8FKPY/LzePVmXEeLyLXdrm2EU9uyseXJy4CACbdEY1lD/TnHVvk8oQQOHqhCjuPlSH7eBm+PVdpdwkxLECPuxPCMDYhFCNuD4G3zvNmjO9IbjuPFxGRK+viq8Pbj9+BNz4vxJ93nMDGfcWICvLG78bGK10a0TXqzVbkfH8JO46VYufxMlww1dvtH9g9EHcnhCK1Txj6RQbwxhEnYfAiImoDtVqFJ8bGIyxAj2f+7xDe3nMa/29UT/YQkEuoN1vx8cES7DhWhq8Ly3HFfPUSosFLjZG3d0Nqn1DcxbsQFcPgRUR0CyYM6Y43Pi9EccUVbM4rxtSUWKVLok4u78xl/P6Db3HqYq28LTLQgLv7hGJsnzCk9OzqkYtOuxsGLyKiW6DVqDFjVE8s+eQI1u46hUeSenB5IVJEvdmKP28/gXVfnYIkgFB/PaamxODuhDD0ieBEpq6GwYuI6BY9NDQaK3ecxLnLV/DpoQt4IDFK6ZKokzl49jKe3vwtvm/u5frFkCgs/Xk/BPpwrjlXxf+eERHdIm+dBo8PjwUArPnyFHiTODlLvdmKl7cdx4S39uD7i7Xo5q/HX6cOw58eTmTocnEMXkRE7TA1JQY+Og2OXajCVyfLlS6HOoFviysx/vXdWPPl95AE8ODgKGyfNxqpfcOULo1agcGLiKgdgnx0mHRHDwDAmi+/V7ga8mQNFiuWZx3HL97ag5NlNQjx02PtY0Px54mJCPLRKV0etRKDFxFRO2WMioNWrcKe7y/hu3OVSpdDHui7c029XG9+8T2sksADiZHYPm80ftovXOnSqI0YvIiI2ikqyBv3D2pa15W9XuRIjRYJr31WgAff3IMTpTUI8dNhzaND8b+TBqOLL3u53BHvaiQicoBZY27DhwdLsO2wEUXltYgL8VW6JHJzh0tMeHrztzhurAYAjB8UiRfu74dgBi63xh4vIiIH6B3uj7sTQiEEsO6rU0qXQ26s0SLhT9tP4IHVX+O4sRpdfXV4a8oQvD55MEOXB2DwIiJykFmjewIAPsg7h7Lq+pu0JrrWkfMmPLD6a6zKPgmrJDBuQAQ+mzca9w2IULo0chAGLyIiB0mKC8bgHkFotEh45+vTSpdDbsRslbByxwk88MbXOHahCsG+Oqx+ZAhWTxmCrn56pcsjB2LwIiJyEJVKhV+PuQ0A8N43Z1Bdb1a4InIHR89X4YE3vsbKHSdhkQTu6x+Oz+aNxriB7OXyRBxcT0TkQPf0CcNt3Xzx/cVavL/3LGaOvk3pkshFma0S3vrie7y+8yTMVoEuPl5Y9kB//HxgBNdX9GDs8SIiciC1WoVZzWHrb7uL0GiRFK6IXNFxYxUefPNr/Gn7CZitAmn9wvDZvDEYPyiSocvDMXgRETnYA4MjERagR2lVAz7OL1G6HHIhQgi8+UUhxr++G4dLqhDk44X/nZSINY8ORTd/juXqDBi8iIgcTK/V4Fcj4gAAf/nye0gSF8+mJhv3FWN5VgHMVoF7+obhs3mj8UBiFHu5OhEGLyKiDvBIcg/4G7T4/mItdhwrVboccgHnK6/gD58eAwA8dU8vrH1sKEL9DQpXRc7G4EVE1AH8DV549M4YAE3LCAnBXq/OTAiB5z86hJoGCwb3CMJv77qdvVydFIMXEVEHmT48FjqNGgfOVmL/mctKl0MK+uhgCT4vuAidRo1XfzkQGjVDV2fF4EVE1EFCAwyYMDQKALDmCy6e3VmVVdfjhf8cBQDMTY3H7aH+CldESmLwIiLqQDNG9YRKBWQfL0NB82LH1Lks/eQITFfM6BcZgJnNy0pR58XgRUTUgXp288O9/cIBAH/ZxV6vzmbroQvYdtgIrVqF5b8cCC8NP3Y7O/4NICLqYLZlhP6dfx7nK68oXA05y+XaRiz55DAA4Dc/uQ39IgMVrohcAYMXEVEHGxQdhDt7BsMiCfxtd5HS5ZCTLNtyFOU1jYgP9cOcu29XuhxyEQxeREROYOv1en/vWVTWNSpcDXW0ncdL8dHBEqhVwPJfDoReq1G6JHIRDF5ERE4wplc39IkIQF2jFe/lnFG6HOpAVfVmPPdh0yXGjJFxGNyji8IVkSth8CIicgKVSoVfj2m6o+2dPadRb7YqXBF1lMytx2CsqkdsVx/Mv6e30uWQi2HwIiJyknEDIhAV5I1LtY3YnHdO6XKoA3xdWI739xYDAF6ZMBDeOl5iJHsMXkRETqLVqDFjVNPi2et2nYLFKilcETlSbYMFz374HQDgsTtjkNyzq8IVkSti8CIicqKH74hGFx8vnK2ow7bDRqXLIQd69b8FKK64gqggbzxzX4LS5ZCLYvAiInIiH50W04bHAuDi2Z5k/+kKvJtzGgCQ+YsB8NNrlS2IXBaDFxGRk01LiYW3lwZHzldhd2G50uVQO9WbrVjwwXcQAnhoaHeM7tVN6ZLIhTF4ERE5WRdfHSbeEQ0A+MuXpxSuhtpr5Y6TOFVei1B/PRaN66t0OeTiGLyIiBSQMTIOGrUKuwvLceicSely6BZ9d64Sa5vX4PzDgwMQ6OOlcEXk6hi8iIgUEB3sg/EDIwAAa7h4tltqtEhY8MF3kAQwflAk7ukbpnRJ5AYYvIiIFDKreRmhbYcu4MylWoWrobZ684tCHDdWI9hXh/8Zz0uM1DoMXkRECukTEYCf9O4GSQBrd3Gslzs5bqzCGzsLAQD/c38/dPXTK1wRuQsGLyIiBc0a3dTrtTnvHC5WNyhcDbWGxdp0idEiCdzTN0y+ZEzUGi4ZvFavXo3Y2FgYDAYkJydj7969N2y/efNmJCQkwGAwYMCAAdi6davdfiEElixZgoiICHh7eyM1NRUnT560a1NRUYEpU6YgICAAQUFByMjIQE1NTYvPV1hYCH9/fwQFBdltX7duHUaNGoUuXbqgS5cuSE1NvWntRNS53dkzGIOig9BokfDuntNKl0Ot8NfdRfjunAkBBi1eSu8PlUqldEnkRlwueG3atAnz58/H0qVLceDAAQwaNAhpaWkoKytrsf2ePXswefJkZGRk4ODBg0hPT0d6ejoOHz4st1m+fDlWrVqFNWvWIDc3F76+vkhLS0N9fb3cZsqUKThy5Ai2b9+OLVu2YNeuXZg5c+Y1z2c2mzF58mSMGjXqmn1ffPEFJk+ejM8//xw5OTmIjo7GT3/6U5SUlDjgJ0NEnkilUuE3zYtn/yPnNGoaLApXRDfy/cUa/Gn7CQDAop/3RViAQeGKyO0IF5OUlCRmz54tf2+1WkVkZKTIzMxssf3DDz8sxo0bZ7ctOTlZzJo1SwghhCRJIjw8XLz66qvy/srKSqHX68X7778vhBDi6NGjAoDYt2+f3Gbbtm1CpVKJkpISu3MvWLBAPProo+Ltt98WgYGBN3wtFotF+Pv7i3fffffmL1wIYTKZBABhMpla1Z6IPIPFKom7Xv1cxDyzRazb9b3S5dB1WK2SmPDm1yLmmS3i0b9+IyRJUrokchFt+fx2qR6vxsZG5OXlITU1Vd6mVquRmpqKnJycFo/Jycmxaw8AaWlpcvuioiIYjUa7NoGBgUhOTpbb5OTkICgoCMOGDZPbpKamQq1WIzc3V962c+dObN68GatXr27V66mrq4PZbEZwcHCL+xsaGlBVVWX3IKLOR6NWYcbopl6vv35VhEYLF892Rf/IOY39Zy7DV6dB5i8G8BIj3RKXCl7l5eWwWq0IC7OfCyUsLAxGY8uLyRqNxhu2t329WZvQ0FC7/VqtFsHBwXKbS5cu4fHHH8c777yDgICAVr2eZ555BpGRkdcEQ5vMzEwEBgbKj+jo6Fadl4g8z4ODo9DNXw9jVT3+/e15pcuhHymuqMMrWQUAgGfvS0D3Lj4KV0TuyqWClyubMWMGHnnkEYwePbpV7V9++WVs3LgRH330EQyGlscALFy4ECaTSX4UFxc7smQiciMGLw1+NSIOAPCXL7+HJHHxbFchhMCzH36HK2YrkuKCMSU5RumSyI25VPAKCQmBRqNBaWmp3fbS0lKEh4e3eEx4ePgN29u+3qzNjwfvWywWVFRUyG127tyJFStWQKvVQqvVIiMjAyaTCVqtFn//+9/tjl2xYgVefvllfPbZZxg4cOB1X69er0dAQIDdg4g6ryl39oC/XouTZTXYebzlG4rI+TbtK8bXhZdg8FJj+YSBUKt5iZFunUsFL51Oh6FDhyI7O1veJkkSsrOzkZKS0uIxKSkpdu0BYPv27XL7uLg4hIeH27WpqqpCbm6u3CYlJQWVlZXIy8uT2+zcuROSJCE5ORlA0ziw/Px8+bFs2TL4+/sjPz8fDz74oHzc8uXL8eKLLyIrK8tuzBgR0c0EGLzwyJ09AABrvuQyQq7ggukK/vDpMQDAU/f0RmyIr8IVkdvr+LH+bbNx40ah1+vFO++8I44ePSpmzpwpgoKChNFoFEII8dhjj4lnn31Wbv/1118LrVYrVqxYIY4dOyaWLl0qvLy8xKFDh+Q2L7/8sggKChKffPKJ+O6778QDDzwg4uLixJUrV+Q29957rxg8eLDIzc0Vu3fvFvHx8WLy5MnXrbOluxpffvllodPpxAcffCAuXLggP6qrq1v12nlXIxEZTVdE/HNbRcwzW8S+oktKl9OpSZIkfvX2XhHzzBZx/xu7hcXKuxipZW57VyMATJw4EStWrMCSJUuQmJiI/Px8ZGVlyYPjz549iwsXLsjthw8fjg0bNmDt2rUYNGgQPvjgA3z88cfo37+/3GbBggX43e9+h5kzZ+KOO+5ATU0NsrKy7MZerV+/HgkJCRg7dix+9rOfYeTIkVi7dm2ban/rrbfQ2NiIX/7yl4iIiJAfK1asaOdPhYg6i7AAAx4cHAUAWPMllxFS0if555F9vAw6jRqv/nIgNLzESA6gEkJwBKeLqKqqQmBgIEwmE8d7EXVi31+sQeqfvoQQwFcL7kJ0MO+gc7aL1Q24589forLOjKfu6YXfjY1XuiRyYW35/Ha5Hi8ios7utm5+SIwOAgDsP1OhbDGd1P/8+wgq68zoGxGAX//kNqXLIQ/C4EVE5IJswSv/bKWidXRG2w5dwKeHLkCjVmH5LwfCS8OPSnIc/m0iInJBcvA6Z1K2kE5GkgSWbTkKAPj1mJ7oHxWocEXkaRi8iIhckC14HTtfhQaLVdliOpHD5024YKqHn16L393NcV3keAxeREQuqEewD7r4eKHRKuHYhWqly+k0viy4CAAYcXtXGLw0CldDnojBi4jIBalUKgySx3ldVraYTuTLE03Ba0yv0Ju0JLo1DF5ERC7KdrnxW47zcgrTFTMOFlcCAEb3ClG2GPJYDF5ERC5K7vFqDgPUsfYUlsMqCdzWzRfdu3DuNOoYDF5ERC4qsXsQAKCovBaVdY3KFtMJ7DrJy4zU8Ri8iIhcVBdfHWK6NvW88HJjxxJCyAPreZmROhKDFxGRC5PHefFyY4cqLKvBeVM99Fo17uzZVelyyIMxeBERubBBzZcbOc6rY9nuZkyKC+Y0EtShGLyIiFxYYo8gAE09XkIIZYvxYFenkeimcCXk6Ri8iIhcWN+IAHhpVLhU24hzl68oXY5HutJoRW5R02LkP+nN4EUdi8GLiMiFGbw06BMRAICXGztKbtElNFokRAYacFs3P6XLIQ/H4EVE5OI4zqtjyZcZe3eDSqVSuBrydAxeREQujnc2dqxdHN9FTsTgRUTk4mwz2B8qMcFslZQtxsMUV9Th+4u10KhVGH475++ijsfgRUTk4nqG+MLfoEWDRUKBsVrpcjyKbbb6IT2CEGDwUrga6gwYvIiIXJxareI4rw5iu8w4Op6XGck5GLyIiNwAx3k5ntkq4evCSwCaBtYTOQODFxGRG7CN82KPl+McOHMZNQ0WBPvq0D8yUOlyqJNg8CIicgODopuCQeHFGlTXmxWuxjPYxneNig+BWs1pJMg5GLyIiNxAqL8BUUHeEAI4dM6kdDkegcsEkRIYvIiI3IRtnFf+uUpF6/AE5TUNOFxSBQAYxYH15EQMXkREbsJ2uTH/bKWyhXiAr5ovM/aLDEA3f73C1VBnwuBFROQmEqO7AAC+ZY9Xu31ZwMuMpAwGLyIiN9E/KgAatQqlVQ24YLqidDluS5IEvjpZDgAYzeBFTsbgRUTkJnx0WvQK8wfA+bza48j5KlyqbYSfXoshPbooXQ51MgxeRERuJLF5nNdBBq9b9uWJMgDA8Nu6QqflxyA5F//GERG5Ec5g3367TvAyIymHwYuIyI3YZrA/dM4EqySULcYNVdWbkXf2MgAOrCdlMHgREbmR+FB/+Og0qG20orCsRuly3M6ewkuwSgI9u/kiOthH6XKoE3JI8Lpy5QpKSkqu2X7kyBFHnJ6IiJpp1CoMiGqez6v4ssLVuB/bbPWjOWkqKaTdweuDDz5AfHw8xo0bh4EDByI3N1fe99hjj7X39ERE9COJPYIAAPnFXDqoLYQQ2GVbJqg3gxcpo93B66WXXkJeXh7y8/Px9ttvIyMjAxs2bADQ9JeciIgca7Bt6SAOsG+T7y/WoqTyCnRaNe6M66p0OdRJadt7ArPZjLCwMADA0KFDsWvXLjz44IMoLCyESsXV3omIHM02wP5EaTXqGi3w0bX7n/JOwXaZMTkuGN46jcLVUGfV7h6v0NBQfPfdd/L3wcHB2L59O44dO2a3nYiIHCMi0BthAXpYJSEv9Ew3ZwtevJuRlNTu4PXee+8hNDTUbptOp8P777+PL7/8sr2nJyKiFgzqHgSA83m1Vr3ZitxTlwBw/i5SVruDV/fu3REeHt7ivhEjRrT39ERE1IKrA+wrFa3DXeQWVaDBIiEi0ID4UD+ly6FOjPN4ERG5ocTmHi8Gr9bZ9YPLjBx/TEpqU/CKi4tDz5492/xYtWpVm4pavXo1YmNjYTAYkJycjL17996w/ebNm5GQkACDwYABAwZg69atdvuFEFiyZAkiIiLg7e2N1NRUnDx50q5NRUUFpkyZgoCAAAQFBSEjIwM1NS1PTlhYWAh/f38EBQW1uRYiIkcY0D0QKhVQUnkFF6sblC7H5cnzd/EyIymsTbfCvPPOO7f0JLGxsa1uu2nTJsyfPx9r1qxBcnIyVq5cibS0NBQUFFwzlgwA9uzZg8mTJyMzMxM///nPsWHDBqSnp+PAgQPo378/AGD58uVYtWoV3n33XcTFxWHx4sVIS0vD0aNHYTAYAABTpkzBhQsXsH37dpjNZkyfPh0zZ86Up8awMZvNmDx5MkaNGoU9e/a0uRYiIkfwN3jh9m5+OFlWg2+LK5HaN0zpklxWSeUVFJbVQKNWYcTtIUqXQ52dcDFJSUli9uzZ8vdWq1VERkaKzMzMFts//PDDYty4cXbbkpOTxaxZs4QQQkiSJMLDw8Wrr74q76+srBR6vV68//77Qgghjh49KgCIffv2yW22bdsmVCqVKCkpsTv3ggULxKOPPirefvttERgY2KZabsZkMgkAwmQytao9EXVuT/8rX8Q8s0W8mnVc6VJc2obcMyLmmS3iF29+rXQp5KHa8vntUmO8GhsbkZeXh9TUVHmbWq1GamoqcnJyWjwmJyfHrj0ApKWlye2LiopgNBrt2gQGBiI5OVluk5OTg6CgIAwbNkxuk5qaCrVabTcT/86dO7F582asXr36lmr5sYaGBlRVVdk9iIhayzaf17fnKhWtw9V9WcBpJMh1tDt4nTlzBibT1WUrsrOz8cQTT2DFihVoaGjbuIPy8nJYrVZ5QlabsLAwGI3GFo8xGo03bG/7erM2P76MqdVqERwcLLe5dOkSHn/8cbzzzjsICAi4pVp+LDMzE4GBgfIjOjq6xXZERC1J/MEM9pLElUJaYrZK+LqwHACDF7mGdgevhx56CLW1tQCAvLw8PPzww4iJicGRI0cwa9asdhfoKmbMmIFHHnkEo0ePdtg5Fy5cCJPJJD+Ki4sddm4i8ny9w/2h16pRXW9B0aVapctxSfnFlahusKCLjxf6Ny8uTqSkdgev+vp6REZGAmiaTHXmzJl46qmn8Pe//x15eXltOldISAg0Gg1KS0vttpeWll53rrDw8PAbtrd9vVmbsrIyu/0WiwUVFRVym507d2LFihXQarXQarXIyMiAyWSCVqvF3//+91bV8mN6vR4BAQF2DyKi1vLSqDGgOUzkn61UthgXZbvMOCq+GzRqTiNBymt38JIkCZIkAQB27Nghj3G6lXlSdDodhg4diuzsbLvzZ2dnIyUlpcVjUlJS7NoDwPbt2+X2cXFxCA8Pt2tTVVWF3NxcuU1KSgoqKyvtguLOnTshSRKSk5MBNI3fys/Plx/Lli2Dv78/8vPz8eCDD7aqFiIiR+M4rxvbdZLju8i1tHtl1YkTJ+Kee+5BSEgI1Go17rrrLgDAqVOn4O/v3+bzzZ8/H9OmTcOwYcOQlJSElStXora2FtOnTwcATJ06FVFRUcjMzAQAzJ07F2PGjMFrr72GcePGYePGjdi/fz/Wrl0LoCkAPvnkk3jppZcQHx8vTycRGRmJ9PR0AECfPn1w7733YsaMGVizZg3MZjPmzJmDSZMmyb15ffr0satz//79UKvVdtNE3KwWIiJH++E4L7JXXtOA7841jUEe1YvTSJBraHfwWrx4MVJTU2E0GnHPPfdArW7qRLNYLBg/fnybzzdx4kRcvHgRS5YsgdFoRGJiIrKysuRB62fPnpWfAwCGDx+ODRs2YNGiRXjuuecQHx+Pjz/+2C4QLViwALW1tZg5cyYqKysxcuRIZGVlyXN4AcD69esxZ84cjB07Fmq1GhMmTGjzxK+tqYWIyJFswevYhSrUm60weGmULciF7D7ZNKi+b0QAQv0NN2lN5BwqIUSH3QrTo0cPnD17tqNO73GqqqoQGBgIk8nE8V5E1CpCCAx7aQcu1Tbiw98Ox5AeXZQuyWXM35SPDw+W4NdjbsOz9yUoXQ55sLZ8fnfoPF4dmOmIiAhNwynkcV683CiTJMHxXeSSOjR4cSFSIqKOx3Fe1zp6oQrlNY3w1WkwNIa9gOQ62j3Gq1u3lld6F0KgsrKyvacnIqKbYI/XtWyLYqfcFgKd1qUWaaFOrt3B6+LFi46og4iIbtGg7k1zeZ2+VIfLtY3o4qtTuCLl2YLXmN68zEiuxaH/DaipqUFNTY0jT0lERDcR5KNDXIgvAM7nBQDV9WYcOHMZADAmnsGLXItDgteqVasQHR2NHj16yI/XX3/dEacmIqJW4Divq/Z8fwkWSSAuxBc9uvooXQ6RnXYHrxdeeAE7duzAV199hYqKClRUVODLL79EdnY2li5d6ogaiYjoJmyXGznO6weXGXk3I7mgdgev9evX44MPPkBsbKy8LS4uDps2bcKGDRvae3oiImqFxOb5u/KLKzv1VD5CCOxqDl6jOVs9uSCHXGrU6a4dyKnX6zmdBBGRk/SJ8IdOo8blOjOKK64oXY5iTpXX4tzlK9Bp1LizZ1elyyG6RruDV69evbBx48Zrtm/atAm33357e09PREStoNdq0Ceyacbsg8WXFa5GOV8WNPV2JcUFw0fX7hv3iRyu3X8r33rrLTz44IP4y1/+giFDhgAADhw4gKqqKnz00UftLpCIiFonsXsgvi2uRH5xJR5IjFK6HEXYZqvnZUZyVe0OXtHR0di/fz+ys7Nx9OhRAMDPfvYzjB07tt3FERFR6yX2CMK7OWc67QD7erMV35y6BAAY0ytU4WqIWuawftixY8cybBERKWhQ9yAAwOHzVWi0SJ1uxvZ9pytQb5YQHmBArzA/pcshalGbfiu3bt2KmJgYBAcHY+zYscjKygIALFu2DOPGjcPLL7+MsrKyDimUiIhuLC7EFwEGLRotEgqM1UqX43S28V2je4Xw5i5yWW0KXk8//TR+8Ytf4F//+hcGDx6M9PR0PPTQQ1i+fDl69OiBf//73xg8eDBOnDjRUfUSEdF1qFQqed3G/E44wP7q/F28zEiuq03B68yZM5g7dy5SU1OxYsUKvPHGG/jwww/xhz/8AW+99Rb27NmDhx56CM8//3xH1UtERDcwWA5eJmULcbLzlVdwsqwGahUw8nYOrCfX1abgFRsbi71798rfT5kyBUIIjBgxQt7229/+Frt373ZchURE1GqdtcfLNmlqYnQQAn28FK6G6PraNLj+97//PTIyMnD8+HHcd999GDRoEHbv3o2EhAS5TV1dHWprax1eKBER3ZwteH1/sRZV9WYEGDpHCOFlRnIXbQpejz/+OPz9/fHnP/8Zy5Ytg0ajQUJCAoYMGYIhQ4agT58+WLZsGVJSUjqqXiIiuoEQPz26d/HGuctX8F2xCSPjPf+ym8UqYXdhOQDO30Wur83TSUyYMAETJkxATU0Nvv32W+Tn5yM/Px//+Mc/cOTIEdTX1yMyMhITJkzAwIEDMXDgQDz44IMdUTsREbUgMToI5y5fwbfnKjtF8MovrkR1vQVBPl4Y2DylBpGruuV5vPz8/DBixAi78V1WqxXHjx+Xw9ju3bvx5ptvMngRETlRYnQQtnx3AQfPVipdilPYxneNiu8GjZrTSJBrc+hCVhqNBv369UO/fv0wZcoUR56aiIhaKVEeYF8JIYTHz2llG981uhP07pH761zTGhMRdQL9IgOhUatQXtOA86Z6pcvpUBW1jfiupGnqjDG9uilcDdHNMXgREXkYb50GCeH+AODx6zZ+dfIihAASwv0RGmBQuhyim3JI8Dpx4gQsFosjTkVERA4w6AeXGz2ZPI1Eb/Z2kXtwSPDq06cPTp065YhTERGRAyR2guAlSQK7TjRNI8HLjOQuHBK8hBCOOA0RETmILXgdOmeCxSopW0wHOWasQnlNA3x0GgyLCVa6HKJW4RgvIiIPdFs3P/jptbhituJkWY3S5XQI22XG4bd1hU7LjzNyD/ybSkTkgTRqFQZEBQLw3MuNtvm7RvMyI7kRBi8iIg+V2CMIgGfe2VjTYMH+000LgXN8F7kTBi8iIg81qHn5HE/s8dpTWA6LJBDb1QcxXX2VLoeo1Ri8iIg81ODmHq8TpdWobfCsKX92neRlRnJPDF5ERB4qLMCA8AADJAEcap7d3RMIIfBFQfP8XQxe5GYcEryeeeYZdO3a1RGnIiIiB7JNK+FJ47yKymtx7vIV6DRq3NmTnz3kXhwSvDIzMxm8iIhckCfOYG+7m3FYbBf46rUKV0PUNrzUSETkwTyxx2vP95cAcHwXuScGLyIiDzaweyDUKuC8qR5lVfVKl+MQhRebJoS1zVNG5E4YvIiIPJivXov4UH8AnnG50WKVcPZSHQAgLoTTSJD7cWjw2rZtG15//XUAgNFoxLFjxxx5eiIiugWetGB2SeUVWCQBvVaN8ACD0uUQtZnDgtfTTz+NjRs3YvXq1QAAjUaDxx9/3FGnJyKiW2QbYP/tuUpF63CEU+W1AJp6u9RqlcLVELWdw24Hyc7OxsGDBzF48GAAQLdu3VBf7xnjCYiI3Jmtx+u7YhMkSbh1YCm6eDV4Ebkjh/V4eXl5QZIkqFRNv9AVFRVQq9t++tWrVyM2NhYGgwHJycnYu3fvDdtv3rwZCQkJMBgMGDBgALZu3Wq3XwiBJUuWICIiAt7e3khNTcXJkyft2lRUVGDKlCkICAhAUFAQMjIyUFNTI+8vKCjAXXfdhbCwMBgMBvTs2ROLFi2C2Wy2O8/KlSvRu3dveHt7Izo6GvPmzWP4JCLF9Qrzg7eXBtUNFpwqr7n5AS6sqJzBi9ybw4LXE088gYkTJ6K8vBwvvvgiRo8ejQULFrTpHJs2bcL8+fOxdOlSHDhwAIMGDUJaWhrKyspabL9nzx5MnjwZGRkZOHjwINLT05Geno7Dhw/LbZYvX45Vq1ZhzZo1yM3Nha+vL9LS0uwC0ZQpU3DkyBFs374dW7Zswa5duzBz5kx5v5eXF6ZOnYrPPvsMBQUFWLlyJdatW4elS5fKbTZs2IBnn30WS5cuxbFjx/C3v/0NmzZtwnPPPdemnwERkaNpNWr5DsCDZyuVLaadGLzI7QkHOnbsmHjjjTfEqlWrxJEjR9p8fFJSkpg9e7b8vdVqFZGRkSIzM7PF9g8//LAYN26c3bbk5GQxa9YsIYQQkiSJ8PBw8eqrr8r7KysrhV6vF++//74QQoijR48KAGLfvn1ym23btgmVSiVKSkquW+u8efPEyJEj5e9nz54t7r77brs28+fPFyNGjLjZy5aZTCYBQJhMplYfQ0TUGi9tOSJintkinv/oO6VLaZfhmdki5pktYl/RJaVLIZK15fO73T1eW7dulR+nTp1CXFwcbrvtNpw+ffqay3430tjYiLy8PKSmpsrb1Go1UlNTkZOT0+IxOTk5du0BIC0tTW5fVFQEo9Fo1yYwMBDJyclym5ycHAQFBWHYsGFym9TUVKjVauTm5rb4vIWFhcjKysKYMWPkbcOHD0deXp58afTUqVPYunUrfvazn133NTc0NKCqqsruQUTUERKjuwBw7zsb681WnDddAcAeL3Jf7R5cv3nzZgBAaWkpcnJyMHbsWAgh8PnnnyMlJeWGweOHysvLYbVaERYWZrc9LCwMx48fb/EYo9HYYnuj0Sjvt227UZvQ0FC7/VqtFsHBwXIbm+HDh+PAgQNoaGjAzJkzsWzZMnnfI488gvLycowcORJCCFgsFvz617++4aXGzMxMvPDCC9fdT0TkKIOimy41Hr9QjXqzFQYvjcIVtd2ZS3UQAggwaBHsq1O6HKJb0u4er7fffhtvv/02GhsbcezYMXzwwQf4v//7Pxw9ehQNDQ2OqNFlbNq0CQcOHMCGDRvw6aefYsWKFfK+L774An/84x/x5ptv4sCBA/jwww/x6aef4sUXX7zu+RYuXAiTySQ/iouLnfEyiKgTigryRoifHhZJ4Mh5k9Ll3JKi5hsD4rr5yTdyEbkbh00nce7cOYSEhMjfd+3aFefOnWv18SEhIdBoNCgtLbXbXlpaivDw8BaPCQ8Pv2F729fS0lJERETYtUlMTJTb/HjwvsViQUVFxTXPGx0dDQDo27cvrFYrZs6ciaeeegoajQaLFy/GY489hv/3//4fAGDAgAGora3FzJkz8fzzz7d4h6der4der7/hz4WIyBFUKhUSowOx41gZ8otNGBoTrHRJbWabw6snLzOSG3PYXY2TJk3CiBEj8PLLL+OVV17B6NGjMXny5FYfr9PpMHToUGRnZ8vbJElCdnY2UlJSWjwmJSXFrj0AbN++XW4fFxeH8PBwuzZVVVXIzc2V26SkpKCyshJ5eXlym507d0KSJCQnJ1+3XkmSYDabIUkSAKCuru6acKXRNHXlCyFu+vqJiDqau89gb5vDK7Yrgxe5L4f1eP3P//wPfv7zn+Prr78GALzxxhsYOnRom84xf/58TJs2DcOGDUNSUhJWrlyJ2tpaTJ8+HQAwdepUREVFITMzEwAwd+5cjBkzBq+99hrGjRuHjRs3Yv/+/Vi7di2Apv/hPfnkk3jppZcQHx+PuLg4LF68GJGRkUhPTwcA9OnTB/feey9mzJiBNWvWwGw2Y86cOZg0aRIiIyMBAOvXr4eXlxcGDBgAvV6P/fv3Y+HChZg4cSK8vLwAAOPHj8ef/vQnDB48GMnJySgsLMTixYsxfvx4OYARESlJnsHeTYPX6UvNU0l0Y/Ai9+Ww4AUAgwYNQpcuXeSxXUePHkXfvn1bffzEiRNx8eJFLFmyBEajEYmJicjKypIHx589e9auV2n48OHYsGEDFi1ahOeeew7x8fH4+OOP0b9/f7nNggUL5Et+lZWVGDlyJLKysmAwXF3ja/369ZgzZw7Gjh0LtVqNCRMmYNWqVfJ+rVaLV155BSdOnIAQAjExMZgzZw7mzZsnt1m0aBFUKhUWLVqEkpISdOvWDePHj8cf/vCHtv8giYg6wMDuQQCAsxV1uFTTgK5+7jXUoYiXGskDqISDroO9//77eOmll1BcXIzevXvj22+/xbBhw7Bnzx5HnL5TqKqqQmBgIEwmEwICApQuh4g80N2vfYFTF2vx9uN34K6E0Jsf4CJMV8wY9MJnAIDDL6TBT+/QfgOidmnL57fDxnhlZmZi37596NmzJ/bt24e9e/fKg9GJiMg12MZ5HXSzy42nm3u7Qv31DF3k1hwWvPR6PXx8fAAAZrMZiYmJOHLkiKNOT0REDpDopuO8uFQQeQqH/bchPDwclZWVGD9+PO677z507dqVPV5ERC5GDl7nKiGEcJv5sBi8yFM4LHh98MEH0Ov1ePHFF/HFF1+gqqoK9957r6NOT0REDpAQHgCdVo3KOjPOXKpDrJsEGQYv8hQOudQohMDgwYPl73/yk5/g/vvvh07HJR2IiFyJTqtGv8imwb/uNJ8Xgxd5CocEL5VKhUGDBnFMFxGRGxjUPK2EuwQvIcTVqSQ4hxe5OYddajxy5AgGDx6MXr16wcfHRx47sHfvXkc9BREROcDgHkF4Z4/7BK+LNQ2oabBArQKig32ULoeoXRwWvP7zn/846lRERNSBbBOpHrtQBaskoFG79gD70+V1AICoLt7Qa7kSCLk3h00n8d577yEmJsbu8d577znq9ERE5CA9gn1g8FKjwSLhTPMyPK6sqLwGABAX4qdwJUTt57Dg9eGHH16zbfPmzY46PREROYhGrUJ8qD8A4ERptcLV3NwpLhVEHqTdlxrXrVuHtWvXoqCgAElJSfL26upquzsdiYjIdfQO98ehEhOOG6txb/8Ipcu5oaKLvKORPEe7g9fDDz+Me+65B4sWLbJbENrf3x/BwcHtPT0REXWA3mHu0+PFqSTIk7Q7eAUGBiIwMBD//Oc/HVEPERE5Qa/wpuBVYHTt4GWVBM5UNA2uZ/AiT9CmMV5bt25FTEwMgoODMXbsWGRlZQEAli1bhnHjxiEzMxNlZWUdUigRETlOQnPwOn2pDvVmq8LVXN/5yitotEjQadSIDPJWuhyidmtT8Hr66afxi1/8Av/6178wePBgpKen46GHHsLy5cvRo0cP/Oc//8HgwYNx4sSJjqqXiIgcINRfj0BvL1glge8v1ihdznXZLjPGdPVx+WkviFqjTZcaz5w5g7lz5yI2NhapqalISEjArFmz8Kc//Qlz584FADz55JN4/vnneUcjEZELU6lU6B3mj72nK3CitBr9IgOVLqlFHN9FnqZNPV6xsbF2M9FPmTIFQgiMGDFC3vbb3/4Wu3fvdlyFRETUIXrL47xcv8crjksFkYdoU4/X73//e2RkZOD48eO47777MGjQIOzevRsJCQlym7q6OtTWuv6EfEREnd3VAfZVCldyfUWcw4s8TJuC1+OPPw5/f3/8+c9/xrJly6DRaJCQkIAhQ4ZgyJAh6NOnD5YtW4aUlJSOqpeIiBzk6pQSrt/jFduVwYs8Q5unk5gwYQImTJiAmpoafPvtt8jPz0d+fj7+8Y9/4MiRI6ivr0dkZCQmTJiAgQMHYuDAgXjwwQc7onYiImoHW/AqqbyC6noz/A1eCldkr8FixbnLzVNJ8FIjeYhbnsfLz88PI0aMsBvfZbVacfz4cTmM7d69G2+++SaDFxGRCwr08UJ4gAHGqnqcKK3G0BjXmvS6uKIOkgD89Fp089MrXQ6RQ7R7AtUf0mg06NevH/r164cpU6Y48tRERNQBeoX7w1hVjwJjjcsFr1M/WCpIpeJUEuQZ2hS84uLibukv/5NPPoknnniizccREVHHSgj3x64TF11y6SBOJUGeqE3B65133rmlJ4mNjb2l44iIqGP1ah7nddwF72w8fal5YD2DF3mQNgWvMWPGdFQdRESkANsA+wJjNYQQLnVJz3apkVNJkCdp0wSqRETkWeLD/KBSAZfrzCivaVS6HDu81EieiMGLiKgTM3hp5DmyCoyuM86rpsGCsuoGALzUSJ6FwYuIqJPrFeYHAChwoQH2p5t7u0L8dAj0dq35xYjag8GLiKiT6x0eAAA44UI9XpyxnjwVgxcRUSdnG2B/3IV6vDi+izwVgxcRUSfXO7zpUuPJ0mpIklC4miZy8OJSQeRhGLyIiDq52K6+0GnUqGu0oqTyitLlAABOlXMqCfJMDF5ERJ2cVqPGbaFNvV7HXWCclxACRRdrAABxIX4KV0PkWAxeRESE3s13NrrC0kGX68yoqrcAAGK6+ihcDZFjMXgREZF8Z6MrzOVVVN7U2xUV5A2Dl0bhaogci8GLiIjkAfauELxsSwXxjkbyRAxeREQkL5b9/cUaNFokRWvhVBLkyRi8iIgIUUHe8NNrYZEETl+qVbQWBi/yZAxeREQElUolLx2k9J2NnMOLPBmDFxERAQB6hzddblRy6SDpBz1ucVwuiDwQgxcREQG4Os5LycWyjVX1qDdL0KpV6N7FW7E6iDoKgxcREQG42uOl5J2NtsuMPbr6QKvhRxR5Hpf7W7169WrExsbCYDAgOTkZe/fuvWH7zZs3IyEhAQaDAQMGDMDWrVvt9gshsGTJEkRERMDb2xupqak4efKkXZuKigpMmTIFAQEBCAoKQkZGBmpqauT9BQUFuOuuuxAWFgaDwYCePXti0aJFMJvNdueprKzE7NmzERERAb1ej169el1TDxGRq7Itln22og51jRZFauBSQeTpXCp4bdq0CfPnz8fSpUtx4MABDBo0CGlpaSgrK2ux/Z49ezB58mRkZGTg4MGDSE9PR3p6Og4fPiy3Wb58OVatWoU1a9YgNzcXvr6+SEtLQ319vdxmypQpOHLkCLZv344tW7Zg165dmDlzprzfy8sLU6dOxWeffYaCggKsXLkS69atw9KlS+U2jY2NuOeee3D69Gl88MEHKCgowLp16xAVFdUBPykiIsfr6qdHiJ8OAHCytOYmrTvGad7RSJ5OuJCkpCQxe/Zs+Xur1SoiIyNFZmZmi+0ffvhhMW7cOLttycnJYtasWUIIISRJEuHh4eLVV1+V91dWVgq9Xi/ef/99IYQQR48eFQDEvn375Dbbtm0TKpVKlJSUXLfWefPmiZEjR8rfv/XWW6Jnz56isbGxDa/YnslkEgCEyWS65XMQEbXHI+tyRMwzW8SmvWcVef7pb+8VMc9sEf/85rQiz090K9ry+e0yPV6NjY3Iy8tDamqqvE2tViM1NRU5OTktHpOTk2PXHgDS0tLk9kVFRTAajXZtAgMDkZycLLfJyclBUFAQhg0bJrdJTU2FWq1Gbm5ui89bWFiIrKwsjBkzRt7273//GykpKZg9ezbCwsLQv39//PGPf4TVar3ua25oaEBVVZXdg4hISUoPsOccXuTpXCZ4lZeXw2q1IiwszG57WFgYjEZji8cYjcYbtrd9vVmb0NBQu/1arRbBwcHXPO/w4cNhMBgQHx+PUaNGYdmyZfK+U6dO4YMPPoDVasXWrVuxePFivPbaa3jppZeu+5ozMzMRGBgoP6Kjo6/blojIGWzjvJRYLNtslXC2og4A0DPEz+nPT+QMLhO83MGmTZtw4MABbNiwAZ9++ilWrFgh75MkCaGhoVi7di2GDh2KiRMn4vnnn8eaNWuue76FCxfCZDLJj+LiYme8DCKi67Ld2ajEJKrFFXWwSgLeXhqEBeid/vxEzqBVugCbkJAQaDQalJaW2m0vLS1FeHh4i8eEh4ffsL3ta2lpKSIiIuzaJCYmym1+PHjfYrGgoqLimue19Uj17dsXVqsVM2fOxFNPPQWNRoOIiAh4eXlBo9HI7fv06QOj0YjGxkbodLpr6tfr9dDr+Y8LEbmO+OYer4vVDaiobUSw77X/dnUUeeLUEF+oVCqnPS+RM7lMj5dOp8PQoUORnZ0tb5MkCdnZ2UhJSWnxmJSUFLv2ALB9+3a5fVxcHMLDw+3aVFVVITc3V26TkpKCyspK5OXlyW127twJSZKQnJx83XolSYLZbIYkNS0mO2LECBQWFsrfA8CJEycQERHRYugiInJFfnqtPHGpsy83nrrI8V3k+VymxwsA5s+fj2nTpmHYsGFISkrCypUrUVtbi+nTpwMApk6diqioKGRmZgIA5s6dizFjxuC1117DuHHjsHHjRuzfvx9r164F0LT22JNPPomXXnoJ8fHxiIuLw+LFixEZGYn09HQATb1S9957L2bMmIE1a9bAbDZjzpw5mDRpEiIjIwEA69evh5eXFwYMGAC9Xo/9+/dj4cKFmDhxIry8vAAAv/nNb/DGG29g7ty5+N3vfoeTJ0/ij3/8I5544gkn/xSJiNonIdwf5y5fQYGxGnf27Oq05+XAeuoMXCp4TZw4ERcvXsSSJUtgNBqRmJiIrKwseXD82bNnoVZf7aQbPnw4NmzYgEWLFuG5555DfHw8Pv74Y/Tv319us2DBAtTW1mLmzJmorKzEyJEjkZWVBYPBILdZv3495syZg7Fjx0KtVmPChAlYtWqVvF+r1eKVV17BiRMnIIRATEwM5syZg3nz5sltoqOj8d///hfz5s3DwIEDERUVhblz5+KZZ57pyB8ZEZHD9Qrzx45jZU6/s5HBizoDlRBCKF0ENamqqkJgYCBMJhMCAgKULoeIOqlP8kswd2M+hsV0wQe/Ge60503JzMYFUz0+/O1wDOnRxWnPS9Rebfn8dpkxXkRE5BrkNRtLq+Gs/5tfabTigqlpRREuF0SejMGLiIjs9Azxg1atQnW9RQ5DHc12R2MXHy8E+fCGJPJcDF5ERGRHp1XL46ycNc7LNr4rlr1d5OEYvIiI6Bq2y40nnDSRKgfWU2fB4EVERNewLR1U4KTgZZvDi+O7yNMxeBER0TV6hTt3seyi8hoAQBzXaCQPx+BFRETXSGgOXifLamCVOv7OxtOXmhbH5qVG8nQMXkREdI3oLj4weKnRaJHkOw47SmVdIypqGwEAsSE+HfpcREpj8CIiomuo1Sr0CnPOAHvbwPrwAAN8dC61oAqRwzF4ERFRi+QB9h08zot3NFJnwuBFREQtkmewd1KPV1w3Bi/yfAxeRETUol5O7vHiVBLUGTB4ERFRi2x3Np4ur0W92dphzyPPWt+VwYs8H4MXERG1qJu/HkE+XpAEUFhW0yHPIYTgpUbqVBi8iIioRSrVD+5s7KDLjWXVDahrtEKjViG6C6eSIM/H4EVERNeV0MEz2NuWCoru4g2dlh9J5Pn4t5yIiK6rVwev2WibnJVTSVBnweBFRETXZZtSoqMmUZUH1jN4USfB4EVERNdl6/E6b6pHVb3Z4ee3XWrkVBLUWTB4ERHRdQV6eyEi0ACgY3q9isqb7paMC/Fz+LmJXBGDFxER3VBHTaRqsUo4W1EHgFNJUOfB4EVERDeU0EHjvM5X1sNsFdBr1YgIMDj03ESuisGLiIhuyNbjddzBweuUfJnRF2q1yqHnJnJVDF5ERHRD8p2NpdUQQjjsvFwqiDojBi8iIrqh20P9oFYBl+vMuFjT4LDzcqkg6owYvIiI6IYMXhq5V8qRE6nKwYtTSVAnwuBFREQ31REz2NuCF+fwos6EwYuIiG7qh+O8HKHebEVJ5RUA7PGizoXBi4iIbsoWvBzV43W2og5CAP4GLYJ9dQ45J5E7YPAiIqKbsl1qPFFaA0lq/52NP1wqSKXiVBLUeTB4ERHRTcV29YFOq8YVsxXnLl9p9/k4sJ46KwYvIiK6Ka1Gjdu7Na2neNxY1e7zcY1G6qwYvIiIqFUcOcD+dDnXaKTOicGLiIha5epi2TXtPtcp26VGzlpPnQyDFxERtUqCfGdj+y41VtWbUd48A35siE+76yJyJwxeRETUKr2ag9epi7VotEi3fJ7Tzb1d3fz18Dd4OaQ2InfB4EVERK0SGWiAv14LiyTkuxJvBe9opM6MwYuIiFpFpVLJvV7tubORSwVRZ8bgRURErXZ1ItVbv7PRFrxiGbyoE2LwIiKiVusd1jTvVoHx1u9s5KVG6swYvIiIqNV6hwcAuPUeLyEEii7yUiN1Xi4ZvFavXo3Y2FgYDAYkJydj7969N2y/efNmJCQkwGAwYMCAAdi6davdfiEElixZgoiICHh7eyM1NRUnT560a1NRUYEpU6YgICAAQUFByMjIQE3N1f/RFRQU4K677kJYWBgMBgN69uyJRYsWwWw2t1jTxo0boVKpkJ6efms/BCIiF9SrucfrbEUdahssbT6+vKYR1Q0WqFRAj66cSoI6H5cLXps2bcL8+fOxdOlSHDhwAIMGDUJaWhrKyspabL9nzx5MnjwZGRkZOHjwINLT05Geno7Dhw/LbZYvX45Vq1ZhzZo1yM3Nha+vL9LS0lBfXy+3mTJlCo4cOYLt27djy5Yt2LVrF2bOnCnv9/LywtSpU/HZZ5+hoKAAK1euxLp167B06dJrajp9+jSefvppjBo1yoE/GSIi5XX10yPETw8AOFnW9suNpy819XZ17+INvVbj0NqI3IJwMUlJSWL27Nny91arVURGRorMzMwW2z/88MNi3LhxdtuSk5PFrFmzhBBCSJIkwsPDxauvvirvr6ysFHq9Xrz//vtCCCGOHj0qAIh9+/bJbbZt2yZUKpUoKSm5bq3z5s0TI0eOtNtmsVjE8OHDxV//+lcxbdo08cADD7TuhQshTCaTACBMJlOrjyEicrYp674RMc9sEZv2nm3zsZv2nhUxz2wRj/0ttwMqI1JGWz6/XarHq7GxEXl5eUhNTZW3qdVqpKamIicnp8VjcnJy7NoDQFpamty+qKgIRqPRrk1gYCCSk5PlNjk5OQgKCsKwYcPkNqmpqVCr1cjNzW3xeQsLC5GVlYUxY8bYbV+2bBlCQ0ORkZFx09fb0NCAqqoquwcRkauz3dl43Nj2cV5XlwriZUbqnFwqeJWXl8NqtSIsLMxue1hYGIxGY4vHGI3GG7a3fb1Zm9DQULv9Wq0WwcHB1zzv8OHDYTAYEB8fj1GjRmHZsmXyvt27d+Nvf/sb1q1b16rXm5mZicDAQPkRHR3dquOIiJTUO7xpnNetDLAvKm+6PMk7Gqmzcqng5Q42bdqEAwcOYMOGDfj000+xYsUKAEB1dTUee+wxrFu3DiEhIa0618KFC2EymeRHcXFxR5ZOROQQtjsbC24peDX3eHXzc2hNRO5Cq3QBPxQSEgKNRoPS0lK77aWlpQgPD2/xmPDw8Bu2t30tLS1FRESEXZvExES5zY8H71ssFlRUVFzzvLZeqb59+8JqtWLmzJl46qmn8P333+P06dMYP3683FaSmtYy02q1KCgowG233WZ3Lr1eD71ef/0fCBGRC4oPbQpNF6sbUFHbiGBfXauOkySB05fqAHAqCeq8XKrHS6fTYejQocjOzpa3SZKE7OxspKSktHhMSkqKXXsA2L59u9w+Li4O4eHhdm2qqqqQm5srt0lJSUFlZSXy8vLkNjt37oQkSUhOTr5uvZIkwWw2Q5IkJCQk4NChQ8jPz5cf999/P+666y7k5+fzMiIReQxfvRbRwd4AgII2jPM6b7qCRosEnUaNyCDvjiqPyKW5VI8XAMyfPx/Tpk3DsGHDkJSUhJUrV6K2thbTp08HAEydOhVRUVHIzMwEAMydOxdjxozBa6+9hnHjxmHjxo3Yv38/1q5dC6BpbbEnn3wSL730EuLj4xEXF4fFixcjMjJSnmOrT58+uPfeezFjxgysWbMGZrMZc+bMwaRJkxAZGQkAWL9+Pby8vDBgwADo9Xrs378fCxcuxMSJE+Hl5QUvLy/079/f7rUEBQUBwDXbiYjcXe+wABRXXMGJ0mqk3Na1VcfYLjP26OoDjVrVkeURuSyXC14TJ07ExYsXsWTJEhiNRiQmJiIrK0seHH/27Fmo1Vc76oYPH44NGzZg0aJFeO655xAfH4+PP/7YLuwsWLAAtbW1mDlzJiorKzFy5EhkZWXBYDDIbdavX485c+Zg7NixUKvVmDBhAlatWiXv12q1eOWVV3DixAkIIRATE4M5c+Zg3rx5TvipEBG5lt7hfthxrLRNdzZyqSAiQCWEEEoXQU2qqqoQGBgIk8mEgIAApcshIrquT/JLMHdjPobGdMH//WZ4q475n38fwTt7TmPW6J5Y+LM+HVwhkfO05fPbpcZ4ERGRe0iwrdlorEZr//9um7WePV7UmTF4ERFRm8WF+EKrVqG6wYLzpvqbHwBeaiQCGLyIiOgW6LRq9OzWFKBOtGKcV6NFQnFF01QSDF7UmTF4ERHRLWnLRKpnK+ogCcBXp0E3f85fSJ0XgxcREd2S3mFNE6m2Zi6vqzPW+0Kl4lQS1HkxeBER0S2xLZbduuBlW6ORSwVR58bgRUREt8R2Z2PhxRpYrNIN2xaVc3wXEcDgRUREt6h7F294e2nQaJHkNRivx9bjxTUaqbNj8CIioluiVqvQq3mc14mbDLC3jfGKZfCiTo7Bi4iIblnv8JuP86ptsKC0qgEAENeVwYs6NwYvIiK6Za0ZYG/r7erqq0Ogj5dT6iJyVQxeRER0y2w9Xje61MilgoiuYvAiIqJbZgtepy/Vot5sbbFN0UUGLyIbBi8iIrpl3fz06OLjBUkAhWU1LbbhwHqiqxi8iIjolqlUqpuO8zrVHLw4lQQRgxcREbVTwk3Gef1wuSCizo7Bi4iI2qVXc/A63kKP1+XaRpiumAEAsZxKgojBi4iI2qd32PV7vGyXGaOCvGHw0ji1LiJXxOBFRETtYuvxumCql3u3bK4OrPdxel1ErojBi4iI2iXA4IXIQAOAa3u9bGs0cioJoiYMXkRE1G69rrN0kDywPsTP6TURuSIGLyIiarfrjfMqKq8DwKkkiGwYvIiIqN16t3BnoyQJnC7nrPVEP8TgRURE7dbrBz1eQggAQGl1Pa6YrdCqVejexVvJ8ohcBoMXERG12+2hflCrgMo6My5WNwC4ukZjj2AfaDX8uCECGLyIiMgBDF4aeS3GguZxXqd4mZHoGgxeRETkEL1/tGYjx3cRXYvBi4iIHOLHi2VzjUaiazF4ERGRQ/x4sewi9ngRXYPBi4iIHKKXHLxq0GCx4mxF0xxeDF5EVzF4ERGRQ8QE+0CnVeOK2Yqc7y/BIgl4e2kQ5m9QujQil8HgRUREDqHVqBEf2rQ00H+PlAIAYkN8oVarlCyLyKUweBERkcPY7mzcftQIgEsFEf0YgxcRETmMbZxXeU0jAI7vIvoxBi8iInIY25qNNrEMXkR2GLyIiMhhbJcabdjjRWSPwYuIiBwmItAAf4NW/p5jvIjsMXgREZHDqFQqudcryMcLXXx1CldE5FoYvIiIyKFsA+x5mZHoWgxeRETkUEN6dAEADIgKVLgSItejvXkTIiKi1ktPjERYgB6DmwMYEV3lkj1eq1evRmxsLAwGA5KTk7F3794btt+8eTMSEhJgMBgwYMAAbN261W6/EAJLlixBREQEvL29kZqaipMnT9q1qaiowJQpUxAQEICgoCBkZGSgpqZG3l9QUIC77roLYWFhMBgM6NmzJxYtWgSz2Sy3WbduHUaNGoUuXbqgS5cuSE1NvWntRESeRqtRY1R8N/jp+X97oh9zueC1adMmzJ8/H0uXLsWBAwcwaNAgpKWloaysrMX2e/bsweTJk5GRkYGDBw8iPT0d6enpOHz4sNxm+fLlWLVqFdasWYPc3Fz4+voiLS0N9fX1cpspU6bgyJEj2L59O7Zs2YJdu3Zh5syZ8n4vLy9MnToVn332GQoKCrBy5UqsW7cOS5culdt88cUXmDx5Mj7//HPk5OQgOjoaP/3pT1FSUtIBPykiIiJyO8LFJCUlidmzZ8vfW61WERkZKTIzM1ts//DDD4tx48bZbUtOThazZs0SQgghSZIIDw8Xr776qry/srJS6PV68f777wshhDh69KgAIPbt2ye32bZtm1CpVKKkpOS6tc6bN0+MHDnyuvstFovw9/cX77777g1e8VUmk0kAECaTqVXtiYiISHlt+fx2qR6vxsZG5OXlITU1Vd6mVquRmpqKnJycFo/Jycmxaw8AaWlpcvuioiIYjUa7NoGBgUhOTpbb5OTkICgoCMOGDZPbpKamQq1WIzc3t8XnLSwsRFZWFsaMGXPd11NXVwez2Yzg4OAW9zc0NKCqqsruQURERJ7LpYJXeXk5rFYrwsLC7LaHhYXBaDS2eIzRaLxhe9vXm7UJDQ2126/VahEcHHzN8w4fPhwGgwHx8fEYNWoUli1bdt3X88wzzyAyMvKaYGiTmZmJwMBA+REdHX3dcxEREZH7c6ng5Q42bdqEAwcOYMOGDfj000+xYsWKFtu9/PLL2LhxIz766CMYDIYW2yxcuBAmk0l+FBcXd2TpREREpDCXuuUkJCQEGo0GpaWldttLS0sRHh7e4jHh4eE3bG/7WlpaioiICLs2iYmJcpsfD963WCyoqKi45nltvVJ9+/aF1WrFzJkz8dRTT0Gj0chtVqxYgZdffhk7duzAwIEDr/t69Xo99Hr9dfcTERGRZ3GpHi+dToehQ4ciOztb3iZJErKzs5GSktLiMSkpKXbtAWD79u1y+7i4OISHh9u1qaqqQm5urtwmJSUFlZWVyMvLk9vs3LkTkiQhOTn5uvVKkgSz2QxJkuRty5cvx4svvoisrCy7MWNERERELtXjBQDz58/HtGnTMGzYMCQlJWHlypWora3F9OnTAQBTp05FVFQUMjMzAQBz587FmDFj8Nprr2HcuHHYuHEj9u/fj7Vr1wJoWjfsySefxEsvvYT4+HjExcVh8eLFiIyMRHp6OgCgT58+uPfeezFjxgysWbMGZrMZc+bMwaRJkxAZGQkAWL9+Pby8vDBgwADo9Xrs378fCxcuxMSJE+Hl5QUAeOWVV7BkyRJs2LABsbGx8vgwPz8/+Pn5OfPHSERERK7ICXdZttnrr78uevToIXQ6nUhKShLffPONvG/MmDFi2rRpdu3/9a9/iV69egmdTif69esnPv30U7v9kiSJxYsXi7CwMKHX68XYsWNFQUGBXZtLly6JyZMnCz8/PxEQECCmT58uqqur5f0bN24UQ4YMEX5+fsLX11f07dtX/PGPfxRXrlyR28TExAgA1zyWLl3aqtfN6SSIiIjcT1s+v1VCCKFg7qMfqKqqQmBgIEwmEwICApQuh4iIiFqhLZ/fLjXGi4iIiMiTMXgREREROQmDFxEREZGTuNxdjZ2Zbbgdlw4iIiJyH7bP7dYMm2fwciHV1dUAwKWDiIiI3FB1dTUCAwNv2IZ3NboQSZJw/vx5+Pv7Q6VSKV2OW6mqqkJ0dDSKi4t5R6ib4nvo/vgeuje+f7dOCIHq6mpERkZCrb7xKC72eLkQtVqN7t27K12GWwsICOA/GG6O76H743vo3vj+3Zqb9XTZcHA9ERERkZMweBERERE5CYMXeQS9Xo+lS5dCr9crXQrdIr6H7o/voXvj++ccHFxPRERE5CTs8SIiIiJyEgYvIiIiIidh8CIiIiJyEgYvIiIiIidh8CIiIiJyEgYv6pTq6uoQExODp59+WulSqI2Ki4vxk5/8BH379sXAgQOxefNmpUuiVtiyZQt69+6N+Ph4/PWvf1W6HGoj/t45DqeToE7p+eefR2FhIaKjo7FixQqly6E2uHDhAkpLS5GYmAij0YihQ4fixIkT8PX1Vbo0ug6LxYK+ffvi888/R2BgIIYOHYo9e/aga9euSpdGrcTfO8dhjxd1OidPnsTx48dx3333KV0K3YKIiAgkJiYCAMLDwxESEoKKigpli6Ib2rt3L/r164eoqCj4+fnhvvvuw2effaZ0WdQG/L1zHAYvcim7du3C+PHjERkZCZVKhY8//viaNqtXr0ZsbCwMBgOSk5Oxd+/eNj3H008/jczMTAdVTD/mjPfQJi8vD1arFdHR0e2smm6kve/p+fPnERUVJX8fFRWFkpISZ5ROzRz5e8nfu/Zh8CKXUltbi0GDBmH16tUt7t+0aRPmz5+PpUuX4sCBAxg0aBDS0tJQVlYmt0lMTET//v2veZw/fx6ffPIJevXqhV69ejnrJXU6Hf0e2lRUVGDq1KlYu3Zth7+mzs4R7ykpy1HvIX/vHEAQuSgA4qOPPrLblpSUJGbPni1/b7VaRWRkpMjMzGzVOZ999lnRvXt3ERMTI7p27SoCAgLECy+84Miy6Qc64j0UQoj6+noxatQo8Y9//MNRpVIr3cp7+vXXX4v09HR5/9y5c8X69eudUi9d61Z/L/l75xjs8SK30djYiLy8PKSmpsrb1Go1UlNTkZOT06pzZGZmori4GKdPn8aKFSswY8YMLFmypKNKph9xxHsohMDjjz+Ou+++G4899lhHlUqt1Jr3NCkpCYcPH0ZJSQlqamqwbds2pKWlKVUy/Uhr3kP+3jkOgxe5jfLyclitVoSFhdltDwsLg9FoVKgqagtHvIdff/01Nm3ahI8//hiJiYlITEzEoUOHOqJcaoXWvKdarRavvfYa7rrrLiQmJuKpp57iHY0upDXvIX/vHEerdAFESnn88ceVLoFuwciRIyFJktJlUBvdf//9uP/++5Uug24Rf+8chz1e5DZCQkKg0WhQWlpqt720tBTh4eEKVUVtwffQ8/A9dX98D52LwYvchk6nw9ChQ5GdnS1vkyQJ2dnZSElJUbAyai2+h56H76n743voXLzUSC6lpqYGhYWF8vdFRUXIz89HcHAwevTogfnz52PatGkYNmwYkpKSsHLlStTW1mL69OkKVk0/xPfQ8/A9dX98D12I0rdVEv3Q559/LgBc85g2bZrc5vXXXxc9evQQOp1OJCUliW+++Ua5gukafA89D99T98f30HVwrUYiIiIiJ+EYLyIiIiInYfAiIiIichIGLyIiIiInYfAiIiIichIGLyIiIiInYfAiIiIichIGLyIiIiInYfAiIiIichIGLyIiIiInYfAiInKCZ599Fnq9Ho888ojSpRCRgrhkEBGRE5hMJrz33nv43e9+h5MnT+L2229XuiQiUgB7vIiInCAwMBAZGRlQq9U4dOiQ0uUQkUIYvIiInMRiscDHxweHDx9WuhQiUgiDFxGRkyxatAg1NTUMXkSdGMd4ERE5QV5eHoYPH4577rkHRUVFOHLkiNIlEZECGLyIiDqYJElISkrCmDFjkJycjEcffRS1tbXw8vJSujQicjJeaiQi6mCvv/46ysvLsWzZMgwYMABmsxnHjx9XuiwiUgCDFxFRByopKcHixYuxevVq+Pr6Ij4+Hnq9nuO8iDopBi8iog70xBNP4L777sO4ceMAAFqtFn369GHwIuqktEoXQETkqbZs2YKdO3fi2LFjdtsHDBjA4EXUSXFwPREREZGT8FIjERERkZMweBERERE5CYMXERERkZMweBERERE5CYMXERERkZMweBERERE5CYMXERERkZMweBERERE5CYMXERERkZMweBERERE5CYMXERERkZMweBERERE5yf8Hlh7Q2PG5dNMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot difference between model's betas and OLS beta\n",
    "# Is this actually a significant difference?\n",
    "beta_l2 = [np.linalg.norm(model_beta - ols_beta.numpy()) / np.linalg.norm(ols_beta.numpy()) for model_beta in model_betas]\n",
    "plt.plot(lambdas, beta_l2)\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.ylabel(r'$\\| \\beta_{\\mathrm{trade}} - \\beta_{\\mathrm{OLS}} \\|_2$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Adding Explicit Regularizer and Varying $\\lambda$ Tradeoff Parameter\n",
    "Now, we add an explicit $\\ell_2$ regularization to the objective, controlled by $\\eta > 0.$ This gives us the objective:\n",
    "$$\n",
    "\\mathcal{R}_{\\mathrm{trade}}(\\beta; \\lambda) + \\eta \\|\\beta\\|_2\n",
    "= \\lambda \\max_{g \\in \\mathcal{G}} \\mathbb{E}_{(X, Y) \\sim \\mathbb{P}_g}[(X^\\top \\beta - Y)^2] + \\mathbb{E}_{X \\sim \\mathbb{P}_X}\\left[ \\mathbb{E} \\left[ (X^\\top \\beta - Y)^2 \\mid X \\right] \\right] + \\eta\\|\\beta\\|_2.\n",
    "$$\n",
    "Again, we first look at the effect that varying $\\lambda$ has on this objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Objective loss is 4394.8877  = 0.00 * 3851.1809 + 4394.8877\n",
      " Objective loss is 101.1026  = 0.00 * 94.1922 + 99.6609\n",
      " Objective loss is 24.1462  = 0.00 * 21.3383 + 22.5286\n",
      " Objective loss is 9.4619  = 0.00 * 7.3925 + 7.7818\n",
      " Objective loss is 4.9382  = 0.00 * 3.0047 + 3.2281\n",
      " Objective loss is 3.1003  = 0.00 * 1.3300 + 1.3731\n",
      " Objective loss is 2.3647  = 0.00 * 0.6172 + 0.6273\n",
      " Objective loss is 2.0625  = 0.00 * 0.2982 + 0.3186\n",
      " Objective loss is 1.8994  = 0.00 * 0.1487 + 0.1514\n",
      " Objective loss is 1.8285  = 0.00 * 0.0758 + 0.0778\n",
      " Objective loss is 1.7935  = 0.00 * 0.0396 + 0.0409\n",
      " Objective loss is 1.7758  = 0.00 * 0.0211 + 0.0220\n",
      " Objective loss is 1.7670  = 0.00 * 0.0116 + 0.0124\n",
      " Objective loss is 1.7621  = 0.00 * 0.0065 + 0.0069\n",
      " Objective loss is 1.7598  = 0.00 * 0.0038 + 0.0042\n",
      " Objective loss is 1.7583  = 0.00 * 0.0024 + 0.0025\n",
      " Objective loss is 1.7577  = 0.00 * 0.0015 + 0.0016\n",
      " Objective loss is 1.7574  = 0.00 * 0.0011 + 0.0011\n",
      " Objective loss is 1.7572  = 0.00 * 0.0008 + 0.0008\n",
      " Objective loss is 1.7571  = 0.00 * 0.0006 + 0.0007\n",
      "Maximum iteration reached.\n",
      " Objective loss is 5180.8430  = 0.20 * 3851.1809 + 4394.8877\n",
      " Objective loss is 84.1184  = 0.20 * 65.7483 + 69.2035\n",
      " Objective loss is 18.8801  = 0.20 * 13.5268 + 14.4710\n",
      " Objective loss is 7.0296  = 0.20 * 4.2468 + 4.4623\n",
      " Objective loss is 3.6564  = 0.20 * 1.5548 + 1.6145\n",
      " Objective loss is 2.5297  = 0.20 * 0.6147 + 0.6667\n",
      " Objective loss is 2.0675  = 0.20 * 0.2573 + 0.2700\n",
      " Objective loss is 1.8927  = 0.20 * 0.1124 + 0.1204\n",
      " Objective loss is 1.8147  = 0.20 * 0.0505 + 0.0524\n",
      " Objective loss is 1.7826  = 0.20 * 0.0234 + 0.0241\n",
      " Objective loss is 1.7684  = 0.20 * 0.0112 + 0.0113\n",
      " Objective loss is 1.7624  = 0.20 * 0.0056 + 0.0058\n",
      " Objective loss is 1.7595  = 0.20 * 0.0029 + 0.0030\n",
      " Objective loss is 1.7582  = 0.20 * 0.0016 + 0.0017\n",
      " Objective loss is 1.7575  = 0.20 * 0.0010 + 0.0010\n",
      " Objective loss is 1.7573  = 0.20 * 0.0007 + 0.0007\n",
      " Objective loss is 1.7571  = 0.20 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7571  = 0.20 * 0.0004 + 0.0004\n",
      " Objective loss is 1.7571  = 0.20 * 0.0003 + 0.0004\n",
      " Objective loss is 1.7570  = 0.20 * 0.0003 + 0.0003\n",
      "Maximum iteration reached.\n",
      " Objective loss is 5966.7983  = 0.41 * 3851.1809 + 4394.8877\n",
      " Objective loss is 70.6691  = 0.41 * 47.4009 + 49.7826\n",
      " Objective loss is 14.7568  = 0.41 * 8.9486 + 9.4332\n",
      " Objective loss is 5.3131  = 0.41 * 2.5316 + 2.5652\n",
      " Objective loss is 2.9522  = 0.41 * 0.8296 + 0.8794\n",
      " Objective loss is 2.1749  = 0.41 * 0.2964 + 0.3099\n",
      " Objective loss is 1.9144  = 0.41 * 0.1114 + 0.1195\n",
      " Objective loss is 1.8158  = 0.41 * 0.0438 + 0.0454\n",
      " Objective loss is 1.7801  = 0.41 * 0.0179 + 0.0186\n",
      " Objective loss is 1.7663  = 0.41 * 0.0076 + 0.0080\n",
      " Objective loss is 1.7607  = 0.41 * 0.0034 + 0.0035\n",
      " Objective loss is 1.7585  = 0.41 * 0.0016 + 0.0017\n",
      " Objective loss is 1.7577  = 0.41 * 0.0009 + 0.0009\n",
      " Objective loss is 1.7573  = 0.41 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7572  = 0.41 * 0.0004 + 0.0004\n",
      " Objective loss is 1.7571  = 0.41 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7571  = 0.41 * 0.0002 + 0.0003\n",
      " Objective loss is 1.7571  = 0.41 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.41 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.41 * 0.0002 + 0.0002\n",
      "Maximum iteration reached.\n",
      " Objective loss is 6752.7536  = 0.61 * 3851.1809 + 4394.8877\n",
      " Objective loss is 59.9124  = 0.61 * 35.5626 + 36.5681\n",
      " Objective loss is 11.6978  = 0.61 * 6.0888 + 6.2821\n",
      " Objective loss is 4.2563  = 0.61 * 1.5457 + 1.5852\n",
      " Objective loss is 2.4785  = 0.61 * 0.4555 + 0.4590\n",
      " Objective loss is 1.9900  = 0.61 * 0.1458 + 0.1525\n",
      " Objective loss is 1.8341  = 0.61 * 0.0495 + 0.0517\n",
      " Objective loss is 1.7831  = 0.61 * 0.0176 + 0.0180\n",
      " Objective loss is 1.7663  = 0.61 * 0.0066 + 0.0069\n",
      " Objective loss is 1.7603  = 0.61 * 0.0026 + 0.0026\n",
      " Objective loss is 1.7583  = 0.61 * 0.0011 + 0.0012\n",
      " Objective loss is 1.7575  = 0.61 * 0.0006 + 0.0006\n",
      " Objective loss is 1.7572  = 0.61 * 0.0003 + 0.0004\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0003\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0001 + 0.0002\n",
      " Objective loss is 1.7571  = 0.61 * 0.0001 + 0.0002\n",
      "Maximum iteration reached.\n",
      " Objective loss is 7538.7088  = 0.82 * 3851.1809 + 4394.8877\n",
      " Objective loss is 51.7766  = 0.82 * 27.1128 + 28.0464\n",
      " Objective loss is 9.4150  = 0.82 * 4.2308 + 4.2607\n",
      " Objective loss is 3.5276  = 0.82 * 0.9676 + 1.0056\n",
      " Objective loss is 2.2270  = 0.82 * 0.2546 + 0.2739\n",
      " Objective loss is 1.8854  = 0.82 * 0.0734 + 0.0744\n",
      " Objective loss is 1.7960  = 0.82 * 0.0225 + 0.0237\n",
      " Objective loss is 1.7691  = 0.82 * 0.0073 + 0.0078\n",
      " Objective loss is 1.7609  = 0.82 * 0.0025 + 0.0028\n",
      " Objective loss is 1.7583  = 0.82 * 0.0010 + 0.0010\n",
      " Objective loss is 1.7575  = 0.82 * 0.0004 + 0.0005\n",
      " Objective loss is 1.7572  = 0.82 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7572  = 0.82 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 0.82 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 8324.6641  = 1.02 * 3851.1809 + 4394.8877\n",
      " Objective loss is 45.0762  = 1.02 * 21.2314 + 21.7938\n",
      " Objective loss is 7.8631  = 1.02 * 2.9875 + 3.1040\n",
      " Objective loss is 2.9946  = 1.02 * 0.6108 + 0.6335\n",
      " Objective loss is 2.0425  = 1.02 * 0.1448 + 0.1464\n",
      " Objective loss is 1.8311  = 1.02 * 0.0375 + 0.0399\n",
      " Objective loss is 1.7767  = 1.02 * 0.0104 + 0.0110\n",
      " Objective loss is 1.7623  = 1.02 * 0.0031 + 0.0031\n",
      " Objective loss is 1.7586  = 1.02 * 0.0010 + 0.0010\n",
      " Objective loss is 1.7575  = 1.02 * 0.0004 + 0.0004\n",
      " Objective loss is 1.7572  = 1.02 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 1.02 * 0.0001 + 0.0002\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.02 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 9110.6194  = 1.22 * 3851.1809 + 4394.8877\n",
      " Objective loss is 39.2243  = 1.22 * 16.7641 + 17.0617\n",
      " Objective loss is 6.6632  = 1.22 * 2.1353 + 2.3301\n",
      " Objective loss is 2.6460  = 1.22 * 0.3915 + 0.4247\n",
      " Objective loss is 1.9390  = 1.22 * 0.0833 + 0.0863\n",
      " Objective loss is 1.7984  = 1.22 * 0.0195 + 0.0204\n",
      " Objective loss is 1.7671  = 1.22 * 0.0049 + 0.0053\n",
      " Objective loss is 1.7595  = 1.22 * 0.0014 + 0.0015\n",
      " Objective loss is 1.7577  = 1.22 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7573  = 1.22 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.22 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7571  = 1.22 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 9896.5747  = 1.43 * 3851.1809 + 4394.8877\n",
      " Objective loss is 35.0632  = 1.43 * 13.4916 + 14.1401\n",
      " Objective loss is 5.5787  = 1.43 * 1.5407 + 1.6528\n",
      " Objective loss is 2.3716  = 1.43 * 0.2528 + 0.2652\n",
      " Objective loss is 1.8723  = 1.43 * 0.0484 + 0.0508\n",
      " Objective loss is 1.7804  = 1.43 * 0.0102 + 0.0107\n",
      " Objective loss is 1.7621  = 1.43 * 0.0024 + 0.0025\n",
      " Objective loss is 1.7582  = 1.43 * 0.0006 + 0.0006\n",
      " Objective loss is 1.7574  = 1.43 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.43 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 10682.5300  = 1.63 * 3851.1809 + 4394.8877\n",
      " Objective loss is 30.4154  = 1.63 * 10.8757 + 10.9975\n",
      " Objective loss is 4.7298  = 1.63 * 1.1215 + 1.1687\n",
      " Objective loss is 2.1847  = 1.63 * 0.1648 + 0.1678\n",
      " Objective loss is 1.8297  = 1.63 * 0.0285 + 0.0297\n",
      " Objective loss is 1.7702  = 1.63 * 0.0054 + 0.0057\n",
      " Objective loss is 1.7596  = 1.63 * 0.0012 + 0.0012\n",
      " Objective loss is 1.7576  = 1.63 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.63 * 0.0001 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 11468.4853  = 1.84 * 3851.1809 + 4394.8877\n",
      " Objective loss is 27.4635  = 1.84 * 8.8586 + 9.5206\n",
      " Objective loss is 4.1026  = 1.84 * 0.8182 + 0.8653\n",
      " Objective loss is 2.0628  = 1.84 * 0.1083 + 0.1141\n",
      " Objective loss is 1.8032  = 1.84 * 0.0168 + 0.0180\n",
      " Objective loss is 1.7645  = 1.84 * 0.0029 + 0.0031\n",
      " Objective loss is 1.7584  = 1.84 * 0.0006 + 0.0006\n",
      " Objective loss is 1.7574  = 1.84 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 1.84 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 1.84 * 0.0000 + 0.0001\n",
      "Maximum iteration reached.\n",
      " Objective loss is 12254.4406  = 2.04 * 3851.1809 + 4394.8877\n",
      " Objective loss is 23.9975  = 2.04 * 7.2995 + 7.4198\n",
      " Objective loss is 3.6045  = 2.04 * 0.6045 + 0.6328\n",
      " Objective loss is 1.9738  = 2.04 * 0.0717 + 0.0761\n",
      " Objective loss is 1.7858  = 2.04 * 0.0100 + 0.0103\n",
      " Objective loss is 1.7614  = 2.04 * 0.0016 + 0.0017\n",
      " Objective loss is 1.7578  = 2.04 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 2.04 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.04 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.04 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 13040.3959  = 2.24 * 3851.1809 + 4394.8877\n",
      " Objective loss is 21.6046  = 2.24 * 6.0208 + 6.3999\n",
      " Objective loss is 3.2202  = 2.24 * 0.4481 + 0.4733\n",
      " Objective loss is 1.9085  = 2.24 * 0.0477 + 0.0490\n",
      " Objective loss is 1.7751  = 2.24 * 0.0060 + 0.0060\n",
      " Objective loss is 1.7595  = 2.24 * 0.0009 + 0.0009\n",
      " Objective loss is 1.7575  = 2.24 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7572  = 2.24 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.24 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 13826.3511  = 2.45 * 3851.1809 + 4394.8877\n",
      " Objective loss is 19.2613  = 2.45 * 5.0190 + 5.2745\n",
      " Objective loss is 2.9066  = 2.45 * 0.3341 + 0.3450\n",
      " Objective loss is 1.8654  = 2.45 * 0.0318 + 0.0341\n",
      " Objective loss is 1.7686  = 2.45 * 0.0036 + 0.0038\n",
      " Objective loss is 1.7585  = 2.45 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7574  = 2.45 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.45 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 14612.3064  = 2.65 * 3851.1809 + 4394.8877\n",
      " Objective loss is 17.1557  = 2.65 * 4.1759 + 4.3754\n",
      " Objective loss is 2.6705  = 2.65 * 0.2490 + 0.2645\n",
      " Objective loss is 1.8333  = 2.65 * 0.0214 + 0.0224\n",
      " Objective loss is 1.7644  = 2.65 * 0.0022 + 0.0023\n",
      " Objective loss is 1.7579  = 2.65 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 2.65 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.65 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 15398.2617  = 2.86 * 3851.1809 + 4394.8877\n",
      " Objective loss is 15.5183  = 2.86 * 3.5036 + 3.8016\n",
      " Objective loss is 2.4809  = 2.86 * 0.1871 + 0.1992\n",
      " Objective loss is 1.8110  = 2.86 * 0.0144 + 0.0152\n",
      " Objective loss is 1.7617  = 2.86 * 0.0013 + 0.0014\n",
      " Objective loss is 1.7576  = 2.86 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 2.86 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 2.86 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 16184.2170  = 3.06 * 3851.1809 + 4394.8877\n",
      " Objective loss is 13.8262  = 3.06 * 2.9430 + 3.1055\n",
      " Objective loss is 2.3314  = 3.06 * 0.1411 + 0.1510\n",
      " Objective loss is 1.7956  = 3.06 * 0.0097 + 0.0106\n",
      " Objective loss is 1.7601  = 3.06 * 0.0008 + 0.0009\n",
      " Objective loss is 1.7574  = 3.06 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.06 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 16970.1723  = 3.27 * 3851.1809 + 4394.8877\n",
      " Objective loss is 12.4504  = 3.27 * 2.4829 + 2.6277\n",
      " Objective loss is 2.2078  = 3.27 * 0.1063 + 0.1109\n",
      " Objective loss is 1.7842  = 3.27 * 0.0066 + 0.0070\n",
      " Objective loss is 1.7590  = 3.27 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7574  = 3.27 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.27 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 17756.1276  = 3.47 * 3851.1809 + 4394.8877\n",
      " Objective loss is 11.1693  = 3.47 * 2.0923 + 2.1912\n",
      " Objective loss is 2.1115  = 3.47 * 0.0805 + 0.0813\n",
      " Objective loss is 1.7764  = 3.47 * 0.0045 + 0.0049\n",
      " Objective loss is 1.7584  = 3.47 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 3.47 * 0.0000 + 0.0001\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.47 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 18542.0829  = 3.67 * 3851.1809 + 4394.8877\n",
      " Objective loss is 10.1169  = 3.67 * 1.7737 + 1.8790\n",
      " Objective loss is 2.0413  = 3.67 * 0.0611 + 0.0651\n",
      " Objective loss is 1.7706  = 3.67 * 0.0031 + 0.0032\n",
      " Objective loss is 1.7579  = 3.67 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.67 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 19328.0382  = 3.88 * 3851.1809 + 4394.8877\n",
      " Objective loss is 9.0884  = 3.88 * 1.5080 + 1.5156\n",
      " Objective loss is 1.9825  = 3.88 * 0.0465 + 0.0496\n",
      " Objective loss is 1.7667  = 3.88 * 0.0021 + 0.0022\n",
      " Objective loss is 1.7577  = 3.88 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 3.88 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 20113.9934  = 4.08 * 3851.1809 + 4394.8877\n",
      " Objective loss is 8.3090  = 4.08 * 1.2821 + 1.3479\n",
      " Objective loss is 1.9355  = 4.08 * 0.0355 + 0.0372\n",
      " Objective loss is 1.7639  = 4.08 * 0.0014 + 0.0014\n",
      " Objective loss is 1.7575  = 4.08 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.08 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 20899.9487  = 4.29 * 3851.1809 + 4394.8877\n",
      " Objective loss is 7.6088  = 4.29 * 1.0958 + 1.1820\n",
      " Objective loss is 1.8975  = 4.29 * 0.0271 + 0.0277\n",
      " Objective loss is 1.7620  = 4.29 * 0.0010 + 0.0011\n",
      " Objective loss is 1.7574  = 4.29 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.29 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 21685.9040  = 4.49 * 3851.1809 + 4394.8877\n",
      " Objective loss is 6.9248  = 4.49 * 0.9358 + 0.9904\n",
      " Objective loss is 1.8688  = 4.49 * 0.0207 + 0.0217\n",
      " Objective loss is 1.7606  = 4.49 * 0.0007 + 0.0008\n",
      " Objective loss is 1.7574  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7572  = 4.49 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.49 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 22471.8593  = 4.69 * 3851.1809 + 4394.8877\n",
      " Objective loss is 6.3478  = 4.69 * 0.8012 + 0.8522\n",
      " Objective loss is 1.8456  = 4.69 * 0.0159 + 0.0165\n",
      " Objective loss is 1.7596  = 4.69 * 0.0005 + 0.0005\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.69 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 23257.8146  = 4.90 * 3851.1809 + 4394.8877\n",
      " Objective loss is 5.8041  = 4.90 * 0.6847 + 0.7135\n",
      " Objective loss is 1.8274  = 4.90 * 0.0122 + 0.0127\n",
      " Objective loss is 1.7589  = 4.90 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 4.90 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 24043.7699  = 5.10 * 3851.1809 + 4394.8877\n",
      " Objective loss is 5.3460  = 5.10 * 0.5873 + 0.6110\n",
      " Objective loss is 1.8128  = 5.10 * 0.0094 + 0.0097\n",
      " Objective loss is 1.7584  = 5.10 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.10 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 24829.7252  = 5.31 * 3851.1809 + 4394.8877\n",
      " Objective loss is 4.9435  = 5.31 * 0.5043 + 0.5276\n",
      " Objective loss is 1.8010  = 5.31 * 0.0072 + 0.0073\n",
      " Objective loss is 1.7581  = 5.31 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.31 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 25615.6805  = 5.51 * 3851.1809 + 4394.8877\n",
      " Objective loss is 4.5881  = 5.51 * 0.4349 + 0.4505\n",
      " Objective loss is 1.7921  = 5.51 * 0.0055 + 0.0058\n",
      " Objective loss is 1.7578  = 5.51 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.51 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 26401.6357  = 5.71 * 3851.1809 + 4394.8877\n",
      " Objective loss is 4.2546  = 5.71 * 0.3738 + 0.3762\n",
      " Objective loss is 1.7850  = 5.71 * 0.0043 + 0.0046\n",
      " Objective loss is 1.7577  = 5.71 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.71 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 27187.5910  = 5.92 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.9865  = 5.92 * 0.3221 + 0.3366\n",
      " Objective loss is 1.7793  = 5.92 * 0.0033 + 0.0036\n",
      " Objective loss is 1.7575  = 5.92 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 5.92 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 27973.5463  = 6.12 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.7521  = 6.12 * 0.2778 + 0.3066\n",
      " Objective loss is 1.7745  = 6.12 * 0.0025 + 0.0026\n",
      " Objective loss is 1.7575  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.12 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 28759.5016  = 6.33 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.5166  = 6.33 * 0.2400 + 0.2525\n",
      " Objective loss is 1.7710  = 6.33 * 0.0020 + 0.0021\n",
      " Objective loss is 1.7574  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.33 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 29545.4569  = 6.53 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.3214  = 6.53 * 0.2082 + 0.2153\n",
      " Objective loss is 1.7681  = 6.53 * 0.0015 + 0.0016\n",
      " Objective loss is 1.7574  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.53 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 30331.4122  = 6.73 * 3851.1809 + 4394.8877\n",
      " Objective loss is 3.1463  = 6.73 * 0.1801 + 0.1862\n",
      " Objective loss is 1.7658  = 6.73 * 0.0012 + 0.0012\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.73 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 31117.3675  = 6.94 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.9874  = 6.94 * 0.1556 + 0.1596\n",
      " Objective loss is 1.7640  = 6.94 * 0.0009 + 0.0009\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 6.94 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 31903.3228  = 7.14 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.8498  = 7.14 * 0.1348 + 0.1383\n",
      " Objective loss is 1.7626  = 7.14 * 0.0007 + 0.0007\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.14 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 32689.2780  = 7.35 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.7294  = 7.35 * 0.1167 + 0.1228\n",
      " Objective loss is 1.7615  = 7.35 * 0.0006 + 0.0006\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.35 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 33475.2333  = 7.55 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.6248  = 7.55 * 0.1014 + 0.1090\n",
      " Objective loss is 1.7606  = 7.55 * 0.0004 + 0.0004\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.55 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 34261.1886  = 7.76 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.5226  = 7.76 * 0.0880 + 0.0899\n",
      " Objective loss is 1.7599  = 7.76 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.76 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 35047.1439  = 7.96 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.4404  = 7.96 * 0.0762 + 0.0824\n",
      " Objective loss is 1.7594  = 7.96 * 0.0003 + 0.0003\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 7.96 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 35833.0992  = 8.16 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.3625  = 8.16 * 0.0663 + 0.0698\n",
      " Objective loss is 1.7589  = 8.16 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.16 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 36619.0545  = 8.37 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.2938  = 8.37 * 0.0577 + 0.0589\n",
      " Objective loss is 1.7586  = 8.37 * 0.0002 + 0.0002\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.37 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 37405.0098  = 8.57 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.2325  = 8.57 * 0.0501 + 0.0503\n",
      " Objective loss is 1.7583  = 8.57 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.57 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 38190.9651  = 8.78 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.1822  = 8.78 * 0.0436 + 0.0465\n",
      " Objective loss is 1.7581  = 8.78 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.78 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 38976.9203  = 8.98 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.1352  = 8.98 * 0.0380 + 0.0412\n",
      " Objective loss is 1.7579  = 8.98 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 8.98 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 39762.8756  = 9.18 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.0931  = 9.18 * 0.0331 + 0.0359\n",
      " Objective loss is 1.7578  = 9.18 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.18 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 40548.8309  = 9.39 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.0555  = 9.39 * 0.0288 + 0.0312\n",
      " Objective loss is 1.7577  = 9.39 * 0.0001 + 0.0001\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.39 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 41334.7862  = 9.59 * 3851.1809 + 4394.8877\n",
      " Objective loss is 2.0222  = 9.59 * 0.0251 + 0.0272\n",
      " Objective loss is 1.7576  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.59 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 42120.7415  = 9.80 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.9925  = 9.80 * 0.0219 + 0.0235\n",
      " Objective loss is 1.7575  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 9.80 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n",
      " Objective loss is 42906.6968  = 10.00 * 3851.1809 + 4394.8877\n",
      " Objective loss is 1.9667  = 10.00 * 0.0191 + 0.0210\n",
      " Objective loss is 1.7575  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      " Objective loss is 1.7573  = 10.00 * 0.0000 + 0.0000\n",
      "Maximum iteration reached.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_iter = 2000\n",
    "lambdas = torch.tensor(np.linspace(0, 10.0), requires_grad=False)\n",
    "ols_beta = torch.linalg.lstsq( X, Y ).solution  # regular OLS solution (TODO: regularize this)\n",
    "subgroup_betas = [ torch.linalg.lstsq( group.x, group.y ).solution for group in groups ] # OLS for each group\n",
    "model_betas = list()\n",
    "\n",
    "# Fix beta regularizer to 0.1, vary lambdas\n",
    "for lmbd in lambdas:\n",
    "    # train tradeoff model\n",
    "    model = LinearModel(num_features)\n",
    "    optimize_GD(model, trade_regularization = lmbd, beta_regularization=0.1, max_iter= max_iter)\n",
    "    model_betas.append(model.linear.weight.data.numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do standard OLS with regularization to compare?\n",
    "\n",
    "# TODO: Change the convergence criterion\n",
    "# TODO: Change the objective to model selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
